{
  "source_item_id": 137115,
  "source_type": "github",
  "generator_model_id": "llama3-8b-groq",
  "generation_timestamp": "2025-10-26T13:29:40.113614",
  "input_code_language": "java",
  "input_code_snippet": "/*\n * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n * or more contributor license agreements. Licensed under the \"Elastic License\n * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n * Public License v 1\"; you may not use this file except in compliance with, at\n * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n * License v3.0 only\", or the \"Server Side Public License, v 1\".\n */\n\npackage org.elasticsearch.index.shard;\n\nimport org.apache.logging.log4j.Logger;\nimport org.apache.lucene.index.IndexWriter;\nimport org.apache.lucene.index.IndexWriterConfig;\nimport org.apache.lucene.index.SegmentInfos;\nimport org.apache.lucene.misc.store.HardlinkCopyDirectoryWrapper;\nimport org.apache.lucene.search.Sort;\nimport org.apache.lucene.store.Directory;\nimport org.apache.lucene.store.FilterDirectory;\nimport org.apache.lucene.store.IOContext;\nimport org.apache.lucene.store.IndexInput;\nimport org.elasticsearch.ExceptionsHelper;\nimport org.elasticsearch.action.ActionListener;\nimport org.elasticsearch.action.support.SubscribableListener;\nimport org.elasticsearch.action.support.ThreadedActionListener;\nimport org.elasticsearch.cluster.metadata.IndexMetadata;\nimport org.elasticsearch.cluster.metadata.MappingMetadata;\nimport org.elasticsearch.cluster.routing.RecoverySource;\nimport org.elasticsearch.cluster.routing.RecoverySource.SnapshotRecoverySource;\nimport org.elasticsearch.common.UUIDs;\nimport org.elasticsearch.common.lucene.Lucene;\nimport org.elasticsearch.common.unit.ByteSizeValue;\nimport org.elasticsearch.common.util.Maps;\nimport org.elasticsearch.common.util.concurrent.EsExecutors;\nimport org.elasticsearch.core.Releasable;\nimport org.elasticsearch.core.Releasables;\nimport org.elasticsearch.core.TimeValue;\nimport org.elasticsearch.index.Index;\nimport org.elasticsearch.index.IndexVersion;\nimport org.elasticsearch.index.IndexVersions;\nimport org.elasticsearch.index.engine.Engine;\nimport org.elasticsearch.index.mapper.MapperService;\nimport org.elasticsearch.index.seqno.SequenceNumbers;\nimport org.elasticsearch.index.snapshots.IndexShardRestoreFailedException;\nimport org.elasticsearch.index.store.Store;\nimport org.elasticsearch.index.translog.Translog;\nimport org.elasticsearch.indices.recovery.RecoveryState;\nimport org.elasticsearch.repositories.IndexId;\nimport org.elasticsearch.repositories.Repository;\nimport org.elasticsearch.threadpool.ThreadPool;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.atomic.AtomicBoolean;\nimport java.util.function.BiConsumer;\nimport java.util.stream.Collectors;\n\nimport static org.elasticsearch.cluster.metadata.IndexMetadataVerifier.isReadOnlyVerified;\nimport static org.elasticsearch.common.lucene.Lucene.indexWriterConfigWithNoMerging;\nimport static org.elasticsearch.core.TimeValue.timeValueMillis;\n\n/**\n * This package private utility class encapsulates the logic to recover an index shard from either an existing index on\n * disk or from a snapshot in a repository.\n */\npublic final class StoreRecovery {\n\n    private final Logger logger;\n    private final ShardId shardId;\n\n    StoreRecovery(ShardId shardId, Logger logger) {\n        this.logger = logger;\n        this.shardId = shardId;\n    }\n\n    /**\n     * Recovers a shard from it's local file system store. This method required pre-knowledge about if the shard should\n     * exist on disk ie. has been previously allocated or if the shard is a brand new allocation without pre-existing index\n     * files / transaction logs. This\n     * @param indexShard the index shard instance to recovery the shard into\n     * @param listener resolves to <code>true</code> if the shard has been recovered successfully, <code>false</code> if the recovery\n     *                 has been ignored due to a concurrent modification of if the clusters state has changed due to async updates.\n     * @see Store\n     */\n    void recoverFromStore(final IndexShard indexShard, ActionListener<Boolean> listener) {\n        if (canRecover(indexShard)) {\n            RecoverySource.Type recoveryType = indexShard.recoveryState().getRecoverySource().getType();\n            assert recoveryType == RecoverySource.Type.EMPTY_STORE\n                || recoveryType == RecoverySource.Type.EXISTING_STORE\n                || recoveryType == RecoverySource.Type.RESHARD_SPLIT : \"expected one of store recovery types but was: \" + recoveryType;\n            logger.debug(\"starting recovery from store ...\");\n            final var recoveryListener = recoveryListener(indexShard, listener);\n            try {\n                internalRecoverFromStore(indexShard, recoveryListener.map(ignored -> true));\n            } catch (Exception e) {\n                recoveryListener.onFailure(e);\n            }\n        } else {\n            listener.onResponse(false);\n        }\n    }\n\n    void recoverFromLocalShards(\n        BiConsumer<MappingMetadata, ActionListener<Void>> mappingUpdateConsumer,\n        final IndexShard indexShard,\n        final List<LocalShardSnapshot> shards,\n        ActionListener<Boolean> outerListener\n    ) {\n        if (canRecover(indexShard)) {\n            RecoverySource.Type recoveryType = indexShard.recoveryState().getRecoverySource().getType();\n            assert recoveryType == RecoverySource.Type.LOCAL_SHARDS : \"expected local shards recovery type: \" + recoveryType;\n            if (shards.isEmpty()) {\n                throw new IllegalArgumentException(\"shards must not be empty\");\n            }\n            Set<Index> indices = shards.stream().map((s) -> s.getIndex()).collect(Collectors.toSet());\n            if (indices.size() > 1) {\n                throw new IllegalArgumentException(\"can't add shards from more than one index\");\n            }\n            IndexMetadata sourceMetadata = shards.get(0).getIndexMetadata();\n            final var mappingStep = new SubscribableListener<Void>();\n            if (sourceMetadata.mapping() == null) {\n                mappingStep.onResponse(null);\n            } else {\n                mappingUpdateConsumer.accept(sourceMetadata.mapping(), mappingStep);\n            }\n            mappingStep.addListener(outerListener.delegateFailure((listener, ignored) -> {\n                indexShard.mapperService().merge(sourceMetadata, MapperService.MergeReason.MAPPING_RECOVERY);\n                // now that the mapping is merged we can validate the index sort configuration.\n                Sort indexSort = indexShard.getIndexSort();\n                final boolean hasNested = indexShard.mapperService().hasNested();\n                final boolean isSplit = sourceMetadata.getNumberOfShards() < indexShard.indexSettings().getNumberOfShards();\n\n                final var recoveryListener = recoveryListener(indexShard, listener);\n                logger.debug(\"starting recovery from local shards {}\", shards);\n                try {\n                    final Directory directory = indexShard.store().directory(); // don't close this directory!!\n                    final Directory[] sources = shards.stream().map(LocalShardSnapshot::getSnapshotDirectory).toArray(Directory[]::new);\n                    final long maxSeqNo = shards.stream().mapToLong(LocalShardSnapshot::maxSeqNo).max().getAsLong();\n                    final long maxUnsafeAutoIdTimestamp = shards.stream()\n                        .mapToLong(LocalShardSnapshot::maxUnsafeAutoIdTimestamp)\n                        .max()\n                        .getAsLong();\n                    addIndices(\n                        indexShard.recoveryState().getIndex(),\n                        directory,\n                        indexSort,\n                        sources,\n                        maxSeqNo,\n                        maxUnsafeAutoIdTimestamp,\n                        indexShard.indexSettings().getIndexMetadata(),\n                        indexShard.shardId().id(),\n                        ",
  "raw_llm_output": "{\n  \"bugs_found\": [\n      {\n         \"explanation\": \"The method 'recoverFromStore' does not handle the case where the 'indexShard' is null.\",\n         \"suggested_fix\": \"Add a null check for 'indexShard' before calling 'recoverFromStore'.\"\n      },\n      {\n         \"explanation\": \"The method 'recoverFromLocalShards' does not handle the case where the 'shards' list is null.\",\n         \"suggested_fix\": \"Add a null check for 'shards' before calling 'recoverFromLocalShards'.\"\n      },\n      {\n         \"explanation\": \"The 'internalRecoverFromStore' method does not handle the case where the 'recoveryListener' is null.\",\n         \"suggested_fix\": \"Add a null check for 'recoveryListener' before calling 'internalRecoverFromStore'.\"\n      },\n      {\n         \"explanation\": \"The 'addIndices' method does not handle the case where the 'sources' array is null.\",\n         \"suggested_fix\": \"Add a null check for 'sources' before calling 'addIndices'.\"\n      }\n   ],\n   \"no_bugs_reasoning\": \"No bugs found in the provided code snippet.\"\n}",
  "parsed_llm_output": {
    "bugs_found": [
      {
        "explanation": "The method 'recoverFromStore' does not handle the case where the 'indexShard' is null.",
        "suggested_fix": "Add a null check for 'indexShard' before calling 'recoverFromStore'."
      },
      {
        "explanation": "The method 'recoverFromLocalShards' does not handle the case where the 'shards' list is null.",
        "suggested_fix": "Add a null check for 'shards' before calling 'recoverFromLocalShards'."
      },
      {
        "explanation": "The 'internalRecoverFromStore' method does not handle the case where the 'recoveryListener' is null.",
        "suggested_fix": "Add a null check for 'recoveryListener' before calling 'internalRecoverFromStore'."
      },
      {
        "explanation": "The 'addIndices' method does not handle the case where the 'sources' array is null.",
        "suggested_fix": "Add a null check for 'sources' before calling 'addIndices'."
      }
    ],
    "no_bugs_reasoning": "No bugs found in the provided code snippet."
  },
  "error": null
}