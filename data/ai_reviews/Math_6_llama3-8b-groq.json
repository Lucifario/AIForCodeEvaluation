{"sample_id": "Math_6", "model": "llama3-8b-groq", "code_context": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.commons.math3.optim.nonlinear.scalar.gradient;\n\nimport org.apache.commons.math3.analysis.UnivariateFunction;\nimport org.apache.commons.math3.analysis.solvers.BrentSolver;\nimport org.apache.commons.math3.analysis.solvers.UnivariateSolver;\nimport org.apache.commons.math3.exception.MathInternalError;\nimport org.apache.commons.math3.exception.MathIllegalStateException;\nimport org.apache.commons.math3.exception.TooManyEvaluationsException;\nimport org.apache.commons.math3.exception.MathUnsupportedOperationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.optim.OptimizationData;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GradientMultivariateOptimizer;\nimport org.apache.commons.math3.util.FastMath;\n\n/**\n * Non-linear conjugate gradient optimizer.\n * <br/>\n * This class supports both the Fletcher-Reeves and the Polak-Ribi\u00e8re\n * update formulas for the conjugate search directions.\n * It also supports optional preconditioning.\n * <br/>\n * Constraints are not supported: the call to\n * {@link #optimize(OptimizationData[]) optimize} will throw\n * {@link MathUnsupportedOperationException} if bounds are passed to it.\n *\n * @version $Id$\n * @since 2.0\n */\npublic class NonLinearConjugateGradientOptimizer\n    extends GradientMultivariateOptimizer {\n    /** Update formula for the beta parameter. */\n    private final Formula updateFormula;\n    /** Preconditioner (may be null). */\n    private final Preconditioner preconditioner;\n    /** solver to use in the line search (may be null). */\n    private final UnivariateSolver solver;\n    /** Initial step used to bracket the optimum in line search. */\n    private double initialStep = 1;\n\n    /**\n     * Constructor with default {@link BrentSolver line search solver} and\n     * {@link IdentityPreconditioner preconditioner}.\n     *\n     * @param updateFormula formula to use for updating the &beta; parameter,\n     * must be one of {@link Formula#FLETCHER_REEVES} or\n     * {@link Formula#POLAK_RIBIERE}.\n     * @param checker Convergence checker.\n     */\n    public NonLinearConjugateGradientOptimizer(final Formula updateFormula,\n                                               ConvergenceChecker<PointValuePair> checker) {\n        this(updateFormula,\n             checker,\n             new BrentSolver(),\n             new IdentityPreconditioner());\n    }\n\n    /**\n     * Available choices of update formulas for the updating the parameter\n     * that is used to compute the successive conjugate search directions.\n     * For non-linear conjugate gradients, there are\n     * two formulas:\n     * <ul>\n     *   <li>Fletcher-Reeves formula</li>\n     *   <li>Polak-Ribi\u00e8re formula</li>\n     * </ul>\n     *\n     * On the one hand, the Fletcher-Reeves formula is guaranteed to converge\n     * if the start point is close enough of the optimum whether the\n     * Polak-Ribi\u00e8re formula may not converge in rare cases. On the\n     * other hand, the Polak-Ribi\u00e8re formula is often faster when it\n     * does converge. Polak-Ribi\u00e8re is often used.\n     *\n     * @since 2.0\n     */\n    public static enum Formula {\n        /** Fletcher-Reeves formula. */\n        FLETCHER_REEVES,\n        /** Polak-Ribi\u00e8re formula. */\n        POLAK_RIBIERE\n    }\n\n    /**\n     * The initial step is a factor with respect to the search direction\n     * (which itself is roughly related to the gradient of the function).\n     * <br/>\n     * It is used to find an interval that brackets the optimum in line\n     * search.\n     *\n     * @since 3.1\n     */\n    public static class BracketingStep implements OptimizationData {\n        /** Initial step. */\n        private final double initialStep;\n\n        /**\n         * @param step Initial step for the bracket search.\n         */\n        public BracketingStep(double step) {\n            initialStep = step;\n        }\n\n        /**\n         * Gets the initial step.\n         *\n         * @return the initial step.\n         */\n        public double getBracketingStep() {\n            return initialStep;\n        }\n    }\n\n    /**\n     * Constructor with default {@link IdentityPreconditioner preconditioner}.\n     *\n     * @param updateFormula formula to use for updating the &beta; parameter,\n     * must be one of {@link Formula#FLETCHER_REEVES} or\n     * {@link Formula#POLAK_RIBIERE}.\n     * @param checker Convergence checker.\n     * @param lineSearchSolver Solver to use during line search.\n     */\n    public NonLinearConjugateGradientOptimizer(final Formula updateFormula,\n                                               ConvergenceChecker<PointValuePair> checker,\n                                               final UnivariateSolver lineSearchSolver) {\n        this(updateFormula,\n             checker,\n             lineSearchSolver,\n             new IdentityPreconditioner());\n    }\n\n    /**\n     * @param updateFormula formula to use for updating the &beta; parameter,\n     * must be one of {@link Formula#FLETCHER_REEVES} or\n     * {@link Formula#POLAK_RIBIERE}.\n     * @param checker Convergence checker.\n     * @param lineSearchSolver Solver to use during line search.\n     * @param preconditioner Preconditioner.\n     */\n    public NonLinearConjugateGradientOptimizer(final Formula updateFormula,\n                                               ConvergenceChecker<PointValuePair> checker,\n                                               final UnivariateSolver lineSearchSolver,\n                                               final Preconditioner preconditioner) {\n        super(checker);\n\n        this.updateFormula = updateFormula;\n        solver = lineSearchSolver;\n        this.preconditioner = preconditioner;\n        initialStep = 1;\n    }\n\n    /**\n     * {@inheritDoc}\n     *\n     * @param optData Optimization data. In addition to those documented in\n     * {@link GradientMultivariateOptimizer#parseOptimizationData(OptimizationData[])\n     * GradientMultivariateOptimizer}, this method will register the following data:\n     * <ul>\n     *  <li>{@link BracketingStep}</li>\n     * </ul>\n     * @return {@inheritDoc}\n     * @throws TooManyEvaluationsException if the maximal number of\n     * evaluations (of the objective function) is exceeded.\n     */\n    @Override\n    public PointValuePair optimize(OptimizationData... optData)\n        throws TooManyEvaluationsException {\n        // Set up base class and perform computation.\n        return super.optimize(optData);\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    protected PointValuePair doOptimize() {\n        final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n        final double[] point = getStartPoint();\n        final GoalType goal = getGoalType();\n        final int n = point.length;\n        double[] r = computeObjectiveGradient(point);\n        if (goal == GoalType.MINIMIZE) {\n            for (int i = 0; i < n; i++) {\n                r[i] = -r[i];\n            }\n        }\n\n        // Initial search direction.\n        double[] steepestDescent = preconditioner.precondition(point, r);\n        double[] searchDirection = steepestDescent.clone();\n\n        double delta = 0;\n        for (int i = 0; i < n; ++i) {\n            delta += r[i] * searchDirection[i];\n        }\n\n        PointValuePair current = null;\n        int iter = 0;\n        int maxEval = getMaxEvaluations();\n        while (true) {\n            ++iter;\n\n            final double objective = computeObjectiveValue(point);\n            PointValuePair previous = current;\n            current = new PointValuePair(point, objective);\n            if (previous != null) {\n                if (checker.converged(iter, previous, current)) {\n                    // We have found an optimum.\n                    return current;\n                }\n            }\n\n            // Find the optimal step in the search direction.\n            final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);\n            final double uB = findUpperBound(lsf, 0, initialStep);\n            // XXX Last parameters is set to a value close to zero in order to\n            // work around the divergence problem in the \"testCircleFitting\"\n            // unit test (see MATH-439).\n            final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);\n            maxEval -= solver.getEvaluations(); // Subtract used up evaluations.\n\n            // Validate new point.\n            for (int i = 0; i < point.length; ++i) {\n                point[i] += step * searchDirection[i];\n            }\n\n            r = computeObjectiveGradient(point);\n            if (goal == GoalType.MINIMIZE) {\n                for (int i = 0; i < n; ++i) {\n                    r[i] = -r[i];\n                }\n            }\n\n            // Compute beta.\n            final double deltaOld = delta;\n            final double[] newSteepestDescent = preconditioner.precondition(point, r);\n            delta = 0;\n            for (int i = 0; i < n; ++i) {\n                delta += r[i] * newSteepestDescent[i];\n            }\n\n            final double beta;\n            switch (updateFormula) {\n            case FLETCHER_REEVES:\n                beta = delta / deltaOld;\n                break;\n            case POLAK_RIBIERE:\n                double deltaMid = 0;\n                for (int i = 0; i < r.length; ++i) {\n                    deltaMid += r[i] * steepestDescent[i];\n                }\n                beta = (delta - deltaMid) / deltaOld;\n                break;\n            default:\n                // Should never happen.\n                throw new MathInternalError();\n            }\n            steepestDescent = newSteepestDescent;\n\n            // Compute conjugate search direction.\n            if (iter % n == 0 ||\n                beta < 0) {\n                // Break conjugation: reset search direction.\n                searchDirection = steepestDescent.clone();\n            } else {\n                // Compute new conjugate search direction.\n                for (int i = 0; i < n; ++i) {\n                    searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];\n                }\n            }\n        }\n    }\n\n    /**\n     * Scans the list of (required and optional) optimization data that\n     * characterize the problem.\n     *\n     * @param optData Optimization data.\n     * The following data will be looked for:\n     * <ul>\n     *  <li>{@link BracketingStep}</li>\n     * </ul>\n     */\n    @Override\n    protected void parseOptimizationData(OptimizationData... optData) {\n        // Allow base class to register its own data.\n        super.parseOptimizationData(optData);\n\n        // The existing values (as set by the previous call) are reused if\n        // not provided in the argument list.\n        for (OptimizationData data : optData) {\n            if  (data instanceof BracketingStep) {\n                initialStep = ((BracketingStep) data).getBracketingStep();\n                // If more data must be parsed, this statement _must_ be\n                // changed to \"continue\".\n                break;\n            }\n        }\n\n        checkParameters();\n    }\n\n    /**\n     * Finds the upper bound b ensuring bracketing of a root between a and b.\n     *\n     * @param f function whose root must be bracketed.\n     * @param a lower bound of the interval.\n     * @param h initial step to try.\n     * @return b such that f(a) and f(b) have opposite signs.\n     * @throws MathIllegalStateException if no bracket can be found.\n     */\n    private double findUpperBound(final UnivariateFunction f,\n                                  final double a, final double h) {\n        final double yA = f.value(a);\n        double yB = yA;\n        for (double step = h; step < Double.MAX_VALUE; step *= FastMath.max(2, yA / yB)) {\n            final double b = a + step;\n            yB = f.value(b);\n            if (yA * yB <= 0) {\n                return b;\n            }\n        }\n        throw new MathIllegalStateException(LocalizedFormats.UNABLE_TO_BRACKET_OPTIMUM_IN_LINE_SEARCH);\n    }\n\n    /** Default identity preconditioner. */\n    public static class IdentityPreconditioner implements Preconditioner {\n        /** {@inheritDoc} */\n        public double[] precondition(double[] variables, double[] r) {\n            return r.clone();\n        }\n    }\n\n    /**\n     * Internal class for line search.\n     * <p>\n     * The function represented by this class is the dot product of\n     * the objective function gradient and the search direction. Its\n     * value is zero when the gradient is orthogonal to the search\n     * direction, i.e. when the objective function value is a local\n     * extremum along the search direction.\n     * </p>\n     */\n    private class LineSearchFunction implements UnivariateFunction {\n        /** Current point. */\n        private final double[] currentPoint;\n        /** Search direction. */\n        private final double[] searchDirection;\n\n        /**\n         * @param point Current point.\n         * @param direction Search direction.\n         */\n        public LineSearchFunction(double[] point,\n                                  double[] direction) {\n            currentPoint = point.clone();\n            searchDirection = direction.clone();\n        }\n\n        /** {@inheritDoc} */\n        public double value(double x) {\n            // current point in the search direction\n            final double[] shiftedPoint = currentPoint.clone();\n            for (int i = 0; i < shiftedPoint.length; ++i) {\n                shiftedPoint[i] += x * searchDirection[i];\n            }\n\n            // gradient of the objective function\n            final double[] gradient = computeObjectiveGradient(shiftedPoint);\n\n            // dot product with the search direction\n            double dotProduct = 0;\n            for (int i = 0; i < gradient.length; ++i) {\n                dotProduct += gradient[i] * searchDirection[i];\n            }\n\n            return dotProduct;\n        }\n    }\n\n    /**\n     * @throws MathUnsupportedOperationException if bounds were passed to the\n     * {@link #optimize(OptimizationData[]) optimize} method.\n     */\n    private void checkParameters() {\n        if (getLowerBound() != null ||\n            getUpperBound() != null) {\n            throw new MathUnsupportedOperationException(LocalizedFormats.CONSTRAINT);\n        }\n    }\n}\n", "review": {"response": "{\n  \"bugs\": [\n      {\n         \"category\": \"Potential Null Pointer Exception\",\n         \"description\": \"The constructor NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker) does not check if the updateFormula is null. It should be checked and an exception should be thrown if it is null.\",\n         \"lineNumber\": 55,\n         \"fileName\": \"NonLinearConjugateGradientOptimizer.java\"\n      },\n      {\n         \"category\": \"Potential Null Pointer Exception\",\n         \"description\": \"The constructor NonLinearConjugateGradientOptimizer(final Formula updateFormula, ConvergenceChecker<PointValuePair> checker, final UnivariateSolver lineSearchSolver) does not check if the updateFormula is null. It should be checked and an exception should be thrown if it is null.\",\n         \"lineNumber\": 81,\n         \"fileName\": \"NonLinearConjugateGradientOptimizer.java\"\n      },\n      {\n         \"category\": \"Potential MathInternalError\",\n         \"description\": \"The method optimize(OptimizationData[]) does not check if the preconditioner is null before using it. If the preconditioner is null, a MathInternalError should be thrown.\",\n         \"lineNumber\": 234,\n         \"fileName\": \"NonLinearConjugateGradientOptimizer.java\"\n      },\n      {\n         \"category\": \"Potential TooManyEvaluationsException\",\n         \"description\": \"The method optimize(OptimizationData[]) does not check if the maximum number of evaluations has been reached before continuing the optimization process. If the maximum number of evaluations has been reached, a TooManyEvaluationsException should be thrown.\",\n         \"lineNumber\": 243,\n         \"fileName\": \"NonLinearConjugateGradientOptimizer.java\"\n      }\n   ]\n}"}}