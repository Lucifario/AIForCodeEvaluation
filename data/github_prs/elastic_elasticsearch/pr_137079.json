{
  "id": 137079,
  "repository": "elastic/elasticsearch",
  "title": "Use the ScalarQuantizedVectorsReader in Lucene BWC",
  "body": "The Lucene class is now public, so can be referenced by ES",
  "state": "closed",
  "merged": true,
  "merged_at": "2025-10-24T14:40:51+00:00",
  "created_at": "2025-10-24T08:12:48+00:00",
  "updated_at": "2025-10-24T14:41:19+00:00",
  "author": "thecoop",
  "reviewers": [
    "john-wagster"
  ],
  "base_sha": "3d5b71e587c40822941ce1bae6dc18eb639fc0df",
  "head_sha": "8a580f3f05e87d684fa2206eb0384fd9922a7f5f",
  "review_comments": [
    {
      "user": "john-wagster",
      "state": "APPROVED",
      "body": "lgtm",
      "submitted_at": "2025-10-24T11:50:01+00:00"
    }
  ],
  "pr_comments": [
    {
      "user": "elasticsearchmachine",
      "body": "Pinging @elastic/es-search-relevance (Team:Search Relevance)",
      "created_at": "2025-10-24T08:13:31+00:00"
    }
  ],
  "files_changed": [
    {
      "filename": "server/src/main/java/org/elasticsearch/index/codec/vectors/ES814ScalarQuantizedVectorsFormat.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -9,6 +9,7 @@\n \n package org.elasticsearch.index.codec.vectors;\n \n+import org.apache.lucene.backward_codecs.lucene99.Lucene99ScalarQuantizedVectorsReader;\n import org.apache.lucene.codecs.hnsw.FlatFieldVectorsWriter;\n import org.apache.lucene.codecs.hnsw.FlatVectorScorerUtil;\n import org.apache.lucene.codecs.hnsw.FlatVectorsFormat;"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/codec/vectors/Lucene99ScalarQuantizedVectorsReader.java",
      "status": "removed",
      "additions": 0,
      "deletions": 455,
      "changes": 455,
      "patch": "@@ -1,455 +0,0 @@\n-/*\n- * @notice\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- *\n- * Modifications copyright (C) 2024 Elasticsearch B.V.\n- */\n-\n-package org.elasticsearch.index.codec.vectors;\n-\n-import org.apache.lucene.codecs.CodecUtil;\n-import org.apache.lucene.codecs.KnnVectorsReader;\n-import org.apache.lucene.codecs.hnsw.FlatVectorsReader;\n-import org.apache.lucene.codecs.hnsw.FlatVectorsScorer;\n-import org.apache.lucene.codecs.lucene95.OrdToDocDISIReaderConfiguration;\n-import org.apache.lucene.index.ByteVectorValues;\n-import org.apache.lucene.index.CorruptIndexException;\n-import org.apache.lucene.index.FieldInfo;\n-import org.apache.lucene.index.FieldInfos;\n-import org.apache.lucene.index.FloatVectorValues;\n-import org.apache.lucene.index.IndexFileNames;\n-import org.apache.lucene.index.SegmentReadState;\n-import org.apache.lucene.index.VectorEncoding;\n-import org.apache.lucene.index.VectorSimilarityFunction;\n-import org.apache.lucene.internal.hppc.IntObjectHashMap;\n-import org.apache.lucene.search.VectorScorer;\n-import org.apache.lucene.store.ChecksumIndexInput;\n-import org.apache.lucene.store.DataAccessHint;\n-import org.apache.lucene.store.FileDataHint;\n-import org.apache.lucene.store.FileTypeHint;\n-import org.apache.lucene.store.IOContext;\n-import org.apache.lucene.store.IndexInput;\n-import org.apache.lucene.util.IOUtils;\n-import org.apache.lucene.util.RamUsageEstimator;\n-import org.apache.lucene.util.hnsw.RandomVectorScorer;\n-import org.apache.lucene.util.quantization.QuantizedByteVectorValues;\n-import org.apache.lucene.util.quantization.QuantizedVectorsReader;\n-import org.apache.lucene.util.quantization.ScalarQuantizer;\n-import org.elasticsearch.core.SuppressForbidden;\n-\n-import java.io.IOException;\n-import java.util.Map;\n-\n-import static org.apache.lucene.codecs.lucene99.Lucene99HnswVectorsReader.readSimilarityFunction;\n-import static org.apache.lucene.codecs.lucene99.Lucene99HnswVectorsReader.readVectorEncoding;\n-\n-/**\n- * Copied from Lucene 10.3.\n- */\n-@SuppressForbidden(reason = \"Lucene classes\")\n-final class Lucene99ScalarQuantizedVectorsReader extends FlatVectorsReader implements QuantizedVectorsReader {\n-\n-    private static final long SHALLOW_SIZE = RamUsageEstimator.shallowSizeOfInstance(Lucene99ScalarQuantizedVectorsReader.class);\n-\n-    static final int VERSION_START = 0;\n-    static final int VERSION_ADD_BITS = 1;\n-    static final int VERSION_CURRENT = VERSION_ADD_BITS;\n-    static final String META_CODEC_NAME = \"Lucene99ScalarQuantizedVectorsFormatMeta\";\n-    static final String VECTOR_DATA_CODEC_NAME = \"Lucene99ScalarQuantizedVectorsFormatData\";\n-    static final String META_EXTENSION = \"vemq\";\n-    static final String VECTOR_DATA_EXTENSION = \"veq\";\n-\n-    /** Dynamic confidence interval */\n-    public static final float DYNAMIC_CONFIDENCE_INTERVAL = 0f;\n-\n-    private final IntObjectHashMap<FieldEntry> fields = new IntObjectHashMap<>();\n-    private final IndexInput quantizedVectorData;\n-    private final FlatVectorsReader rawVectorsReader;\n-    private final FieldInfos fieldInfos;\n-\n-    Lucene99ScalarQuantizedVectorsReader(SegmentReadState state, FlatVectorsReader rawVectorsReader, FlatVectorsScorer scorer)\n-        throws IOException {\n-        super(scorer);\n-        this.rawVectorsReader = rawVectorsReader;\n-        this.fieldInfos = state.fieldInfos;\n-        int versionMeta = -1;\n-        String metaFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, META_EXTENSION);\n-        boolean success = false;\n-        try (ChecksumIndexInput meta = state.directory.openChecksumInput(metaFileName)) {\n-            Throwable priorE = null;\n-            try {\n-                versionMeta = CodecUtil.checkIndexHeader(\n-                    meta,\n-                    META_CODEC_NAME,\n-                    VERSION_START,\n-                    VERSION_CURRENT,\n-                    state.segmentInfo.getId(),\n-                    state.segmentSuffix\n-                );\n-                readFields(meta, versionMeta, state.fieldInfos);\n-            } catch (Throwable exception) {\n-                priorE = exception;\n-            } finally {\n-                CodecUtil.checkFooter(meta, priorE);\n-            }\n-            quantizedVectorData = openDataInput(\n-                state,\n-                versionMeta,\n-                VECTOR_DATA_EXTENSION,\n-                VECTOR_DATA_CODEC_NAME,\n-                // Quantized vectors are accessed randomly from their node ID stored in the HNSW\n-                // graph.\n-                state.context.withHints(FileTypeHint.DATA, FileDataHint.KNN_VECTORS, DataAccessHint.RANDOM)\n-            );\n-            success = true;\n-        } finally {\n-            if (success == false) {\n-                IOUtils.closeWhileHandlingException(this);\n-            }\n-        }\n-    }\n-\n-    private void readFields(ChecksumIndexInput meta, int versionMeta, FieldInfos infos) throws IOException {\n-        for (int fieldNumber = meta.readInt(); fieldNumber != -1; fieldNumber = meta.readInt()) {\n-            FieldInfo info = infos.fieldInfo(fieldNumber);\n-            if (info == null) {\n-                throw new CorruptIndexException(\"Invalid field number: \" + fieldNumber, meta);\n-            }\n-            FieldEntry fieldEntry = readField(meta, versionMeta, info);\n-            validateFieldEntry(info, fieldEntry);\n-            fields.put(info.number, fieldEntry);\n-        }\n-    }\n-\n-    static void validateFieldEntry(FieldInfo info, FieldEntry fieldEntry) {\n-        int dimension = info.getVectorDimension();\n-        if (dimension != fieldEntry.dimension) {\n-            throw new IllegalStateException(\n-                \"Inconsistent vector dimension for field=\\\"\" + info.name + \"\\\"; \" + dimension + \" != \" + fieldEntry.dimension\n-            );\n-        }\n-\n-        final long quantizedVectorBytes;\n-        if (fieldEntry.bits <= 4 && fieldEntry.compress) {\n-            // two dimensions -> one byte\n-            quantizedVectorBytes = ((dimension + 1) >> 1) + Float.BYTES;\n-        } else {\n-            // one dimension -> one byte\n-            quantizedVectorBytes = dimension + Float.BYTES;\n-        }\n-        long numQuantizedVectorBytes = Math.multiplyExact(quantizedVectorBytes, fieldEntry.size);\n-        if (numQuantizedVectorBytes != fieldEntry.vectorDataLength) {\n-            throw new IllegalStateException(\n-                \"Quantized vector data length \"\n-                    + fieldEntry.vectorDataLength\n-                    + \" not matching size=\"\n-                    + fieldEntry.size\n-                    + \" * (dim=\"\n-                    + dimension\n-                    + \" + 4)\"\n-                    + \" = \"\n-                    + numQuantizedVectorBytes\n-            );\n-        }\n-    }\n-\n-    @Override\n-    public void checkIntegrity() throws IOException {\n-        rawVectorsReader.checkIntegrity();\n-        CodecUtil.checksumEntireFile(quantizedVectorData);\n-    }\n-\n-    private FieldEntry getFieldEntry(String field) {\n-        final FieldInfo info = fieldInfos.fieldInfo(field);\n-        final FieldEntry fieldEntry;\n-        if (info == null || (fieldEntry = fields.get(info.number)) == null) {\n-            throw new IllegalArgumentException(\"field=\\\"\" + field + \"\\\" not found\");\n-        }\n-        if (fieldEntry.vectorEncoding != VectorEncoding.FLOAT32) {\n-            throw new IllegalArgumentException(\n-                \"field=\\\"\" + field + \"\\\" is encoded as: \" + fieldEntry.vectorEncoding + \" expected: \" + VectorEncoding.FLOAT32\n-            );\n-        }\n-        return fieldEntry;\n-    }\n-\n-    @Override\n-    public FloatVectorValues getFloatVectorValues(String field) throws IOException {\n-        final FieldEntry fieldEntry = getFieldEntry(field);\n-        final FloatVectorValues rawVectorValues = rawVectorsReader.getFloatVectorValues(field);\n-        OffHeapQuantizedByteVectorValues quantizedByteVectorValues = OffHeapQuantizedByteVectorValues.load(\n-            fieldEntry.ordToDoc,\n-            fieldEntry.dimension,\n-            fieldEntry.size,\n-            fieldEntry.scalarQuantizer,\n-            fieldEntry.similarityFunction,\n-            vectorScorer,\n-            fieldEntry.compress,\n-            fieldEntry.vectorDataOffset,\n-            fieldEntry.vectorDataLength,\n-            quantizedVectorData\n-        );\n-        return new QuantizedVectorValues(rawVectorValues, quantizedByteVectorValues);\n-    }\n-\n-    @Override\n-    public ByteVectorValues getByteVectorValues(String field) throws IOException {\n-        return rawVectorsReader.getByteVectorValues(field);\n-    }\n-\n-    private static IndexInput openDataInput(\n-        SegmentReadState state,\n-        int versionMeta,\n-        String fileExtension,\n-        String codecName,\n-        IOContext context\n-    ) throws IOException {\n-        String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, fileExtension);\n-        IndexInput in = state.directory.openInput(fileName, context);\n-        boolean success = false;\n-        try {\n-            int versionVectorData = CodecUtil.checkIndexHeader(\n-                in,\n-                codecName,\n-                VERSION_START,\n-                VERSION_CURRENT,\n-                state.segmentInfo.getId(),\n-                state.segmentSuffix\n-            );\n-            if (versionMeta != versionVectorData) {\n-                throw new CorruptIndexException(\n-                    \"Format versions mismatch: meta=\" + versionMeta + \", \" + codecName + \"=\" + versionVectorData,\n-                    in\n-                );\n-            }\n-            CodecUtil.retrieveChecksum(in);\n-            success = true;\n-            return in;\n-        } finally {\n-            if (success == false) {\n-                IOUtils.closeWhileHandlingException(in);\n-            }\n-        }\n-    }\n-\n-    @Override\n-    public RandomVectorScorer getRandomVectorScorer(String field, float[] target) throws IOException {\n-        final FieldEntry fieldEntry = getFieldEntry(field);\n-        if (fieldEntry.scalarQuantizer == null) {\n-            return rawVectorsReader.getRandomVectorScorer(field, target);\n-        }\n-        OffHeapQuantizedByteVectorValues vectorValues = OffHeapQuantizedByteVectorValues.load(\n-            fieldEntry.ordToDoc,\n-            fieldEntry.dimension,\n-            fieldEntry.size,\n-            fieldEntry.scalarQuantizer,\n-            fieldEntry.similarityFunction,\n-            vectorScorer,\n-            fieldEntry.compress,\n-            fieldEntry.vectorDataOffset,\n-            fieldEntry.vectorDataLength,\n-            quantizedVectorData\n-        );\n-        return vectorScorer.getRandomVectorScorer(fieldEntry.similarityFunction, vectorValues, target);\n-    }\n-\n-    @Override\n-    public RandomVectorScorer getRandomVectorScorer(String field, byte[] target) throws IOException {\n-        return rawVectorsReader.getRandomVectorScorer(field, target);\n-    }\n-\n-    @Override\n-    public void close() throws IOException {\n-        IOUtils.close(quantizedVectorData, rawVectorsReader);\n-    }\n-\n-    @Override\n-    public long ramBytesUsed() {\n-        return SHALLOW_SIZE + fields.ramBytesUsed() + rawVectorsReader.ramBytesUsed();\n-    }\n-\n-    @Override\n-    public Map<String, Long> getOffHeapByteSize(FieldInfo fieldInfo) {\n-        var raw = rawVectorsReader.getOffHeapByteSize(fieldInfo);\n-        var fieldEntry = fields.get(fieldInfo.number);\n-        if (fieldEntry == null) {\n-            assert fieldInfo.getVectorEncoding() == VectorEncoding.BYTE;\n-            return raw;\n-        }\n-        var quant = Map.of(VECTOR_DATA_EXTENSION, fieldEntry.vectorDataLength());\n-        return KnnVectorsReader.mergeOffHeapByteSizeMaps(raw, quant);\n-    }\n-\n-    private FieldEntry readField(IndexInput input, int versionMeta, FieldInfo info) throws IOException {\n-        VectorEncoding vectorEncoding = readVectorEncoding(input);\n-        VectorSimilarityFunction similarityFunction = readSimilarityFunction(input);\n-        if (similarityFunction != info.getVectorSimilarityFunction()) {\n-            throw new IllegalStateException(\n-                \"Inconsistent vector similarity function for field=\\\"\"\n-                    + info.name\n-                    + \"\\\"; \"\n-                    + similarityFunction\n-                    + \" != \"\n-                    + info.getVectorSimilarityFunction()\n-            );\n-        }\n-        return FieldEntry.create(input, versionMeta, vectorEncoding, info.getVectorSimilarityFunction());\n-    }\n-\n-    @Override\n-    public QuantizedByteVectorValues getQuantizedVectorValues(String field) throws IOException {\n-        final FieldEntry fieldEntry = getFieldEntry(field);\n-        return OffHeapQuantizedByteVectorValues.load(\n-            fieldEntry.ordToDoc,\n-            fieldEntry.dimension,\n-            fieldEntry.size,\n-            fieldEntry.scalarQuantizer,\n-            fieldEntry.similarityFunction,\n-            vectorScorer,\n-            fieldEntry.compress,\n-            fieldEntry.vectorDataOffset,\n-            fieldEntry.vectorDataLength,\n-            quantizedVectorData\n-        );\n-    }\n-\n-    @Override\n-    public ScalarQuantizer getQuantizationState(String field) {\n-        final FieldEntry fieldEntry = getFieldEntry(field);\n-        return fieldEntry.scalarQuantizer;\n-    }\n-\n-    private record FieldEntry(\n-        VectorSimilarityFunction similarityFunction,\n-        VectorEncoding vectorEncoding,\n-        int dimension,\n-        long vectorDataOffset,\n-        long vectorDataLength,\n-        ScalarQuantizer scalarQuantizer,\n-        int size,\n-        byte bits,\n-        boolean compress,\n-        OrdToDocDISIReaderConfiguration ordToDoc\n-    ) {\n-\n-        static FieldEntry create(\n-            IndexInput input,\n-            int versionMeta,\n-            VectorEncoding vectorEncoding,\n-            VectorSimilarityFunction similarityFunction\n-        ) throws IOException {\n-            final var vectorDataOffset = input.readVLong();\n-            final var vectorDataLength = input.readVLong();\n-            final var dimension = input.readVInt();\n-            final var size = input.readInt();\n-            final ScalarQuantizer scalarQuantizer;\n-            final byte bits;\n-            final boolean compress;\n-            if (size > 0) {\n-                if (versionMeta < VERSION_ADD_BITS) {\n-                    int floatBits = input.readInt(); // confidenceInterval, unused\n-                    if (floatBits == -1) { // indicates a null confidence interval\n-                        throw new CorruptIndexException(\"Missing confidence interval for scalar quantizer\", input);\n-                    }\n-                    float confidenceInterval = Float.intBitsToFloat(floatBits);\n-                    // indicates a dynamic interval, which shouldn't be provided in this version\n-                    if (confidenceInterval == DYNAMIC_CONFIDENCE_INTERVAL) {\n-                        throw new CorruptIndexException(\"Invalid confidence interval for scalar quantizer: \" + confidenceInterval, input);\n-                    }\n-                    bits = (byte) 7;\n-                    compress = false;\n-                    float minQuantile = Float.intBitsToFloat(input.readInt());\n-                    float maxQuantile = Float.intBitsToFloat(input.readInt());\n-                    scalarQuantizer = new ScalarQuantizer(minQuantile, maxQuantile, (byte) 7);\n-                } else {\n-                    input.readInt(); // confidenceInterval, unused\n-                    bits = input.readByte();\n-                    compress = input.readByte() == 1;\n-                    float minQuantile = Float.intBitsToFloat(input.readInt());\n-                    float maxQuantile = Float.intBitsToFloat(input.readInt());\n-                    scalarQuantizer = new ScalarQuantizer(minQuantile, maxQuantile, bits);\n-                }\n-            } else {\n-                scalarQuantizer = null;\n-                bits = (byte) 7;\n-                compress = false;\n-            }\n-            final var ordToDoc = OrdToDocDISIReaderConfiguration.fromStoredMeta(input, size);\n-            return new FieldEntry(\n-                similarityFunction,\n-                vectorEncoding,\n-                dimension,\n-                vectorDataOffset,\n-                vectorDataLength,\n-                scalarQuantizer,\n-                size,\n-                bits,\n-                compress,\n-                ordToDoc\n-            );\n-        }\n-    }\n-\n-    private static final class QuantizedVectorValues extends FloatVectorValues {\n-        private final FloatVectorValues rawVectorValues;\n-        private final QuantizedByteVectorValues quantizedVectorValues;\n-\n-        QuantizedVectorValues(FloatVectorValues rawVectorValues, QuantizedByteVectorValues quantizedVectorValues) {\n-            this.rawVectorValues = rawVectorValues;\n-            this.quantizedVectorValues = quantizedVectorValues;\n-        }\n-\n-        @Override\n-        public int dimension() {\n-            return rawVectorValues.dimension();\n-        }\n-\n-        @Override\n-        public int size() {\n-            return rawVectorValues.size();\n-        }\n-\n-        @Override\n-        public float[] vectorValue(int ord) throws IOException {\n-            return rawVectorValues.vectorValue(ord);\n-        }\n-\n-        @Override\n-        public int ordToDoc(int ord) {\n-            return rawVectorValues.ordToDoc(ord);\n-        }\n-\n-        @Override\n-        public QuantizedVectorValues copy() throws IOException {\n-            return new QuantizedVectorValues(rawVectorValues.copy(), quantizedVectorValues.copy());\n-        }\n-\n-        @Override\n-        public VectorScorer scorer(float[] query) throws IOException {\n-            return quantizedVectorValues.scorer(query);\n-        }\n-\n-        @Override\n-        public VectorScorer rescorer(float[] query) throws IOException {\n-            return rawVectorValues.rescorer(query);\n-        }\n-\n-        @Override\n-        public DocIndexIterator iterator() {\n-            return rawVectorValues.iterator();\n-        }\n-    }\n-}"
    }
  ],
  "diff": "diff --git a/server/src/main/java/org/elasticsearch/index/codec/vectors/ES814ScalarQuantizedVectorsFormat.java b/server/src/main/java/org/elasticsearch/index/codec/vectors/ES814ScalarQuantizedVectorsFormat.java\nindex 692ccdfa9222c..dd125b68d292a 100644\n--- a/server/src/main/java/org/elasticsearch/index/codec/vectors/ES814ScalarQuantizedVectorsFormat.java\n+++ b/server/src/main/java/org/elasticsearch/index/codec/vectors/ES814ScalarQuantizedVectorsFormat.java\n@@ -9,6 +9,7 @@\n \n package org.elasticsearch.index.codec.vectors;\n \n+import org.apache.lucene.backward_codecs.lucene99.Lucene99ScalarQuantizedVectorsReader;\n import org.apache.lucene.codecs.hnsw.FlatFieldVectorsWriter;\n import org.apache.lucene.codecs.hnsw.FlatVectorScorerUtil;\n import org.apache.lucene.codecs.hnsw.FlatVectorsFormat;\ndiff --git a/server/src/main/java/org/elasticsearch/index/codec/vectors/Lucene99ScalarQuantizedVectorsReader.java b/server/src/main/java/org/elasticsearch/index/codec/vectors/Lucene99ScalarQuantizedVectorsReader.java\ndeleted file mode 100644\nindex 9c0e855faf6ad..0000000000000\n--- a/server/src/main/java/org/elasticsearch/index/codec/vectors/Lucene99ScalarQuantizedVectorsReader.java\n+++ /dev/null\n@@ -1,455 +0,0 @@\n-/*\n- * @notice\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- *\n- * Modifications copyright (C) 2024 Elasticsearch B.V.\n- */\n-\n-package org.elasticsearch.index.codec.vectors;\n-\n-import org.apache.lucene.codecs.CodecUtil;\n-import org.apache.lucene.codecs.KnnVectorsReader;\n-import org.apache.lucene.codecs.hnsw.FlatVectorsReader;\n-import org.apache.lucene.codecs.hnsw.FlatVectorsScorer;\n-import org.apache.lucene.codecs.lucene95.OrdToDocDISIReaderConfiguration;\n-import org.apache.lucene.index.ByteVectorValues;\n-import org.apache.lucene.index.CorruptIndexException;\n-import org.apache.lucene.index.FieldInfo;\n-import org.apache.lucene.index.FieldInfos;\n-import org.apache.lucene.index.FloatVectorValues;\n-import org.apache.lucene.index.IndexFileNames;\n-import org.apache.lucene.index.SegmentReadState;\n-import org.apache.lucene.index.VectorEncoding;\n-import org.apache.lucene.index.VectorSimilarityFunction;\n-import org.apache.lucene.internal.hppc.IntObjectHashMap;\n-import org.apache.lucene.search.VectorScorer;\n-import org.apache.lucene.store.ChecksumIndexInput;\n-import org.apache.lucene.store.DataAccessHint;\n-import org.apache.lucene.store.FileDataHint;\n-import org.apache.lucene.store.FileTypeHint;\n-import org.apache.lucene.store.IOContext;\n-import org.apache.lucene.store.IndexInput;\n-import org.apache.lucene.util.IOUtils;\n-import org.apache.lucene.util.RamUsageEstimator;\n-import org.apache.lucene.util.hnsw.RandomVectorScorer;\n-import org.apache.lucene.util.quantization.QuantizedByteVectorValues;\n-import org.apache.lucene.util.quantization.QuantizedVectorsReader;\n-import org.apache.lucene.util.quantization.ScalarQuantizer;\n-import org.elasticsearch.core.SuppressForbidden;\n-\n-import java.io.IOException;\n-import java.util.Map;\n-\n-import static org.apache.lucene.codecs.lucene99.Lucene99HnswVectorsReader.readSimilarityFunction;\n-import static org.apache.lucene.codecs.lucene99.Lucene99HnswVectorsReader.readVectorEncoding;\n-\n-/**\n- * Copied from Lucene 10.3.\n- */\n-@SuppressForbidden(reason = \"Lucene classes\")\n-final class Lucene99ScalarQuantizedVectorsReader extends FlatVectorsReader implements QuantizedVectorsReader {\n-\n-    private static final long SHALLOW_SIZE = RamUsageEstimator.shallowSizeOfInstance(Lucene99ScalarQuantizedVectorsReader.class);\n-\n-    static final int VERSION_START = 0;\n-    static final int VERSION_ADD_BITS = 1;\n-    static final int VERSION_CURRENT = VERSION_ADD_BITS;\n-    static final String META_CODEC_NAME = \"Lucene99ScalarQuantizedVectorsFormatMeta\";\n-    static final String VECTOR_DATA_CODEC_NAME = \"Lucene99ScalarQuantizedVectorsFormatData\";\n-    static final String META_EXTENSION = \"vemq\";\n-    static final String VECTOR_DATA_EXTENSION = \"veq\";\n-\n-    /** Dynamic confidence interval */\n-    public static final float DYNAMIC_CONFIDENCE_INTERVAL = 0f;\n-\n-    private final IntObjectHashMap<FieldEntry> fields = new IntObjectHashMap<>();\n-    private final IndexInput quantizedVectorData;\n-    private final FlatVectorsReader rawVectorsReader;\n-    private final FieldInfos fieldInfos;\n-\n-    Lucene99ScalarQuantizedVectorsReader(SegmentReadState state, FlatVectorsReader rawVectorsReader, FlatVectorsScorer scorer)\n-        throws IOException {\n-        super(scorer);\n-        this.rawVectorsReader = rawVectorsReader;\n-        this.fieldInfos = state.fieldInfos;\n-        int versionMeta = -1;\n-        String metaFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, META_EXTENSION);\n-        boolean success = false;\n-        try (ChecksumIndexInput meta = state.directory.openChecksumInput(metaFileName)) {\n-            Throwable priorE = null;\n-            try {\n-                versionMeta = CodecUtil.checkIndexHeader(\n-                    meta,\n-                    META_CODEC_NAME,\n-                    VERSION_START,\n-                    VERSION_CURRENT,\n-                    state.segmentInfo.getId(),\n-                    state.segmentSuffix\n-                );\n-                readFields(meta, versionMeta, state.fieldInfos);\n-            } catch (Throwable exception) {\n-                priorE = exception;\n-            } finally {\n-                CodecUtil.checkFooter(meta, priorE);\n-            }\n-            quantizedVectorData = openDataInput(\n-                state,\n-                versionMeta,\n-                VECTOR_DATA_EXTENSION,\n-                VECTOR_DATA_CODEC_NAME,\n-                // Quantized vectors are accessed randomly from their node ID stored in the HNSW\n-                // graph.\n-                state.context.withHints(FileTypeHint.DATA, FileDataHint.KNN_VECTORS, DataAccessHint.RANDOM)\n-            );\n-            success = true;\n-        } finally {\n-            if (success == false) {\n-                IOUtils.closeWhileHandlingException(this);\n-            }\n-        }\n-    }\n-\n-    private void readFields(ChecksumIndexInput meta, int versionMeta, FieldInfos infos) throws IOException {\n-        for (int fieldNumber = meta.readInt(); fieldNumber != -1; fieldNumber = meta.readInt()) {\n-            FieldInfo info = infos.fieldInfo(fieldNumber);\n-            if (info == null) {\n-                throw new CorruptIndexException(\"Invalid field number: \" + fieldNumber, meta);\n-            }\n-            FieldEntry fieldEntry = readField(meta, versionMeta, info);\n-            validateFieldEntry(info, fieldEntry);\n-            fields.put(info.number, fieldEntry);\n-        }\n-    }\n-\n-    static void validateFieldEntry(FieldInfo info, FieldEntry fieldEntry) {\n-        int dimension = info.getVectorDimension();\n-        if (dimension != fieldEntry.dimension) {\n-            throw new IllegalStateException(\n-                \"Inconsistent vector dimension for field=\\\"\" + info.name + \"\\\"; \" + dimension + \" != \" + fieldEntry.dimension\n-            );\n-        }\n-\n-        final long quantizedVectorBytes;\n-        if (fieldEntry.bits <= 4 && fieldEntry.compress) {\n-            // two dimensions -> one byte\n-            quantizedVectorBytes = ((dimension + 1) >> 1) + Float.BYTES;\n-        } else {\n-            // one dimension -> one byte\n-            quantizedVectorBytes = dimension + Float.BYTES;\n-        }\n-        long numQuantizedVectorBytes = Math.multiplyExact(quantizedVectorBytes, fieldEntry.size);\n-        if (numQuantizedVectorBytes != fieldEntry.vectorDataLength) {\n-            throw new IllegalStateException(\n-                \"Quantized vector data length \"\n-                    + fieldEntry.vectorDataLength\n-                    + \" not matching size=\"\n-                    + fieldEntry.size\n-                    + \" * (dim=\"\n-                    + dimension\n-                    + \" + 4)\"\n-                    + \" = \"\n-                    + numQuantizedVectorBytes\n-            );\n-        }\n-    }\n-\n-    @Override\n-    public void checkIntegrity() throws IOException {\n-        rawVectorsReader.checkIntegrity();\n-        CodecUtil.checksumEntireFile(quantizedVectorData);\n-    }\n-\n-    private FieldEntry getFieldEntry(String field) {\n-        final FieldInfo info = fieldInfos.fieldInfo(field);\n-        final FieldEntry fieldEntry;\n-        if (info == null || (fieldEntry = fields.get(info.number)) == null) {\n-            throw new IllegalArgumentException(\"field=\\\"\" + field + \"\\\" not found\");\n-        }\n-        if (fieldEntry.vectorEncoding != VectorEncoding.FLOAT32) {\n-            throw new IllegalArgumentException(\n-                \"field=\\\"\" + field + \"\\\" is encoded as: \" + fieldEntry.vectorEncoding + \" expected: \" + VectorEncoding.FLOAT32\n-            );\n-        }\n-        return fieldEntry;\n-    }\n-\n-    @Override\n-    public FloatVectorValues getFloatVectorValues(String field) throws IOException {\n-        final FieldEntry fieldEntry = getFieldEntry(field);\n-        final FloatVectorValues rawVectorValues = rawVectorsReader.getFloatVectorValues(field);\n-        OffHeapQuantizedByteVectorValues quantizedByteVectorValues = OffHeapQuantizedByteVectorValues.load(\n-            fieldEntry.ordToDoc,\n-            fieldEntry.dimension,\n-            fieldEntry.size,\n-            fieldEntry.scalarQuantizer,\n-            fieldEntry.similarityFunction,\n-            vectorScorer,\n-            fieldEntry.compress,\n-            fieldEntry.vectorDataOffset,\n-            fieldEntry.vectorDataLength,\n-            quantizedVectorData\n-        );\n-        return new QuantizedVectorValues(rawVectorValues, quantizedByteVectorValues);\n-    }\n-\n-    @Override\n-    public ByteVectorValues getByteVectorValues(String field) throws IOException {\n-        return rawVectorsReader.getByteVectorValues(field);\n-    }\n-\n-    private static IndexInput openDataInput(\n-        SegmentReadState state,\n-        int versionMeta,\n-        String fileExtension,\n-        String codecName,\n-        IOContext context\n-    ) throws IOException {\n-        String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, fileExtension);\n-        IndexInput in = state.directory.openInput(fileName, context);\n-        boolean success = false;\n-        try {\n-            int versionVectorData = CodecUtil.checkIndexHeader(\n-                in,\n-                codecName,\n-                VERSION_START,\n-                VERSION_CURRENT,\n-                state.segmentInfo.getId(),\n-                state.segmentSuffix\n-            );\n-            if (versionMeta != versionVectorData) {\n-                throw new CorruptIndexException(\n-                    \"Format versions mismatch: meta=\" + versionMeta + \", \" + codecName + \"=\" + versionVectorData,\n-                    in\n-                );\n-            }\n-            CodecUtil.retrieveChecksum(in);\n-            success = true;\n-            return in;\n-        } finally {\n-            if (success == false) {\n-                IOUtils.closeWhileHandlingException(in);\n-            }\n-        }\n-    }\n-\n-    @Override\n-    public RandomVectorScorer getRandomVectorScorer(String field, float[] target) throws IOException {\n-        final FieldEntry fieldEntry = getFieldEntry(field);\n-        if (fieldEntry.scalarQuantizer == null) {\n-            return rawVectorsReader.getRandomVectorScorer(field, target);\n-        }\n-        OffHeapQuantizedByteVectorValues vectorValues = OffHeapQuantizedByteVectorValues.load(\n-            fieldEntry.ordToDoc,\n-            fieldEntry.dimension,\n-            fieldEntry.size,\n-            fieldEntry.scalarQuantizer,\n-            fieldEntry.similarityFunction,\n-            vectorScorer,\n-            fieldEntry.compress,\n-            fieldEntry.vectorDataOffset,\n-            fieldEntry.vectorDataLength,\n-            quantizedVectorData\n-        );\n-        return vectorScorer.getRandomVectorScorer(fieldEntry.similarityFunction, vectorValues, target);\n-    }\n-\n-    @Override\n-    public RandomVectorScorer getRandomVectorScorer(String field, byte[] target) throws IOException {\n-        return rawVectorsReader.getRandomVectorScorer(field, target);\n-    }\n-\n-    @Override\n-    public void close() throws IOException {\n-        IOUtils.close(quantizedVectorData, rawVectorsReader);\n-    }\n-\n-    @Override\n-    public long ramBytesUsed() {\n-        return SHALLOW_SIZE + fields.ramBytesUsed() + rawVectorsReader.ramBytesUsed();\n-    }\n-\n-    @Override\n-    public Map<String, Long> getOffHeapByteSize(FieldInfo fieldInfo) {\n-        var raw = rawVectorsReader.getOffHeapByteSize(fieldInfo);\n-        var fieldEntry = fields.get(fieldInfo.number);\n-        if (fieldEntry == null) {\n-            assert fieldInfo.getVectorEncoding() == VectorEncoding.BYTE;\n-            return raw;\n-        }\n-        var quant = Map.of(VECTOR_DATA_EXTENSION, fieldEntry.vectorDataLength());\n-        return KnnVectorsReader.mergeOffHeapByteSizeMaps(raw, quant);\n-    }\n-\n-    private FieldEntry readField(IndexInput input, int versionMeta, FieldInfo info) throws IOException {\n-        VectorEncoding vectorEncoding = readVectorEncoding(input);\n-        VectorSimilarityFunction similarityFunction = readSimilarityFunction(input);\n-        if (similarityFunction != info.getVectorSimilarityFunction()) {\n-            throw new IllegalStateException(\n-                \"Inconsistent vector similarity function for field=\\\"\"\n-                    + info.name\n-                    + \"\\\"; \"\n-                    + similarityFunction\n-                    + \" != \"\n-                    + info.getVectorSimilarityFunction()\n-            );\n-        }\n-        return FieldEntry.create(input, versionMeta, vectorEncoding, info.getVectorSimilarityFunction());\n-    }\n-\n-    @Override\n-    public QuantizedByteVectorValues getQuantizedVectorValues(String field) throws IOException {\n-        final FieldEntry fieldEntry = getFieldEntry(field);\n-        return OffHeapQuantizedByteVectorValues.load(\n-            fieldEntry.ordToDoc,\n-            fieldEntry.dimension,\n-            fieldEntry.size,\n-            fieldEntry.scalarQuantizer,\n-            fieldEntry.similarityFunction,\n-            vectorScorer,\n-            fieldEntry.compress,\n-            fieldEntry.vectorDataOffset,\n-            fieldEntry.vectorDataLength,\n-            quantizedVectorData\n-        );\n-    }\n-\n-    @Override\n-    public ScalarQuantizer getQuantizationState(String field) {\n-        final FieldEntry fieldEntry = getFieldEntry(field);\n-        return fieldEntry.scalarQuantizer;\n-    }\n-\n-    private record FieldEntry(\n-        VectorSimilarityFunction similarityFunction,\n-        VectorEncoding vectorEncoding,\n-        int dimension,\n-        long vectorDataOffset,\n-        long vectorDataLength,\n-        ScalarQuantizer scalarQuantizer,\n-        int size,\n-        byte bits,\n-        boolean compress,\n-        OrdToDocDISIReaderConfiguration ordToDoc\n-    ) {\n-\n-        static FieldEntry create(\n-            IndexInput input,\n-            int versionMeta,\n-            VectorEncoding vectorEncoding,\n-            VectorSimilarityFunction similarityFunction\n-        ) throws IOException {\n-            final var vectorDataOffset = input.readVLong();\n-            final var vectorDataLength = input.readVLong();\n-            final var dimension = input.readVInt();\n-            final var size = input.readInt();\n-            final ScalarQuantizer scalarQuantizer;\n-            final byte bits;\n-            final boolean compress;\n-            if (size > 0) {\n-                if (versionMeta < VERSION_ADD_BITS) {\n-                    int floatBits = input.readInt(); // confidenceInterval, unused\n-                    if (floatBits == -1) { // indicates a null confidence interval\n-                        throw new CorruptIndexException(\"Missing confidence interval for scalar quantizer\", input);\n-                    }\n-                    float confidenceInterval = Float.intBitsToFloat(floatBits);\n-                    // indicates a dynamic interval, which shouldn't be provided in this version\n-                    if (confidenceInterval == DYNAMIC_CONFIDENCE_INTERVAL) {\n-                        throw new CorruptIndexException(\"Invalid confidence interval for scalar quantizer: \" + confidenceInterval, input);\n-                    }\n-                    bits = (byte) 7;\n-                    compress = false;\n-                    float minQuantile = Float.intBitsToFloat(input.readInt());\n-                    float maxQuantile = Float.intBitsToFloat(input.readInt());\n-                    scalarQuantizer = new ScalarQuantizer(minQuantile, maxQuantile, (byte) 7);\n-                } else {\n-                    input.readInt(); // confidenceInterval, unused\n-                    bits = input.readByte();\n-                    compress = input.readByte() == 1;\n-                    float minQuantile = Float.intBitsToFloat(input.readInt());\n-                    float maxQuantile = Float.intBitsToFloat(input.readInt());\n-                    scalarQuantizer = new ScalarQuantizer(minQuantile, maxQuantile, bits);\n-                }\n-            } else {\n-                scalarQuantizer = null;\n-                bits = (byte) 7;\n-                compress = false;\n-            }\n-            final var ordToDoc = OrdToDocDISIReaderConfiguration.fromStoredMeta(input, size);\n-            return new FieldEntry(\n-                similarityFunction,\n-                vectorEncoding,\n-                dimension,\n-                vectorDataOffset,\n-                vectorDataLength,\n-                scalarQuantizer,\n-                size,\n-                bits,\n-                compress,\n-                ordToDoc\n-            );\n-        }\n-    }\n-\n-    private static final class QuantizedVectorValues extends FloatVectorValues {\n-        private final FloatVectorValues rawVectorValues;\n-        private final QuantizedByteVectorValues quantizedVectorValues;\n-\n-        QuantizedVectorValues(FloatVectorValues rawVectorValues, QuantizedByteVectorValues quantizedVectorValues) {\n-            this.rawVectorValues = rawVectorValues;\n-            this.quantizedVectorValues = quantizedVectorValues;\n-        }\n-\n-        @Override\n-        public int dimension() {\n-            return rawVectorValues.dimension();\n-        }\n-\n-        @Override\n-        public int size() {\n-            return rawVectorValues.size();\n-        }\n-\n-        @Override\n-        public float[] vectorValue(int ord) throws IOException {\n-            return rawVectorValues.vectorValue(ord);\n-        }\n-\n-        @Override\n-        public int ordToDoc(int ord) {\n-            return rawVectorValues.ordToDoc(ord);\n-        }\n-\n-        @Override\n-        public QuantizedVectorValues copy() throws IOException {\n-            return new QuantizedVectorValues(rawVectorValues.copy(), quantizedVectorValues.copy());\n-        }\n-\n-        @Override\n-        public VectorScorer scorer(float[] query) throws IOException {\n-            return quantizedVectorValues.scorer(query);\n-        }\n-\n-        @Override\n-        public VectorScorer rescorer(float[] query) throws IOException {\n-            return rawVectorValues.rescorer(query);\n-        }\n-\n-        @Override\n-        public DocIndexIterator iterator() {\n-            return rawVectorValues.iterator();\n-        }\n-    }\n-}\n",
  "additions": 1,
  "deletions": 455,
  "changed_files": 2,
  "url": "https://github.com/elastic/elasticsearch/pull/137079",
  "mined_at": "2025-10-25T13:20:34.008650"
}