{
  "id": 136780,
  "repository": "elastic/elasticsearch",
  "title": "Multi-relation support, a pre-requisite for views and sub-queries",
  "body": "This is extracted from the views prototype at https://github.com/elastic/elasticsearch/pull/134995. It provides the underlying support for multiple `FROM ...` commands within the same ES|QL query, something that both non-materialized views and subqueries require.\r\n\r\nA key feature of this work is that all `UnresolvedRelation` instances are treated equivalently, which means they all support CPS and CPS just as before. This implies that sub-queries using this will support CCS/CPS directly, and for views it means:\r\n* The underlying indexes within the view definitions will support CCS/CPS as if they were in the original FROM command\r\n* Views are strictly resolved in the coordinator of the local cluster, so that the indexes defined within the views can then be resolved using CCS/CPS rules as normal.\r\n\r\nFor reviewing this PR, it should be noted that most of the changes are in tests that had mistakes that went unnoticed because they only ever expected a single IndexPattern, and so could get away with mocking a single IndexResolution even if it was for a different index pattern than expressed in the test. The mismatch in index name between FROM and IndexResolution had no consequences. This is no longer possible since we need the IndexPattern to differentiate between different FROM commands. If you want to focus on the functional changes in this PR, look mostly at `EsqlSession`, `AnalyzerContext`, `Analyzer` and `EsqlCCSUtils`.",
  "state": "closed",
  "merged": true,
  "merged_at": "2025-10-23T15:37:14+00:00",
  "created_at": "2025-10-19T15:36:52+00:00",
  "updated_at": "2025-10-24T12:14:24+00:00",
  "author": "craigtaverner",
  "reviewers": [
    "craigtaverner",
    "idegtiarenko",
    "smalyshev",
    "fang-xing-esql"
  ],
  "base_sha": "c71e06222e1b018f6d054ab5a82e144683a14807",
  "head_sha": "c884f12df205702f5eb5acf1785f43f2c68304aa",
  "review_comments": [
    {
      "user": "fang-xing-esql",
      "state": "COMMENTED",
      "body": "The changes to `Analyzer`, `AnalyzerContext` and `PreAnalyzer` make sense to me. I applied the changes to the subquery PR, and subqueries can be resolved properly, thank you @craigtaverner ! \r\n\r\nThe changes to `EsqlSession` and `EsqlCCSUtils` also look fine to me.",
      "submitted_at": "2025-10-20T22:59:21+00:00"
    },
    {
      "user": "smalyshev",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T00:39:24+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T09:29:12+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T09:30:27+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T09:31:15+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T10:01:25+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T10:02:19+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T10:03:28+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T10:05:42+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T10:06:52+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T10:08:09+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T10:11:54+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T10:14:29+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T10:16:43+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-22T15:06:18+00:00"
    },
    {
      "user": "idegtiarenko",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T07:09:50+00:00"
    },
    {
      "user": "idegtiarenko",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T07:11:24+00:00"
    },
    {
      "user": "idegtiarenko",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T07:15:26+00:00"
    },
    {
      "user": "idegtiarenko",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T07:19:30+00:00"
    },
    {
      "user": "idegtiarenko",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T07:25:26+00:00"
    },
    {
      "user": "idegtiarenko",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T07:28:27+00:00"
    },
    {
      "user": "idegtiarenko",
      "state": "APPROVED",
      "body": "Left several minor comments.\nOverall üëç from index resolution point of view assuming some followups in the separate PRs.",
      "submitted_at": "2025-10-23T07:29:36+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T09:00:11+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T09:03:21+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T09:05:32+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T09:11:02+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T09:18:45+00:00"
    },
    {
      "user": "craigtaverner",
      "state": "COMMENTED",
      "body": "",
      "submitted_at": "2025-10-23T09:20:22+00:00"
    }
  ],
  "pr_comments": [
    {
      "user": "elasticsearchmachine",
      "body": "Pinging @elastic/es-analytical-engine (Team:Analytics)",
      "created_at": "2025-10-19T15:37:16+00:00"
    },
    {
      "user": "github-actions[bot]",
      "body": "## ‚ÑπÔ∏è Important: Docs version tagging\n\nüëã Thanks for updating the docs! Just a friendly reminder that our docs are now **cumulative**. This means all 9.x versions are documented on the same page and published off of the main branch, instead of creating separate pages for each minor version.\n\nWe use [applies_to tags](https://elastic.github.io/docs-builder/syntax/applies) to mark version-specific features and changes.\n\n<details>\n<summary>Expand for a quick overview</summary>\n\n### When to use applies_to tags:\n‚úÖ At the page level to indicate which products/deployments the content applies to (mandatory)\n‚úÖ When features change state (e.g. preview, ga) in a specific version\n‚úÖ When availability differs across deployments and environments\n\n### What NOT to do:\n‚ùå Don't remove or replace information that applies to an older version\n‚ùå Don't add new information that applies to a specific version without an applies_to tag\n‚ùå Don't forget that applies_to tags can be used at the page, section, and inline level\n</details>\n\n### ü§î Need help?\n- Check out the [cumulative docs guidelines](https://elastic.github.io/docs-builder/contribute/cumulative-docs/)\n- Reach out in the [#docs](https://elastic.slack.com/archives/C0JF80CJZ) Slack channel",
      "created_at": "2025-10-19T15:38:34+00:00"
    },
    {
      "user": "alex-spies",
      "body": "Heya, late to the party but I took a look at the changes to the min transport version propagation as that's brand new. That looks correct to me!",
      "created_at": "2025-10-24T12:14:24+00:00"
    }
  ],
  "files_changed": [
    {
      "filename": "benchmarks/src/main/java/org/elasticsearch/benchmark/_nightly/esql/QueryPlanningBenchmark.java",
      "status": "modified",
      "additions": 8,
      "deletions": 2,
      "changes": 10,
      "patch": "@@ -14,8 +14,13 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.index.IndexMode;\n import org.elasticsearch.license.XPackLicenseState;\n-import org.elasticsearch.xpack.esql.analysis.*;\n+import org.elasticsearch.xpack.esql.analysis.Analyzer;\n+import org.elasticsearch.xpack.esql.analysis.AnalyzerContext;\n+import org.elasticsearch.xpack.esql.analysis.AnalyzerSettings;\n+import org.elasticsearch.xpack.esql.analysis.EnrichResolution;\n+import org.elasticsearch.xpack.esql.analysis.Verifier;\n import org.elasticsearch.xpack.esql.core.expression.FoldContext;\n+import org.elasticsearch.xpack.esql.core.tree.Source;\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.core.util.DateUtils;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n@@ -26,6 +31,7 @@\n import org.elasticsearch.xpack.esql.optimizer.LogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n import org.elasticsearch.xpack.esql.parser.QueryParams;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n import org.elasticsearch.xpack.esql.plugin.QueryPragmas;\n import org.elasticsearch.xpack.esql.session.Configuration;\n@@ -108,7 +114,7 @@ public void setup() {\n             new AnalyzerContext(\n                 config,\n                 functionRegistry,\n-                IndexResolution.valid(esIndex),\n+                Map.of(new IndexPattern(Source.EMPTY, esIndex.name()), IndexResolution.valid(esIndex)),\n                 Map.of(),\n                 new EnrichResolution(),\n                 InferenceResolution.EMPTY,"
    },
    {
      "filename": "x-pack/plugin/esql/qa/server/src/main/java/org/elasticsearch/xpack/esql/qa/rest/EsqlSpecTestCase.java",
      "status": "modified",
      "additions": 49,
      "deletions": 13,
      "changes": 62,
      "patch": "@@ -51,6 +51,7 @@\n import java.util.Locale;\n import java.util.Map;\n import java.util.TreeMap;\n+import java.util.concurrent.Callable;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n import java.util.stream.LongStream;\n@@ -122,23 +123,59 @@ protected EsqlSpecTestCase(\n         this.mode = randomFrom(Mode.values());\n     }\n \n-    private static boolean dataLoaded = false;\n+    private static class Protected {\n+        private volatile boolean completed = false;\n+        private volatile boolean started = false;\n+        private volatile Throwable failure = null;\n+\n+        private void protectedBlock(Callable<Void> callable) {\n+            if (completed) {\n+                return;\n+            }\n+            // In case tests get run in parallel, we ensure only one setup is run, and other tests wait for this\n+            synchronized (this) {\n+                if (completed) {\n+                    return;\n+                }\n+                if (started) {\n+                    // Should only happen if a previous test setup failed, possibly with partial setup, let's fail fast the current test\n+                    if (failure != null) {\n+                        fail(failure, \"Previous test setup failed: \" + failure.getMessage());\n+                    }\n+                    fail(\"Previous test setup failed with unknown error\");\n+                }\n+                started = true;\n+                try {\n+                    callable.call();\n+                    completed = true;\n+                } catch (Throwable t) {\n+                    failure = t;\n+                    fail(failure, \"Current test setup failed: \" + failure.getMessage());\n+                }\n+            }\n+        }\n+\n+        private synchronized void reset() {\n+            completed = false;\n+            started = false;\n+            failure = null;\n+        }\n+    }\n+\n+    private static final Protected INGEST = new Protected();\n     protected static boolean testClustersOk = true;\n \n     @Before\n-    public void setup() throws IOException {\n+    public void setup() {\n         assumeTrue(\"test clusters were broken\", testClustersOk);\n-        boolean supportsLookup = supportsIndexModeLookup();\n-        boolean supportsSourceMapping = supportsSourceFieldMapping();\n-        boolean supportsInferenceTestService = supportsInferenceTestService();\n-        if (dataLoaded == false) {\n-            if (supportsInferenceTestService) {\n+        INGEST.protectedBlock(() -> {\n+            // Inference endpoints must be created before ingesting any datasets that rely on them (mapping of inference_id)\n+            if (supportsInferenceTestService()) {\n                 createInferenceEndpoints(adminClient());\n             }\n-\n-            loadDataSetIntoEs(client(), supportsLookup, supportsSourceMapping, supportsInferenceTestService);\n-            dataLoaded = true;\n-        }\n+            loadDataSetIntoEs(client(), supportsIndexModeLookup(), supportsSourceFieldMapping(), supportsInferenceTestService());\n+            return null;\n+        });\n     }\n \n     @AfterClass\n@@ -147,15 +184,14 @@ public static void wipeTestData() throws IOException {\n             return;\n         }\n         try {\n-            dataLoaded = false;\n             adminClient().performRequest(new Request(\"DELETE\", \"/*\"));\n         } catch (ResponseException e) {\n             // 404 here just means we had no indexes\n             if (e.getResponse().getStatusLine().getStatusCode() != 404) {\n                 throw e;\n             }\n         }\n-\n+        INGEST.reset();\n         deleteInferenceEndpoints(adminClient());\n     }\n "
    },
    {
      "filename": "x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/CsvTestsDataLoader.java",
      "status": "modified",
      "additions": 40,
      "deletions": 6,
      "changes": 46,
      "patch": "@@ -78,8 +78,9 @@ public class CsvTestsDataLoader {\n     private static final TestDataset LANGUAGES = new TestDataset(\"languages\");\n     private static final TestDataset LANGUAGES_LOOKUP = LANGUAGES.withIndex(\"languages_lookup\").withSetting(\"lookup-settings.json\");\n     private static final TestDataset LANGUAGES_NON_UNIQUE_KEY = new TestDataset(\"languages_non_unique_key\");\n-    private static final TestDataset LANGUAGES_LOOKUP_NON_UNIQUE_KEY = LANGUAGES_NON_UNIQUE_KEY.withIndex(\"languages_lookup_non_unique_key\")\n-        .withSetting(\"lookup-settings.json\");\n+    private static final TestDataset LANGUAGES_LOOKUP_NON_UNIQUE_KEY = LANGUAGES_LOOKUP.withIndex(\"languages_lookup_non_unique_key\")\n+        .withData(\"languages_non_unique_key.csv\")\n+        .withDynamicTypeMapping(Map.of(\"country\", \"text\"));\n     private static final TestDataset LANGUAGES_NESTED_FIELDS = new TestDataset(\n         \"languages_nested_fields\",\n         \"mapping-languages_nested_fields.json\",\n@@ -423,11 +424,13 @@ private static void loadDataSetIntoEs(\n         Logger logger = LogManager.getLogger(CsvTestsDataLoader.class);\n \n         Set<String> loadedDatasets = new HashSet<>();\n+        logger.info(\"Loading test datasets\");\n         for (var dataset : availableDatasetsForEs(supportsIndexModeLookup, supportsSourceFieldMapping, inferenceEnabled, timeSeriesOnly)) {\n             load(client, dataset, logger, indexCreator);\n             loadedDatasets.add(dataset.indexName);\n         }\n         forceMerge(client, loadedDatasets, logger);\n+        logger.info(\"Loading enrich policies\");\n         for (var policy : ENRICH_POLICIES) {\n             loadEnrichPolicy(client, policy.policyName, policy.policyFileName, logger);\n         }\n@@ -569,6 +572,7 @@ private static void deleteInferenceEndpoint(RestClient client, String inferenceI\n     }\n \n     private static void loadEnrichPolicy(RestClient client, String policyName, String policyFileName, Logger logger) throws IOException {\n+        logger.info(\"Loading enrich policy [{}] from file [{}]\", policyName, policyFileName);\n         URL policyMapping = getResource(\"/\" + policyFileName);\n         String entity = readTextFile(policyMapping);\n         Request request = new Request(\"PUT\", \"/_enrich/policy/\" + policyName);\n@@ -588,6 +592,7 @@ private static URL getResource(String name) {\n     }\n \n     private static void load(RestClient client, TestDataset dataset, Logger logger, IndexCreator indexCreator) throws IOException {\n+        logger.info(\"Loading dataset [{}] into ES index [{}]\", dataset.dataFileName, dataset.indexName);\n         URL mapping = getResource(\"/\" + dataset.mappingFileName);\n         Settings indexSettings = dataset.readSettingsFile();\n         indexCreator.createIndex(client, dataset.indexName, readMappingFile(mapping, dataset.typeMapping), indexSettings);\n@@ -854,15 +859,16 @@ public record TestDataset(\n         String dataFileName,\n         String settingFileName,\n         boolean allowSubFields,\n-        @Nullable Map<String, String> typeMapping,\n+        @Nullable Map<String, String> typeMapping, // Override mappings read from mappings file\n+        @Nullable Map<String, String> dynamicTypeMapping, // Define mappings not in the mapping files, but available from field-caps\n         boolean requiresInferenceEndpoint\n     ) {\n         public TestDataset(String indexName, String mappingFileName, String dataFileName) {\n-            this(indexName, mappingFileName, dataFileName, null, true, null, false);\n+            this(indexName, mappingFileName, dataFileName, null, true, null, null, false);\n         }\n \n         public TestDataset(String indexName) {\n-            this(indexName, \"mapping-\" + indexName + \".json\", indexName + \".csv\", null, true, null, false);\n+            this(indexName, \"mapping-\" + indexName + \".json\", indexName + \".csv\", null, true, null, null, false);\n         }\n \n         public TestDataset withIndex(String indexName) {\n@@ -873,6 +879,7 @@ public TestDataset withIndex(String indexName) {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -885,6 +892,7 @@ public TestDataset withData(String dataFileName) {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -897,6 +905,7 @@ public TestDataset noData() {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -909,6 +918,7 @@ public TestDataset withSetting(String settingFileName) {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -921,6 +931,7 @@ public TestDataset noSubfields() {\n                 settingFileName,\n                 false,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -933,12 +944,35 @@ public TestDataset withTypeMapping(Map<String, String> typeMapping) {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n+                requiresInferenceEndpoint\n+            );\n+        }\n+\n+        public TestDataset withDynamicTypeMapping(Map<String, String> dynamicTypeMapping) {\n+            return new TestDataset(\n+                indexName,\n+                mappingFileName,\n+                dataFileName,\n+                settingFileName,\n+                allowSubFields,\n+                typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n \n         public TestDataset withInferenceEndpoint(boolean needsInference) {\n-            return new TestDataset(indexName, mappingFileName, dataFileName, settingFileName, allowSubFields, typeMapping, needsInference);\n+            return new TestDataset(\n+                indexName,\n+                mappingFileName,\n+                dataFileName,\n+                settingFileName,\n+                allowSubFields,\n+                typeMapping,\n+                dynamicTypeMapping,\n+                needsInference\n+            );\n         }\n \n         private Settings readSettingsFile() throws IOException {"
    },
    {
      "filename": "x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/EsqlTestUtils.java",
      "status": "modified",
      "additions": 5,
      "deletions": 4,
      "changes": 9,
      "patch": "@@ -102,6 +102,7 @@\n import org.elasticsearch.xpack.esql.inference.InferenceService;\n import org.elasticsearch.xpack.esql.optimizer.LogicalOptimizerContext;\n import org.elasticsearch.xpack.esql.parser.QueryParam;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.EsRelation;\n import org.elasticsearch.xpack.esql.plan.logical.Explain;\n@@ -451,11 +452,11 @@ public static TransportVersion randomMinimumVersion() {\n     public static AnalyzerContext testAnalyzerContext(\n         Configuration configuration,\n         EsqlFunctionRegistry functionRegistry,\n-        IndexResolution indexResolution,\n+        Map<IndexPattern, IndexResolution> indexResolutions,\n         EnrichResolution enrichResolution,\n         InferenceResolution inferenceResolution\n     ) {\n-        return testAnalyzerContext(configuration, functionRegistry, indexResolution, Map.of(), enrichResolution, inferenceResolution);\n+        return testAnalyzerContext(configuration, functionRegistry, indexResolutions, Map.of(), enrichResolution, inferenceResolution);\n     }\n \n     /**\n@@ -464,15 +465,15 @@ public static AnalyzerContext testAnalyzerContext(\n     public static AnalyzerContext testAnalyzerContext(\n         Configuration configuration,\n         EsqlFunctionRegistry functionRegistry,\n-        IndexResolution indexResolution,\n+        Map<IndexPattern, IndexResolution> indexResolutions,\n         Map<String, IndexResolution> lookupResolution,\n         EnrichResolution enrichResolution,\n         InferenceResolution inferenceResolution\n     ) {\n         return new AnalyzerContext(\n             configuration,\n             functionRegistry,\n-            indexResolution,\n+            indexResolutions,\n             lookupResolution,\n             enrichResolution,\n             inferenceResolution,"
    },
    {
      "filename": "x-pack/plugin/esql/qa/testFixtures/src/main/resources/inlinestats.csv-spec",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "patch": "@@ -4150,14 +4150,15 @@ required_capability: inline_stats\n required_capability: fix_join_output_merging\n \n FROM languages_lookup_non_unique_key\n+| EVAL country = MV_SORT(country)\n | KEEP country, language_name\n | EVAL language_code = null::integer\n | INLINE STATS MAX(language_code) BY language_code\n | SORT country\n | LIMIT 5\n ;\n \n-country:text      |language_name:keyword |MAX(language_code):integer |language_code:integer\n+country:keyword   |language_name:keyword |MAX(language_code):integer |language_code:integer\n Atlantis          |null                  |null                       |null\n [Austria, Germany]|German                |null                       |null\n Canada            |English               |null                       |null"
    },
    {
      "filename": "x-pack/plugin/esql/qa/testFixtures/src/main/resources/lookup-join.csv-spec",
      "status": "modified",
      "additions": 5,
      "deletions": 3,
      "changes": 8,
      "patch": "@@ -247,11 +247,12 @@ FROM employees\n | EVAL language_code = emp_no % 10\n | LOOKUP JOIN languages_lookup_non_unique_key ON language_code\n | WHERE emp_no > 10090 AND emp_no < 10096\n+| EVAL country = MV_SORT(country)\n | SORT emp_no, country\n | KEEP emp_no, language_code, language_name, country\n ;\n \n-emp_no:integer | language_code:integer | language_name:keyword | country:text\n+emp_no:integer | language_code:integer | language_name:keyword | country:keyword\n     10091      | 1                     | English               | Canada\n     10091      | 1                     | null                  | United Kingdom\n     10091      | 1                     | English               | United States of America\n@@ -272,11 +273,12 @@ FROM employees\n | LIMIT 5\n | EVAL language_code = emp_no % 10\n | LOOKUP JOIN languages_lookup_non_unique_key ON language_code\n+| EVAL country = MV_SORT(country)\n | KEEP emp_no, language_code, language_name, country\n ;\n \n ignoreOrder:true\n-emp_no:integer | language_code:integer | language_name:keyword | country:text\n+emp_no:integer | language_code:integer | language_name:keyword | country:keyword\n 10001          | 1                     | English               | Canada\n 10001          | 1                     | English               | null\n 10001          | 1                     | null                  | United Kingdom\n@@ -324,7 +326,7 @@ ROW language_code = 2\n \n ignoreOrder:true\n language_code:integer | country:text       | language_name:keyword\n-2                     | [Austria, Germany] | German\n+2                     | [Germany, Austria] | German\n 2                     | Switzerland        | German\n 2                     | null               | German\n ;"
    },
    {
      "filename": "x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/Analyzer.java",
      "status": "modified",
      "additions": 23,
      "deletions": 11,
      "changes": 34,
      "patch": "@@ -247,12 +247,10 @@ private static class ResolveTable extends ParameterizedAnalyzerRule<UnresolvedRe\n \n         @Override\n         protected LogicalPlan rule(UnresolvedRelation plan, AnalyzerContext context) {\n-            return resolveIndex(\n-                plan,\n-                plan.indexMode().equals(IndexMode.LOOKUP)\n-                    ? context.lookupResolution().get(plan.indexPattern().indexPattern())\n-                    : context.indexResolution()\n-            );\n+            IndexResolution indexResolution = plan.indexMode().equals(IndexMode.LOOKUP)\n+                ? context.lookupResolution().get(plan.indexPattern().indexPattern())\n+                : context.indexResolution().get(plan.indexPattern());\n+            return resolveIndex(plan, indexResolution);\n         }\n \n         private LogicalPlan resolveIndex(UnresolvedRelation plan, IndexResolution indexResolution) {\n@@ -270,6 +268,7 @@ private LogicalPlan resolveIndex(UnresolvedRelation plan, IndexResolution indexR\n                         plan.telemetryLabel()\n                     );\n             }\n+            // assert indexResolution.matches(plan.indexPattern().indexPattern()) : \"Expected index resolution to match the index pattern\";\n             IndexPattern table = plan.indexPattern();\n             if (indexResolution.matches(table.indexPattern()) == false) {\n                 // TODO: fix this (and tests), or drop check (seems SQL-inherited, where's also defective)\n@@ -537,7 +536,7 @@ protected LogicalPlan rule(LogicalPlan plan, AnalyzerContext context) {\n             }\n \n             if (plan instanceof Insist i) {\n-                return resolveInsist(i, childrenOutput, context.indexResolution());\n+                return resolveInsist(i, childrenOutput, context);\n             }\n \n             if (plan instanceof Fuse fuse) {\n@@ -958,23 +957,36 @@ private List<Attribute> resolveUsingColumns(List<Attribute> cols, List<Attribute\n             return resolved;\n         }\n \n-        private LogicalPlan resolveInsist(Insist insist, List<Attribute> childrenOutput, IndexResolution indexResolution) {\n+        private LogicalPlan resolveInsist(Insist insist, List<Attribute> childrenOutput, AnalyzerContext context) {\n             List<Attribute> list = new ArrayList<>();\n+            List<IndexResolution> resolutions = collectIndexResolutions(insist, context);\n             for (Attribute a : insist.insistedAttributes()) {\n-                list.add(resolveInsistAttribute(a, childrenOutput, indexResolution));\n+                list.add(resolveInsistAttribute(a, childrenOutput, resolutions));\n             }\n             return insist.withAttributes(list);\n         }\n \n-        private Attribute resolveInsistAttribute(Attribute attribute, List<Attribute> childrenOutput, IndexResolution indexResolution) {\n+        private List<IndexResolution> collectIndexResolutions(LogicalPlan plan, AnalyzerContext context) {\n+            List<IndexResolution> resolutions = new ArrayList<>();\n+            plan.forEachDown(EsRelation.class, e -> {\n+                var resolution = context.indexResolution().get(new IndexPattern(e.source(), e.indexPattern()));\n+                if (resolution != null) {\n+                    resolutions.add(resolution);\n+                }\n+            });\n+            return resolutions;\n+        }\n+\n+        private Attribute resolveInsistAttribute(Attribute attribute, List<Attribute> childrenOutput, List<IndexResolution> indices) {\n             Attribute resolvedCol = maybeResolveAttribute((UnresolvedAttribute) attribute, childrenOutput);\n             // Field isn't mapped anywhere.\n             if (resolvedCol instanceof UnresolvedAttribute) {\n                 return insistKeyword(attribute);\n             }\n \n             // Field is partially unmapped.\n-            if (resolvedCol instanceof FieldAttribute fa && indexResolution.get().isPartiallyUnmappedField(fa.name())) {\n+            // TODO: Should the check for partially unmapped fields be done specific to each sub-query in a fork?\n+            if (resolvedCol instanceof FieldAttribute fa && indices.stream().anyMatch(r -> r.get().isPartiallyUnmappedField(fa.name()))) {\n                 return fa.dataType() == KEYWORD ? insistKeyword(fa) : invalidInsistAttribute(fa);\n             }\n "
    },
    {
      "filename": "x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/AnalyzerContext.java",
      "status": "modified",
      "additions": 4,
      "deletions": 3,
      "changes": 7,
      "patch": "@@ -11,6 +11,7 @@\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.inference.InferenceResolution;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.session.Configuration;\n import org.elasticsearch.xpack.esql.session.EsqlSession;\n \n@@ -19,7 +20,7 @@\n public record AnalyzerContext(\n     Configuration configuration,\n     EsqlFunctionRegistry functionRegistry,\n-    IndexResolution indexResolution,\n+    Map<IndexPattern, IndexResolution> indexResolution,\n     Map<String, IndexResolution> lookupResolution,\n     EnrichResolution enrichResolution,\n     InferenceResolution inferenceResolution,\n@@ -29,7 +30,7 @@ public record AnalyzerContext(\n     public AnalyzerContext(\n         Configuration configuration,\n         EsqlFunctionRegistry functionRegistry,\n-        IndexResolution indexResolution,\n+        Map<IndexPattern, IndexResolution> indexResolution,\n         Map<String, IndexResolution> lookupResolution,\n         EnrichResolution enrichResolution,\n         InferenceResolution inferenceResolution,\n@@ -52,7 +53,7 @@ public AnalyzerContext(Configuration configuration, EsqlFunctionRegistry functio\n         this(\n             configuration,\n             functionRegistry,\n-            result.indices(),\n+            result.indexResolution(),\n             result.lookupIndices(),\n             result.enrichResolution(),\n             result.inferenceResolution(),"
    },
    {
      "filename": "x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/PreAnalyzer.java",
      "status": "modified",
      "additions": 18,
      "deletions": 17,
      "changes": 35,
      "patch": "@@ -16,22 +16,23 @@\n import org.elasticsearch.xpack.esql.plan.logical.UnresolvedRelation;\n \n import java.util.ArrayList;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n \n /**\n  * This class is part of the planner.  Acts somewhat like a linker, to find the indices and enrich policies referenced by the query.\n  */\n public class PreAnalyzer {\n \n     public record PreAnalysis(\n-        IndexMode indexMode,\n-        IndexPattern indexPattern,\n+        Map<IndexPattern, IndexMode> indexes,\n         List<Enrich> enriches,\n         List<IndexPattern> lookupIndices,\n         boolean supportsAggregateMetricDouble,\n         boolean supportsDenseVector\n     ) {\n-        public static final PreAnalysis EMPTY = new PreAnalysis(null, null, List.of(), List.of(), false, false);\n+        public static final PreAnalysis EMPTY = new PreAnalysis(Map.of(), List.of(), List.of(), false, false);\n     }\n \n     public PreAnalysis preAnalyze(LogicalPlan plan) {\n@@ -43,17 +44,19 @@ public PreAnalysis preAnalyze(LogicalPlan plan) {\n     }\n \n     protected PreAnalysis doPreAnalyze(LogicalPlan plan) {\n-        Holder<IndexMode> indexMode = new Holder<>();\n-        Holder<IndexPattern> indexPattern = new Holder<>();\n+        Map<IndexPattern, IndexMode> indexes = new HashMap<>();\n         List<IndexPattern> lookupIndices = new ArrayList<>();\n         plan.forEachUp(UnresolvedRelation.class, p -> {\n             if (p.indexMode() == IndexMode.LOOKUP) {\n                 lookupIndices.add(p.indexPattern());\n-            } else if (indexMode.get() == null || indexMode.get() == p.indexMode()) {\n-                indexMode.set(p.indexMode());\n-                indexPattern.set(p.indexPattern());\n+            } else if (indexes.containsKey(p.indexPattern()) == false || indexes.get(p.indexPattern()) == p.indexMode()) {\n+                indexes.put(p.indexPattern(), p.indexMode());\n             } else {\n-                throw new IllegalStateException(\"index mode is already set\");\n+                IndexMode m1 = p.indexMode();\n+                IndexMode m2 = indexes.get(p.indexPattern());\n+                throw new IllegalStateException(\n+                    \"index pattern '\" + p.indexPattern() + \"' found with with different index mode: \" + m2 + \" != \" + m1\n+                );\n             }\n         });\n \n@@ -71,6 +74,11 @@ protected PreAnalysis doPreAnalyze(LogicalPlan plan) {\n          */\n         Holder<Boolean> supportsAggregateMetricDouble = new Holder<>(false);\n         Holder<Boolean> supportsDenseVector = new Holder<>(false);\n+        indexes.forEach((ip, mode) -> {\n+            if (mode == IndexMode.TIME_SERIES) {\n+                supportsAggregateMetricDouble.set(true);\n+            }\n+        });\n         plan.forEachDown(p -> p.forEachExpression(UnresolvedFunction.class, fn -> {\n             if (fn.name().equalsIgnoreCase(\"knn\")\n                 || fn.name().equalsIgnoreCase(\"to_dense_vector\")\n@@ -90,13 +98,6 @@ protected PreAnalysis doPreAnalyze(LogicalPlan plan) {\n         // mark plan as preAnalyzed (if it were marked, there would be no analysis)\n         plan.forEachUp(LogicalPlan::setPreAnalyzed);\n \n-        return new PreAnalysis(\n-            indexMode.get(),\n-            indexPattern.get(),\n-            unresolvedEnriches,\n-            lookupIndices,\n-            indexMode.get() == IndexMode.TIME_SERIES || supportsAggregateMetricDouble.get(),\n-            supportsDenseVector.get()\n-        );\n+        return new PreAnalysis(indexes, unresolvedEnriches, lookupIndices, supportsAggregateMetricDouble.get(), supportsDenseVector.get());\n     }\n }"
    },
    {
      "filename": "x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtils.java",
      "status": "modified",
      "additions": 42,
      "deletions": 27,
      "changes": 69,
      "patch": "@@ -33,6 +33,7 @@\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n \n import java.util.ArrayList;\n+import java.util.Collection;\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n@@ -186,7 +187,7 @@ static void updateExecutionInfoWithUnavailableClusters(\n \n     static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n         EsqlExecutionInfo executionInfo,\n-        IndexResolution indexResolution,\n+        Collection<IndexResolution> indexResolutions,\n         boolean usedFilter\n     ) {\n         if (executionInfo.clusterInfo.isEmpty()) {\n@@ -195,8 +196,10 @@ static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n         // Get the clusters which are still running, and we will check whether they have any matching indices.\n         // NOTE: we assume that updateExecutionInfoWithUnavailableClusters() was already run and took care of unavailable clusters.\n         final Set<String> clustersWithNoMatchingIndices = executionInfo.getRunningClusterAliases().collect(toSet());\n-        for (String indexName : indexResolution.resolvedIndices()) {\n-            clustersWithNoMatchingIndices.remove(RemoteClusterAware.parseClusterAlias(indexName));\n+        for (IndexResolution indexResolution : indexResolutions) {\n+            for (String indexName : indexResolution.resolvedIndices()) {\n+                clustersWithNoMatchingIndices.remove(RemoteClusterAware.parseClusterAlias(indexName));\n+            }\n         }\n         /*\n          * Rules enforced at planning time around non-matching indices\n@@ -234,20 +237,22 @@ static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n                 }\n             } else {\n                 // We check for the valid resolution because if we have empty resolution it's still an error.\n-                if (indexResolution.isValid()) {\n-                    List<FieldCapabilitiesFailure> failures = indexResolution.failures().getOrDefault(c, List.of());\n-                    // No matching indices, no concrete index requested, and no error in field-caps; just mark as done.\n-                    if (failures.isEmpty()) {\n-                        markClusterWithFinalStateAndNoShards(executionInfo, c, Cluster.Status.SUCCESSFUL, null);\n-                    } else {\n-                        // skip reporting index_not_found exceptions to avoid spamming users with such errors\n-                        // when queries use a remote cluster wildcard, e.g., `*:my-logs*`.\n-                        Exception nonIndexNotFound = failures.stream()\n-                            .map(FieldCapabilitiesFailure::getException)\n-                            .filter(ex -> ExceptionsHelper.unwrap(ex, IndexNotFoundException.class) == null)\n-                            .findAny()\n-                            .orElse(null);\n-                        markClusterWithFinalStateAndNoShards(executionInfo, c, Cluster.Status.SKIPPED, nonIndexNotFound);\n+                for (IndexResolution indexResolution : indexResolutions) {\n+                    if (indexResolution.isValid()) {\n+                        List<FieldCapabilitiesFailure> failures = indexResolution.failures().getOrDefault(c, List.of());\n+                        // No matching indices, no concrete index requested, and no error in field-caps; just mark as done.\n+                        if (failures.isEmpty()) {\n+                            markClusterWithFinalStateAndNoShards(executionInfo, c, Cluster.Status.SUCCESSFUL, null);\n+                        } else {\n+                            // skip reporting index_not_found exceptions to avoid spamming users with such errors\n+                            // when queries use a remote cluster wildcard, e.g., `*:my-logs*`.\n+                            Exception nonIndexNotFound = failures.stream()\n+                                .map(FieldCapabilitiesFailure::getException)\n+                                .filter(ex -> ExceptionsHelper.unwrap(ex, IndexNotFoundException.class) == null)\n+                                .findAny()\n+                                .orElse(null);\n+                            markClusterWithFinalStateAndNoShards(executionInfo, c, Cluster.Status.SKIPPED, nonIndexNotFound);\n+                        }\n                     }\n                 }\n             }\n@@ -258,8 +263,11 @@ static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n     }\n \n     // Filter-less version, mainly for testing where we don't need filter support\n-    static void updateExecutionInfoWithClustersWithNoMatchingIndices(EsqlExecutionInfo executionInfo, IndexResolution indexResolution) {\n-        updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution, false);\n+    static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n+        EsqlExecutionInfo executionInfo,\n+        Set<IndexResolution> indexResolutions\n+    ) {\n+        updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolutions, false);\n     }\n \n     // visible for testing\n@@ -304,24 +312,31 @@ static void updateExecutionInfoAtEndOfPlanning(EsqlExecutionInfo execInfo) {\n     /**\n      * Checks the index expression for the presence of remote clusters.\n      * If found, it will ensure that the caller has a valid Enterprise (or Trial) license on the querying cluster\n-     * as well as initialize corresponding cluster state in execution info.\n+     * as well as initialize the corresponding cluster state in execution info.\n      * @throws org.elasticsearch.ElasticsearchStatusException if the license is not valid (or present) for ES|QL CCS search.\n      */\n     public static void initCrossClusterState(\n         IndicesExpressionGrouper indicesGrouper,\n         XPackLicenseState licenseState,\n-        IndexPattern indexPattern,\n+        Set<IndexPattern> indexPatterns,\n         EsqlExecutionInfo executionInfo\n     ) throws ElasticsearchStatusException {\n-        if (indexPattern == null) {\n+        if (indexPatterns.isEmpty()) {\n             return;\n         }\n         try {\n-            var groupedIndices = indicesGrouper.groupIndices(\n-                IndicesOptions.DEFAULT,\n-                Strings.splitStringByCommaToArray(indexPattern.indexPattern()),\n-                false\n-            );\n+            // TODO it is not safe to concat multiple index patterns in case any of them contains exclusion.\n+            // This is going to be resolved in #136804\n+            String[] indexExpressions = indexPatterns.stream()\n+                .map(indexPattern -> Strings.splitStringByCommaToArray(indexPattern.indexPattern()))\n+                .reduce((a, b) -> {\n+                    String[] combined = new String[a.length + b.length];\n+                    System.arraycopy(a, 0, combined, 0, a.length);\n+                    System.arraycopy(b, 0, combined, a.length, b.length);\n+                    return combined;\n+                })\n+                .get();\n+            var groupedIndices = indicesGrouper.groupIndices(IndicesOptions.DEFAULT, indexExpressions, false);\n \n             executionInfo.clusterInfoInitializing(true);\n             // initialize the cluster entries in EsqlExecutionInfo before throwing the invalid license error"
    },
    {
      "filename": "x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlSession.java",
      "status": "modified",
      "additions": 110,
      "deletions": 61,
      "changes": 171,
      "patch": "@@ -459,9 +459,24 @@ private EsqlStatement parse(String query, QueryParams params) {\n     static void handleFieldCapsFailures(\n         boolean allowPartialResults,\n         EsqlExecutionInfo executionInfo,\n-        Map<String, List<FieldCapabilitiesFailure>> failures\n+        Map<IndexPattern, IndexResolution> indexResolutions\n     ) throws Exception {\n         FailureCollector failureCollector = new FailureCollector();\n+        for (IndexResolution indexResolution : indexResolutions.values()) {\n+            handleFieldCapsFailures(allowPartialResults, executionInfo, indexResolution.failures(), failureCollector);\n+        }\n+        Exception failure = failureCollector.getFailure();\n+        if (failure != null) {\n+            throw failure;\n+        }\n+    }\n+\n+    static void handleFieldCapsFailures(\n+        boolean allowPartialResults,\n+        EsqlExecutionInfo executionInfo,\n+        Map<String, List<FieldCapabilitiesFailure>> failures,\n+        FailureCollector failureCollector\n+    ) throws Exception {\n         for (var e : failures.entrySet()) {\n             String clusterAlias = e.getKey();\n             EsqlExecutionInfo.Cluster cluster = executionInfo.getCluster(clusterAlias);\n@@ -491,10 +506,6 @@ static void handleFieldCapsFailures(\n                 );\n             }\n         }\n-        Exception failure = failureCollector.getFailure();\n-        if (failure != null) {\n-            throw failure;\n-        }\n     }\n \n     public void analyzedPlan(\n@@ -532,14 +543,19 @@ private void resolveIndicesAndAnalyze(\n         PreAnalysisResult result,\n         ActionListener<Versioned<LogicalPlan>> logicalPlanListener\n     ) {\n-        EsqlCCSUtils.initCrossClusterState(indicesExpressionGrouper, verifier.licenseState(), preAnalysis.indexPattern(), executionInfo);\n+        EsqlCCSUtils.initCrossClusterState(\n+            indicesExpressionGrouper,\n+            verifier.licenseState(),\n+            preAnalysis.indexes().keySet(),\n+            executionInfo\n+        );\n \n         // The main index pattern dictates on which nodes the query can be executed, so we use the minimum transport version from this field\n         // caps request.\n         SubscribableListener.<PreAnalysisResult>newForked(\n-            l -> preAnalyzeMainIndicesAndRetrieveMinTransportVersion(preAnalysis, executionInfo, result, requestFilter, l)\n+            l -> preAnalyzeMainIndices(preAnalysis.indexes().entrySet().iterator(), preAnalysis, executionInfo, result, requestFilter, l)\n         ).andThenApply(r -> {\n-            if (r.indices.isValid()\n+            if (r.indexResolution.isEmpty() == false // Rule out ROW case with no FROM clauses\n                 && executionInfo.isCrossClusterSearch()\n                 && executionInfo.getRunningClusterAliases().findAny().isEmpty()) {\n                 LOGGER.debug(\"No more clusters to search, ending analysis stage\");\n@@ -779,7 +795,35 @@ private void validateRemoteVersions(EsqlExecutionInfo executionInfo) {\n         });\n     }\n \n-    private void preAnalyzeMainIndicesAndRetrieveMinTransportVersion(\n+    private void preAnalyzeMainIndices(\n+        Iterator<Map.Entry<IndexPattern, IndexMode>> indexPatterns,\n+        PreAnalyzer.PreAnalysis preAnalysis,\n+        EsqlExecutionInfo executionInfo,\n+        PreAnalysisResult result,\n+        QueryBuilder requestFilter,\n+        ActionListener<PreAnalysisResult> listener\n+    ) {\n+        if (indexPatterns.hasNext()) {\n+            var index = indexPatterns.next();\n+            preAnalyzeMainIndices(\n+                index.getKey(),\n+                index.getValue(),\n+                preAnalysis,\n+                executionInfo,\n+                result,\n+                requestFilter,\n+                listener.delegateFailureAndWrap((l, r) -> {\n+                    preAnalyzeMainIndices(indexPatterns, preAnalysis, executionInfo, r, requestFilter, l);\n+                })\n+            );\n+        } else {\n+            listener.onResponse(result);\n+        }\n+    }\n+\n+    private void preAnalyzeMainIndices(\n+        IndexPattern indexPattern,\n+        IndexMode indexMode,\n         PreAnalyzer.PreAnalysis preAnalysis,\n         EsqlExecutionInfo executionInfo,\n         PreAnalysisResult result,\n@@ -791,42 +835,36 @@ private void preAnalyzeMainIndicesAndRetrieveMinTransportVersion(\n             ThreadPool.Names.SEARCH_COORDINATION,\n             ThreadPool.Names.SYSTEM_READ\n         );\n-        if (preAnalysis.indexPattern() != null) {\n-            if (executionInfo.clusterAliases().isEmpty()) {\n-                // return empty resolution if the expression is pure CCS and resolved no remote clusters (like no-such-cluster*:index)\n-                listener.onResponse(\n-                    result.withIndices(IndexResolution.valid(new EsIndex(preAnalysis.indexPattern().indexPattern(), Map.of(), Map.of())))\n-                        .withMinimumTransportVersion(TransportVersion.current())\n-                );\n-            } else {\n-                indexResolver.resolveAsMergedMappingAndRetrieveMinimumVersion(\n-                    preAnalysis.indexPattern().indexPattern(),\n-                    result.fieldNames,\n-                    // Maybe if no indices are returned, retry without index mode and provide a clearer error message.\n-                    switch (preAnalysis.indexMode()) {\n-                        case IndexMode.TIME_SERIES -> {\n-                            var indexModeFilter = new TermQueryBuilder(IndexModeFieldMapper.NAME, IndexMode.TIME_SERIES.getName());\n-                            yield requestFilter != null\n-                                ? new BoolQueryBuilder().filter(requestFilter).filter(indexModeFilter)\n-                                : indexModeFilter;\n-                        }\n-                        default -> requestFilter;\n-                    },\n-                    preAnalysis.indexMode() == IndexMode.TIME_SERIES,\n-                    preAnalysis.supportsAggregateMetricDouble(),\n-                    preAnalysis.supportsDenseVector(),\n-                    listener.delegateFailureAndWrap((l, indexResolution) -> {\n-                        EsqlCCSUtils.updateExecutionInfoWithUnavailableClusters(executionInfo, indexResolution.inner().failures());\n-                        l.onResponse(\n-                            result.withIndices(indexResolution.inner()).withMinimumTransportVersion(indexResolution.minimumVersion())\n-                        );\n-                    })\n-                );\n-            }\n-        } else {\n-            // occurs when dealing with local relations (row a = 1)\n+        // TODO: This is not yet index specific, but that will not matter as soon as #136804 is dealt with\n+        if (executionInfo.clusterAliases().isEmpty()) {\n+            // return empty resolution if the expression is pure CCS and resolved no remote clusters (like no-such-cluster*:index)\n             listener.onResponse(\n-                result.withIndices(IndexResolution.invalid(\"[none specified]\")).withMinimumTransportVersion(TransportVersion.current())\n+                result.withIndices(indexPattern, IndexResolution.valid(new EsIndex(indexPattern.indexPattern(), Map.of(), Map.of())))\n+            );\n+        } else {\n+            indexResolver.resolveAsMergedMappingAndRetrieveMinimumVersion(\n+                indexPattern.indexPattern(),\n+                result.fieldNames,\n+                // Maybe if no indices are returned, retry without index mode and provide a clearer error message.\n+                switch (indexMode) {\n+                    case IndexMode.TIME_SERIES -> {\n+                        var indexModeFilter = new TermQueryBuilder(IndexModeFieldMapper.NAME, IndexMode.TIME_SERIES.getName());\n+                        yield requestFilter != null\n+                            ? new BoolQueryBuilder().filter(requestFilter).filter(indexModeFilter)\n+                            : indexModeFilter;\n+                    }\n+                    default -> requestFilter;\n+                },\n+                indexMode == IndexMode.TIME_SERIES,\n+                preAnalysis.supportsAggregateMetricDouble(),\n+                preAnalysis.supportsDenseVector(),\n+                listener.delegateFailureAndWrap((l, indexResolution) -> {\n+                    EsqlCCSUtils.updateExecutionInfoWithUnavailableClusters(executionInfo, indexResolution.inner().failures());\n+                    l.onResponse(\n+                        result.withIndices(indexPattern, indexResolution.inner())\n+                            .withMinimumTransportVersion(indexResolution.minimumVersion())\n+                    );\n+                })\n             );\n         }\n     }\n@@ -843,10 +881,14 @@ private void analyzeWithRetry(\n     ) {\n         LOGGER.debug(\"Analyzing the plan ({})\", description);\n         try {\n-            if (result.indices.isValid() || requestFilter != null) {\n+            if (result.indexResolution.values().stream().anyMatch(IndexResolution::isValid) || requestFilter != null) {\n                 // We won't run this check with no filter and no valid indices since this may lead to false positive - missing index report\n                 // when the resolution result is not valid for a different reason.\n-                EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, result.indices, requestFilter != null);\n+                EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(\n+                    executionInfo,\n+                    result.indexResolution.values(),\n+                    requestFilter != null\n+                );\n             }\n             LogicalPlan plan = analyzedPlan(parsed, configuration, result, executionInfo);\n             LOGGER.debug(\"Analyzed plan ({}):\\n{}\", description, plan);\n@@ -900,7 +942,7 @@ private PhysicalPlan logicalPlanToPhysicalPlan(\n \n     private LogicalPlan analyzedPlan(LogicalPlan parsed, Configuration configuration, PreAnalysisResult r, EsqlExecutionInfo executionInfo)\n         throws Exception {\n-        handleFieldCapsFailures(configuration.allowPartialResults(), executionInfo, r.indices.failures());\n+        handleFieldCapsFailures(configuration.allowPartialResults(), executionInfo, r.indexResolution());\n         Analyzer analyzer = new Analyzer(new AnalyzerContext(configuration, functionRegistry, r), verifier);\n         LogicalPlan plan = analyzer.analyze(parsed);\n         plan.setAnalyzed();\n@@ -946,29 +988,30 @@ private PhysicalPlan optimizedPhysicalPlan(LogicalPlan optimizedPlan, PhysicalPl\n     public record PreAnalysisResult(\n         Set<String> fieldNames,\n         Set<String> wildcardJoinIndices,\n-        IndexResolution indices,\n+        Map<IndexPattern, IndexResolution> indexResolution,\n         Map<String, IndexResolution> lookupIndices,\n         EnrichResolution enrichResolution,\n         InferenceResolution inferenceResolution,\n         TransportVersion minimumTransportVersion\n     ) {\n \n         public PreAnalysisResult(Set<String> fieldNames, Set<String> wildcardJoinIndices) {\n-            this(fieldNames, wildcardJoinIndices, null, new HashMap<>(), null, InferenceResolution.EMPTY, null);\n-        }\n-\n-        PreAnalysisResult withIndices(IndexResolution indices) {\n-            return new PreAnalysisResult(\n+            this(\n                 fieldNames,\n                 wildcardJoinIndices,\n-                indices,\n-                lookupIndices,\n-                enrichResolution,\n-                inferenceResolution,\n-                minimumTransportVersion\n+                new HashMap<>(),\n+                new HashMap<>(),\n+                null,\n+                InferenceResolution.EMPTY,\n+                TransportVersion.current()\n             );\n         }\n \n+        PreAnalysisResult withIndices(IndexPattern indexPattern, IndexResolution indices) {\n+            indexResolution.put(indexPattern, indices);\n+            return this;\n+        }\n+\n         PreAnalysisResult addLookupIndexResolution(String index, IndexResolution indexResolution) {\n             lookupIndices.put(index, indexResolution);\n             return this;\n@@ -978,7 +1021,7 @@ PreAnalysisResult withEnrichResolution(EnrichResolution enrichResolution) {\n             return new PreAnalysisResult(\n                 fieldNames,\n                 wildcardJoinIndices,\n-                indices,\n+                indexResolution,\n                 lookupIndices,\n                 enrichResolution,\n                 inferenceResolution,\n@@ -990,7 +1033,7 @@ PreAnalysisResult withInferenceResolution(InferenceResolution inferenceResolutio\n             return new PreAnalysisResult(\n                 fieldNames,\n                 wildcardJoinIndices,\n-                indices,\n+                indexResolution,\n                 lookupIndices,\n                 enrichResolution,\n                 inferenceResolution,\n@@ -999,10 +1042,16 @@ PreAnalysisResult withInferenceResolution(InferenceResolution inferenceResolutio\n         }\n \n         PreAnalysisResult withMinimumTransportVersion(TransportVersion minimumTransportVersion) {\n+            if (this.minimumTransportVersion != null) {\n+                if (this.minimumTransportVersion.equals(minimumTransportVersion)) {\n+                    return this;\n+                }\n+                minimumTransportVersion = TransportVersion.min(this.minimumTransportVersion, minimumTransportVersion);\n+            }\n             return new PreAnalysisResult(\n                 fieldNames,\n                 wildcardJoinIndices,\n-                indices,\n+                indexResolution,\n                 lookupIndices,\n                 enrichResolution,\n                 inferenceResolution,"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/CsvTests.java",
      "status": "modified",
      "additions": 80,
      "deletions": 40,
      "changes": 120,
      "patch": "@@ -60,6 +60,7 @@\n import org.elasticsearch.xpack.esql.analysis.PreAnalyzer;\n import org.elasticsearch.xpack.esql.core.expression.Attribute;\n import org.elasticsearch.xpack.esql.core.expression.FoldContext;\n+import org.elasticsearch.xpack.esql.core.tree.Source;\n import org.elasticsearch.xpack.esql.core.type.DataType;\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.core.type.InvalidMappedField;\n@@ -79,6 +80,7 @@\n import org.elasticsearch.xpack.esql.optimizer.LogicalPreOptimizerContext;\n import org.elasticsearch.xpack.esql.optimizer.TestLocalPhysicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n import org.elasticsearch.xpack.esql.plan.physical.ChangePointExec;\n@@ -414,6 +416,16 @@ protected void assertResults(ExpectedResults expected, ActualResults actual, boo\n         CsvAssert.assertResults(expected, actual, ignoreOrder, logger);\n     }\n \n+    private static Map<IndexPattern, IndexResolution> loadIndexResolution(\n+        Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> datasets\n+    ) {\n+        Map<IndexPattern, IndexResolution> indexResolutions = new HashMap<>();\n+        for (var entry : datasets.entrySet()) {\n+            indexResolutions.put(entry.getKey(), loadIndexResolution(entry.getValue()));\n+        }\n+        return indexResolutions;\n+    }\n+\n     private static IndexResolution loadIndexResolution(CsvTestsDataLoader.MultiIndexTestDataset datasets) {\n         var indexNames = datasets.datasets().stream().map(CsvTestsDataLoader.TestDataset::indexName);\n         Map<String, IndexMode> indexModes = indexNames.collect(Collectors.toMap(x -> x, x -> IndexMode.STANDARD));\n@@ -429,21 +441,30 @@ private static IndexResolution loadIndexResolution(CsvTestsDataLoader.MultiIndex\n \n     private static Map<String, EsField> createMappingForIndex(CsvTestsDataLoader.TestDataset dataset) {\n         var mapping = new TreeMap<>(loadMapping(dataset.mappingFileName()));\n-        if (dataset.typeMapping() == null) {\n-            return mapping;\n+        if (dataset.typeMapping() != null) {\n+            for (var entry : dataset.typeMapping().entrySet()) {\n+                if (mapping.containsKey(entry.getKey())) {\n+                    DataType dataType = DataType.fromTypeName(entry.getValue());\n+                    EsField field = mapping.get(entry.getKey());\n+                    EsField editedField = new EsField(\n+                        field.getName(),\n+                        dataType,\n+                        field.getProperties(),\n+                        field.isAggregatable(),\n+                        field.getTimeSeriesFieldType()\n+                    );\n+                    mapping.put(entry.getKey(), editedField);\n+                }\n+            }\n         }\n-        for (var entry : dataset.typeMapping().entrySet()) {\n-            if (mapping.containsKey(entry.getKey())) {\n-                DataType dataType = DataType.fromTypeName(entry.getValue());\n-                EsField field = mapping.get(entry.getKey());\n-                EsField editedField = new EsField(\n-                    field.getName(),\n-                    dataType,\n-                    field.getProperties(),\n-                    field.isAggregatable(),\n-                    field.getTimeSeriesFieldType()\n-                );\n-                mapping.put(entry.getKey(), editedField);\n+        // Add dynamic mappings, but only if they are not already mapped\n+        if (dataset.dynamicTypeMapping() != null) {\n+            for (var entry : dataset.dynamicTypeMapping().entrySet()) {\n+                if (mapping.containsKey(entry.getKey()) == false) {\n+                    DataType dataType = DataType.fromTypeName(entry.getValue());\n+                    EsField editedField = new EsField(entry.getKey(), dataType, Map.of(), false, EsField.TimeSeriesFieldType.NONE);\n+                    mapping.put(entry.getKey(), editedField);\n+                }\n             }\n         }\n         return mapping;\n@@ -526,7 +547,7 @@ private static EnrichPolicy loadEnrichPolicyMapping(String policyFileName) {\n \n     private LogicalPlan analyzedPlan(\n         LogicalPlan parsed,\n-        CsvTestsDataLoader.MultiIndexTestDataset datasets,\n+        Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> datasets,\n         TransportVersion minimumVersion\n     ) {\n         var indexResolution = loadIndexResolution(datasets);\n@@ -549,46 +570,65 @@ private LogicalPlan analyzedPlan(\n         return plan;\n     }\n \n-    private static CsvTestsDataLoader.MultiIndexTestDataset testDatasets(LogicalPlan parsed) {\n+    private Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> testDatasets(LogicalPlan parsed) {\n         var preAnalysis = new PreAnalyzer().preAnalyze(parsed);\n-        if (preAnalysis.indexPattern() == null) {\n+        if (preAnalysis.indexes().isEmpty()) {\n             // If the data set doesn't matter we'll just grab one we know works. Employees is fine.\n-            return CsvTestsDataLoader.MultiIndexTestDataset.of(CSV_DATASET_MAP.get(\"employees\"));\n+            return Map.of(\n+                new IndexPattern(Source.EMPTY, \"employees\"),\n+                CsvTestsDataLoader.MultiIndexTestDataset.of(CSV_DATASET_MAP.get(\"employees\"))\n+            );\n         }\n \n-        String indexName = preAnalysis.indexPattern().indexPattern();\n-        List<CsvTestsDataLoader.TestDataset> datasets = new ArrayList<>();\n-        if (indexName.endsWith(\"*\")) {\n-            String indexPrefix = indexName.substring(0, indexName.length() - 1);\n-            for (var entry : CSV_DATASET_MAP.entrySet()) {\n-                if (entry.getKey().startsWith(indexPrefix)) {\n-                    datasets.add(entry.getValue());\n+        List<String> missing = new ArrayList<>();\n+        Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> all = new HashMap<>();\n+        for (IndexPattern indexPattern : preAnalysis.indexes().keySet()) {\n+            List<CsvTestsDataLoader.TestDataset> datasets = new ArrayList<>();\n+            String indexName = indexPattern.indexPattern();\n+            if (indexName.endsWith(\"*\")) {\n+                String indexPrefix = indexName.substring(0, indexName.length() - 1);\n+                for (var entry : CSV_DATASET_MAP.entrySet()) {\n+                    if (entry.getKey().startsWith(indexPrefix)) {\n+                        datasets.add(entry.getValue());\n+                    }\n                 }\n-            }\n-        } else {\n-            for (String index : indexName.split(\",\")) {\n-                var dataset = CSV_DATASET_MAP.get(index);\n-                if (dataset == null) {\n-                    throw new IllegalArgumentException(\"unknown CSV dataset for table [\" + index + \"]\");\n+            } else {\n+                for (String index : indexName.split(\",\")) {\n+                    var dataset = CSV_DATASET_MAP.get(index);\n+                    if (dataset == null) {\n+                        throw new IllegalArgumentException(\"unknown CSV dataset for table [\" + index + \"]\");\n+                    }\n+                    datasets.add(dataset);\n                 }\n-                datasets.add(dataset);\n             }\n+            if (datasets.isEmpty() == false) {\n+                all.put(indexPattern, new CsvTestsDataLoader.MultiIndexTestDataset(indexName, datasets));\n+            } else {\n+                missing.add(indexName);\n+            }\n+        }\n+        if (all.isEmpty()) {\n+            throw new IllegalArgumentException(\"Found no CSV datasets for table [\" + preAnalysis.indexes() + \"]\");\n         }\n-        if (datasets.isEmpty()) {\n-            throw new IllegalArgumentException(\"unknown CSV dataset for table [\" + indexName + \"]\");\n+        if (missing.isEmpty() == false) {\n+            throw new IllegalArgumentException(\"Did not find datasets for tables: \" + missing);\n         }\n-        return new CsvTestsDataLoader.MultiIndexTestDataset(indexName, datasets);\n+        return all;\n     }\n \n     private static TestPhysicalOperationProviders testOperationProviders(\n         FoldContext foldCtx,\n-        CsvTestsDataLoader.MultiIndexTestDataset datasets\n+        Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> allDatasets\n     ) throws Exception {\n         var indexPages = new ArrayList<TestPhysicalOperationProviders.IndexPage>();\n-        for (CsvTestsDataLoader.TestDataset dataset : datasets.datasets()) {\n-            var testData = loadPageFromCsv(CsvTests.class.getResource(\"/data/\" + dataset.dataFileName()), dataset.typeMapping());\n-            Set<String> mappedFields = loadMapping(dataset.mappingFileName()).keySet();\n-            indexPages.add(new TestPhysicalOperationProviders.IndexPage(dataset.indexName(), testData.v1(), testData.v2(), mappedFields));\n+        for (CsvTestsDataLoader.MultiIndexTestDataset datasets : allDatasets.values()) {\n+            for (CsvTestsDataLoader.TestDataset dataset : datasets.datasets()) {\n+                var testData = loadPageFromCsv(CsvTests.class.getResource(\"/data/\" + dataset.dataFileName()), dataset.typeMapping());\n+                Set<String> mappedFields = loadMapping(dataset.mappingFileName()).keySet();\n+                indexPages.add(\n+                    new TestPhysicalOperationProviders.IndexPage(dataset.indexName(), testData.v1(), testData.v2(), mappedFields)\n+                );\n+            }\n         }\n         return TestPhysicalOperationProviders.create(foldCtx, indexPages);\n     }"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTestUtils.java",
      "status": "modified",
      "additions": 101,
      "deletions": 22,
      "changes": 123,
      "patch": "@@ -12,6 +12,7 @@\n import org.elasticsearch.test.ESTestCase;\n import org.elasticsearch.xpack.core.enrich.EnrichPolicy;\n import org.elasticsearch.xpack.esql.EsqlTestUtils;\n+import org.elasticsearch.xpack.esql.core.tree.Source;\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.core.type.InvalidMappedField;\n import org.elasticsearch.xpack.esql.enrich.ResolvedEnrichPolicy;\n@@ -22,18 +23,23 @@\n import org.elasticsearch.xpack.esql.inference.ResolvedInference;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n import org.elasticsearch.xpack.esql.parser.QueryParams;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n+import org.elasticsearch.xpack.esql.plan.logical.UnresolvedRelation;\n import org.elasticsearch.xpack.esql.session.Configuration;\n \n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.HashMap;\n import java.util.LinkedHashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n import java.util.function.Predicate;\n import java.util.function.Supplier;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n \n import static org.elasticsearch.xpack.core.enrich.EnrichPolicy.GEO_MATCH_TYPE;\n import static org.elasticsearch.xpack.core.enrich.EnrichPolicy.MATCH_TYPE;\n@@ -55,10 +61,16 @@ public static Analyzer expandedDefaultAnalyzer() {\n         return analyzer(expandedDefaultIndexResolution());\n     }\n \n+    /** Simplest analyzer with a single index, which must be valid */\n     public static Analyzer analyzer(IndexResolution indexResolution) {\n         return analyzer(indexResolution, TEST_VERIFIER);\n     }\n \n+    /** Simple analyzer with multiple indexes, which may also be invalid */\n+    public static Analyzer analyzer(Map<IndexPattern, IndexResolution> indexResolutions) {\n+        return analyzer(indexResolutions, defaultLookupResolution(), defaultEnrichResolution(), TEST_VERIFIER, TEST_CFG);\n+    }\n+\n     public static Analyzer analyzer(IndexResolution indexResolution, Map<String, IndexResolution> lookupResolution) {\n         return analyzer(indexResolution, lookupResolution, TEST_VERIFIER);\n     }\n@@ -77,11 +89,11 @@ public static Analyzer analyzer(\n         EnrichResolution enrichResolution,\n         Verifier verifier\n     ) {\n-        return analyzer(indexResolution, lookupResolution, enrichResolution, verifier, TEST_CFG);\n+        return analyzer(indexResolutions(indexResolution), lookupResolution, enrichResolution, verifier, TEST_CFG);\n     }\n \n     public static Analyzer analyzer(\n-        IndexResolution indexResolution,\n+        Map<IndexPattern, IndexResolution> indexResolutions,\n         Map<String, IndexResolution> lookupResolution,\n         EnrichResolution enrichResolution,\n         Verifier verifier,\n@@ -91,7 +103,7 @@ public static Analyzer analyzer(\n             testAnalyzerContext(\n                 config,\n                 new EsqlFunctionRegistry(),\n-                indexResolution,\n+                mergeIndexResolutions(indexResolutions, defaultSubqueryResolution()),\n                 lookupResolution,\n                 enrichResolution,\n                 defaultInferenceResolution()\n@@ -100,34 +112,40 @@ public static Analyzer analyzer(\n         );\n     }\n \n-    public static Analyzer analyzer(IndexResolution indexResolution, Verifier verifier, Configuration config) {\n-        return analyzer(indexResolution, defaultLookupResolution(), defaultEnrichResolution(), verifier, config);\n+    private static Map<IndexPattern, IndexResolution> mergeIndexResolutions(\n+        Map<IndexPattern, IndexResolution> indexResolutions,\n+        Map<IndexPattern, IndexResolution> more\n+    ) {\n+        Map<IndexPattern, IndexResolution> combined = new HashMap<>(indexResolutions);\n+        combined.putAll(more);\n+        return combined;\n+    }\n+\n+    public static Analyzer analyzer(Map<IndexPattern, IndexResolution> indexResolutions, Verifier verifier, Configuration config) {\n+        return analyzer(indexResolutions, defaultLookupResolution(), defaultEnrichResolution(), verifier, config);\n     }\n \n     public static Analyzer analyzer(Verifier verifier) {\n-        return new Analyzer(\n-            testAnalyzerContext(\n-                EsqlTestUtils.TEST_CFG,\n-                new EsqlFunctionRegistry(),\n-                analyzerDefaultMapping(),\n-                defaultLookupResolution(),\n-                defaultEnrichResolution(),\n-                defaultInferenceResolution()\n-            ),\n-            verifier\n-        );\n+        return analyzer(analyzerDefaultMapping(), defaultLookupResolution(), defaultEnrichResolution(), verifier, EsqlTestUtils.TEST_CFG);\n+    }\n+\n+    public static Analyzer analyzer(Map<IndexPattern, IndexResolution> indexResolutions, Verifier verifier) {\n+        return analyzer(indexResolutions, defaultLookupResolution(), defaultEnrichResolution(), verifier, EsqlTestUtils.TEST_CFG);\n     }\n \n     public static LogicalPlan analyze(String query) {\n         return analyze(query, \"mapping-basic.json\");\n     }\n \n     public static LogicalPlan analyze(String query, String mapping) {\n-        return analyze(query, \"test\", mapping);\n+        return analyze(query, indexFromQuery(query), mapping);\n     }\n \n     public static LogicalPlan analyze(String query, String index, String mapping) {\n-        return analyze(query, analyzer(loadMapping(mapping, index), TEST_VERIFIER, configuration(query)));\n+        Map<IndexPattern, IndexResolution> indexResolutions = index == null\n+            ? Map.of()\n+            : Map.of(new IndexPattern(Source.EMPTY, index), loadMapping(mapping, index));\n+        return analyze(query, analyzer(indexResolutions, TEST_VERIFIER, configuration(query)));\n     }\n \n     public static LogicalPlan analyze(String query, Analyzer analyzer) {\n@@ -138,12 +156,40 @@ public static LogicalPlan analyze(String query, Analyzer analyzer) {\n         return analyzed;\n     }\n \n+    private static final Pattern indexFromPattern = Pattern.compile(\"(?i)FROM\\\\s+([\\\\w-]+)\");\n+\n+    private static String indexFromQuery(String query) {\n+        // Extract the index name from the FROM clause of the query using regexp\n+        Matcher matcher = indexFromPattern.matcher(query);\n+        if (matcher.find()) {\n+            return matcher.group(1);\n+        }\n+        return null;\n+    }\n+\n     public static LogicalPlan analyze(String query, String mapping, QueryParams params) {\n+        return analyze(query, indexFromQuery(query), mapping, params);\n+    }\n+\n+    public static LogicalPlan analyze(String query, String index, String mapping, QueryParams params) {\n         var plan = new EsqlParser().createStatement(query, params);\n-        var analyzer = analyzer(loadMapping(mapping, \"test\"), TEST_VERIFIER, configuration(query));\n+        var indexResolutions = Map.of(new IndexPattern(Source.EMPTY, index), loadMapping(mapping, index));\n+        var analyzer = analyzer(indexResolutions, TEST_VERIFIER, configuration(query));\n         return analyzer.analyze(plan);\n     }\n \n+    public static UnresolvedRelation unresolvedRelation(String index) {\n+        return new UnresolvedRelation(\n+            Source.EMPTY,\n+            new IndexPattern(Source.EMPTY, index),\n+            false,\n+            List.of(),\n+            IndexMode.STANDARD,\n+            null,\n+            \"FROM\"\n+        );\n+    }\n+\n     public static IndexResolution loadMapping(String resource, String indexName, IndexMode indexMode) {\n         EsIndex test = new EsIndex(indexName, EsqlTestUtils.loadMapping(resource), Map.of(indexName, indexMode));\n         return IndexResolution.valid(test);\n@@ -154,8 +200,30 @@ public static IndexResolution loadMapping(String resource, String indexName) {\n         return IndexResolution.valid(test);\n     }\n \n-    public static IndexResolution analyzerDefaultMapping() {\n-        return loadMapping(\"mapping-basic.json\", \"test\");\n+    public static Map<IndexPattern, IndexResolution> analyzerDefaultMapping() {\n+        // Most tests use either \"test\" or \"employees\" as the index name, but for the same mapping\n+        return Map.of(\n+            new IndexPattern(Source.EMPTY, \"test\"),\n+            loadMapping(\"mapping-basic.json\", \"test\"),\n+            new IndexPattern(Source.EMPTY, \"employees\"),\n+            loadMapping(\"mapping-basic.json\", \"employees\")\n+        );\n+    }\n+\n+    public static Map<IndexPattern, IndexResolution> indexResolutions(EsIndex... indexes) {\n+        Map<IndexPattern, IndexResolution> map = new HashMap<>();\n+        for (EsIndex index : indexes) {\n+            map.put(new IndexPattern(Source.EMPTY, index.name()), IndexResolution.valid(index));\n+        }\n+        return map;\n+    }\n+\n+    public static Map<IndexPattern, IndexResolution> indexResolutions(IndexResolution... indexes) {\n+        Map<IndexPattern, IndexResolution> map = new HashMap<>();\n+        for (IndexResolution index : indexes) {\n+            map.put(new IndexPattern(Source.EMPTY, index.get().name()), index);\n+        }\n+        return map;\n     }\n \n     public static IndexResolution expandedDefaultIndexResolution() {\n@@ -232,6 +300,17 @@ public static InferenceResolution defaultInferenceResolution() {\n             .build();\n     }\n \n+    public static Map<IndexPattern, IndexResolution> defaultSubqueryResolution() {\n+        return Map.of(\n+            new IndexPattern(Source.EMPTY, \"languages\"),\n+            loadMapping(\"mapping-languages.json\", \"languages\"),\n+            new IndexPattern(Source.EMPTY, \"sample_data\"),\n+            loadMapping(\"mapping-sample_data.json\", \"sample_data\"),\n+            new IndexPattern(Source.EMPTY, \"test_mixed_types\"),\n+            loadMapping(\"mapping-default-incompatible.json\", \"test_mixed_types\")\n+        );\n+    }\n+\n     public static String randomInferenceId() {\n         return ESTestCase.randomFrom(VALID_INFERENCE_IDS);\n     }\n@@ -308,7 +387,7 @@ public static IndexResolution indexWithDateDateNanosUnionType() {\n         EsField dateDateNanosField = new InvalidMappedField(dateDateNanos, typesToIndices1);\n         EsField dateDateNanosLongField = new InvalidMappedField(dateDateNanosLong, typesToIndices2);\n         EsIndex index = new EsIndex(\n-            \"test*\",\n+            \"index*\",\n             Map.of(dateDateNanos, dateDateNanosField, dateDateNanosLong, dateDateNanosLongField),\n             Map.of(\"index1\", IndexMode.STANDARD, \"index2\", IndexMode.STANDARD, \"index3\", IndexMode.STANDARD)\n         );"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTests.java",
      "status": "modified",
      "additions": 30,
      "deletions": 37,
      "changes": 67,
      "patch": "@@ -131,17 +131,20 @@\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.analyzerDefaultMapping;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultEnrichResolution;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultInferenceResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexWithDateDateNanosUnionType;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.randomInferenceIdOtherThan;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.tsdbIndexResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.unresolvedRelation;\n import static org.elasticsearch.xpack.esql.core.tree.Source.EMPTY;\n import static org.elasticsearch.xpack.esql.core.type.DataType.AGGREGATE_METRIC_DOUBLE;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DATETIME;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DATE_NANOS;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DATE_PERIOD;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DENSE_VECTOR;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DOUBLE;\n+import static org.elasticsearch.xpack.esql.core.type.DataType.INTEGER;\n import static org.elasticsearch.xpack.esql.core.type.DataType.KEYWORD;\n import static org.elasticsearch.xpack.esql.core.type.DataType.LONG;\n import static org.elasticsearch.xpack.esql.core.type.DataType.UNSUPPORTED;\n@@ -162,16 +165,7 @@\n //@TestLogging(value = \"org.elasticsearch.xpack.esql.analysis:TRACE\", reason = \"debug\")\n public class AnalyzerTests extends ESTestCase {\n \n-    private static final UnresolvedRelation UNRESOLVED_RELATION = new UnresolvedRelation(\n-        EMPTY,\n-        new IndexPattern(EMPTY, \"idx\"),\n-        false,\n-        List.of(),\n-        IndexMode.STANDARD,\n-        null,\n-        \"FROM\"\n-    );\n-\n+    private static final UnresolvedRelation UNRESOLVED_RELATION = unresolvedRelation(\"idx\");\n     private static final int MAX_LIMIT = AnalyzerSettings.QUERY_RESULT_TRUNCATION_MAX_SIZE.getDefault(Settings.EMPTY);\n     private static final int DEFAULT_LIMIT = AnalyzerSettings.QUERY_RESULT_TRUNCATION_DEFAULT_SIZE.getDefault(Settings.EMPTY);\n     private static final int DEFAULT_TIMESERIES_LIMIT = AnalyzerSettings.QUERY_TIMESERIES_RESULT_TRUNCATION_DEFAULT_SIZE.getDefault(\n@@ -188,7 +182,7 @@ public void testIndexResolution() {\n     }\n \n     public void testFailOnUnresolvedIndex() {\n-        Analyzer analyzer = analyzer(IndexResolution.invalid(\"Unknown index [idx]\"));\n+        Analyzer analyzer = analyzer(Map.of(new IndexPattern(Source.EMPTY, \"idx\"), IndexResolution.invalid(\"Unknown index [idx]\")));\n \n         VerificationException e = expectThrows(VerificationException.class, () -> analyzer.analyze(UNRESOLVED_RELATION));\n \n@@ -199,7 +193,7 @@ public void testIndexWithClusterResolution() {\n         EsIndex idx = new EsIndex(\"cluster:idx\", Map.of());\n         Analyzer analyzer = analyzer(IndexResolution.valid(idx));\n \n-        var plan = analyzer.analyze(UNRESOLVED_RELATION);\n+        var plan = analyzer.analyze(unresolvedRelation(\"cluster:idx\"));\n         var limit = as(plan, Limit.class);\n \n         assertEquals(new EsRelation(EMPTY, idx.name(), IndexMode.STANDARD, idx.indexNameWithModes(), NO_FIELDS), limit.child());\n@@ -268,7 +262,7 @@ public void testRowAttributeResolution() {\n         var plan = analyzer.analyze(\n             new Eval(\n                 EMPTY,\n-                new Row(EMPTY, List.of(new Alias(EMPTY, \"emp_no\", new Literal(EMPTY, 1, DataType.INTEGER)))),\n+                new Row(EMPTY, List.of(new Alias(EMPTY, \"emp_no\", new Literal(EMPTY, 1, INTEGER)))),\n                 List.of(new Alias(EMPTY, \"e\", new UnresolvedAttribute(EMPTY, \"emp_no\")))\n             )\n         );\n@@ -410,16 +404,16 @@ public void testNoProjection() {\n                 from test\n                 \"\"\",\n             DataType.KEYWORD,\n-            DataType.INTEGER,\n+            INTEGER,\n             DataType.KEYWORD,\n             DataType.TEXT,\n             DATETIME,\n             DataType.TEXT,\n             DataType.KEYWORD,\n-            DataType.INTEGER,\n+            INTEGER,\n             DataType.KEYWORD,\n             DataType.LONG,\n-            DataType.INTEGER\n+            INTEGER\n         );\n     }\n \n@@ -1687,7 +1681,7 @@ public void testEnrichPolicyWithError() {\n         AnalyzerContext context = testAnalyzerContext(\n             configuration(\"from test\"),\n             new EsqlFunctionRegistry(),\n-            testIndex,\n+            indexResolutions(testIndex),\n             enrichResolution,\n             emptyInferenceResolution()\n         );\n@@ -1843,7 +1837,7 @@ public void testEnrichFieldsIncludeMatchField() {\n         AnalyzerContext context = testAnalyzerContext(\n             configuration(query),\n             new EsqlFunctionRegistry(),\n-            testIndex,\n+            indexResolutions(testIndex),\n             enrichResolution,\n             emptyInferenceResolution()\n         );\n@@ -1924,7 +1918,7 @@ public void testUnresolvedMvExpand() {\n \n     public void testRegularStats() {\n         var plan = analyze(\"\"\"\n-            from tests\n+            from test\n             | stats by salary\n             \"\"\");\n \n@@ -2644,7 +2638,7 @@ private void validateConditionalFunctions(LogicalPlan plan) {\n         assertEquals(projection.dataType(), DataType.DOUBLE);\n         projection = as(projections.get(1), ReferenceAttribute.class);\n         assertEquals(projection.name(), \"y\");\n-        assertEquals(projection.dataType(), DataType.INTEGER);\n+        assertEquals(projection.dataType(), INTEGER);\n         projection = as(projections.get(2), ReferenceAttribute.class);\n         assertEquals(projection.name(), \"z\");\n         assertEquals(projection.dataType(), DataType.LONG);\n@@ -3053,7 +3047,7 @@ public void testFromEnrichAndMatchColonUsage() {\n             | EVAL x = to_string(languages)\n             | ENRICH _any:languages ON x\n             | WHERE first_name: \"Anna\"\n-            \"\"\", \"mapping-default.json\");\n+            \"\"\", \"*:test\", \"mapping-default.json\");\n         var limit = as(plan, Limit.class);\n         var filter = as(limit.child(), Filter.class);\n         var match = as(filter.condition(), MatchOperator.class);\n@@ -3062,7 +3056,7 @@ public void testFromEnrichAndMatchColonUsage() {\n         assertEquals(enrich.policy().getMatchField(), \"language_code\");\n         var eval = as(enrich.child(), Eval.class);\n         var esRelation = as(eval.child(), EsRelation.class);\n-        assertEquals(esRelation.indexPattern(), \"test\");\n+        assertEquals(esRelation.indexPattern(), \"*:test\"); // This tests nothing, as whatever appears here comes from the test itself\n     }\n \n     public void testFunctionNamedParamsAsFunctionArgument() {\n@@ -3120,7 +3114,7 @@ public void testResolveInsist_fieldExists_insistedOutputContainsNoUnmappedFields\n \n         Attribute last = plan.output().getLast();\n         assertThat(last.name(), is(\"emp_no\"));\n-        assertThat(last.dataType(), is(DataType.INTEGER));\n+        assertThat(last.dataType(), is(INTEGER));\n         assertThat(\n             plan.output()\n                 .stream()\n@@ -3157,7 +3151,7 @@ public void testResolveInsist_multiIndexFieldPartiallyMappedWithSingleKeywordTyp\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3172,7 +3166,7 @@ public void testResolveInsist_multiIndexFieldPartiallyMappedWithSingleKeywordTyp\n         );\n \n         String query = \"FROM foo, bar | INSIST_üêî message\";\n-        var plan = analyze(query, analyzer(resolution, TEST_VERIFIER, configuration(query)));\n+        var plan = analyze(query, analyzer(indexResolutions(resolution), TEST_VERIFIER, configuration(query)));\n         var limit = as(plan, Limit.class);\n         var insist = as(limit.child(), Insist.class);\n         var attribute = (FieldAttribute) EsqlTestUtils.singleValue(insist.output());\n@@ -3184,7 +3178,7 @@ public void testResolveInsist_multiIndexFieldExistsWithSingleTypeButIsNotKeyword\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3212,7 +3206,7 @@ public void testResolveInsist_multiIndexFieldPartiallyExistsWithMultiTypesNoKeyw\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3240,7 +3234,7 @@ public void testResolveInsist_multiIndexSameMapping_fieldIsMapped() {\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3265,7 +3259,7 @@ public void testResolveInsist_multiIndexFieldPartiallyExistsWithMultiTypesWithKe\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3294,7 +3288,7 @@ public void testResolveInsist_multiIndexFieldPartiallyExistsWithMultiTypesWithCa\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3310,7 +3304,7 @@ public void testResolveInsist_multiIndexFieldPartiallyExistsWithMultiTypesWithCa\n         );\n         VerificationException e = expectThrows(\n             VerificationException.class,\n-            () -> analyze(\"FROM multi_index | INSIST_üêî message | EVAL message = message :: keyword\", analyzer(resolution, TEST_VERIFIER))\n+            () -> analyze(\"FROM foo, bar | INSIST_üêî message | EVAL message = message :: keyword\", analyzer(resolution, TEST_VERIFIER))\n         );\n         // This isn't the most informative error, but it'll do for now.\n         assertThat(\n@@ -3810,7 +3804,7 @@ private static LogicalPlan analyzeWithEmptyFieldCapsResponse(String query) throw\n         );\n         IndexResolver.FieldsInfo caps = new IndexResolver.FieldsInfo(new FieldCapabilitiesResponse(idxResponses, List.of()), true, true);\n         IndexResolution resolution = IndexResolver.mergedMappings(\"test*\", caps);\n-        var analyzer = analyzer(resolution, TEST_VERIFIER, configuration(query));\n+        var analyzer = analyzer(indexResolutions(resolution), TEST_VERIFIER, configuration(query));\n         return analyze(query, analyzer);\n     }\n \n@@ -4427,7 +4421,7 @@ public void testImplicitCastingForDateAndDateNanosFields() {\n         // Validate if a union typed field is cast to a type explicitly, implicit casting won't be applied again, and include some cases of\n         // nested casting as well.\n         LogicalPlan plan = analyze(\"\"\"\n-            FROM tests\n+            FROM index*\n             | Eval a = date_and_date_nanos, b = date_and_date_nanos::datetime, c = date_and_date_nanos::date_nanos,\n                    d = date_and_date_nanos::datetime::datetime, e = date_and_date_nanos::datetime::date_nanos,\n                    f = date_and_date_nanos::date_nanos::datetime, g = date_and_date_nanos::date_nanos::date_nanos,\n@@ -4535,7 +4529,7 @@ public void testImplicitCastingForDateAndDateNanosFields() {\n         fa = as(toDateNanos.field(), FieldAttribute.class);\n         verifyNameAndTypeAndMultiTypeEsField(fa.name(), fa.dataType(), \"$$date_and_date_nanos$converted_to$long\", LONG, fa);\n         EsRelation esRelation = as(eval.child(), EsRelation.class);\n-        assertEquals(\"test*\", esRelation.indexPattern());\n+        assertEquals(\"index*\", esRelation.indexPattern());\n     }\n \n     public void testGroupingOverridesInStats() {\n@@ -4628,12 +4622,11 @@ public void testImplicitCastingForAggregateMetricDouble() {\n             Map.of(\"k8s\", IndexMode.TIME_SERIES, \"k8s-downsampled\", IndexMode.TIME_SERIES),\n             Set.of()\n         );\n-        var indexResolution = IndexResolution.valid(esIndex);\n         var analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                indexResolution,\n+                indexResolutions(esIndex),\n                 defaultEnrichResolution(),\n                 defaultInferenceResolution()\n             ),\n@@ -4697,6 +4690,6 @@ static Literal string(String value) {\n     }\n \n     static Literal literal(int value) {\n-        return new Literal(EMPTY, value, DataType.INTEGER);\n+        return new Literal(EMPTY, value, INTEGER);\n     }\n }"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/ParsingTests.java",
      "status": "modified",
      "additions": 8,
      "deletions": 1,
      "changes": 9,
      "patch": "@@ -45,6 +45,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.emptyInferenceResolution;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.emptyPolicyResolution;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.instanceOf;\n@@ -56,7 +57,13 @@ public class ParsingTests extends ESTestCase {\n \n     private final IndexResolution defaultIndex = loadIndexResolution(\"mapping-basic.json\");\n     private final Analyzer defaultAnalyzer = new Analyzer(\n-        testAnalyzerContext(TEST_CFG, new EsqlFunctionRegistry(), defaultIndex, emptyPolicyResolution(), emptyInferenceResolution()),\n+        testAnalyzerContext(\n+            TEST_CFG,\n+            new EsqlFunctionRegistry(),\n+            indexResolutions(defaultIndex),\n+            emptyPolicyResolution(),\n+            emptyInferenceResolution()\n+        ),\n         TEST_VERIFIER\n     );\n "
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/VerifierTests.java",
      "status": "modified",
      "additions": 55,
      "deletions": 58,
      "changes": 113,
      "patch": "@@ -1006,10 +1006,10 @@ public void testFilterNullField() {\n         query(\"from test | where null::boolean\");\n \n         // Provide `NULL` type in `EVAL`\n-        query(\"from t | EVAL x = null | where x\");\n+        query(\"from test | EVAL x = null | where x\");\n \n         // `to_string(null)` is of `KEYWORD` type null, resulting in `to_string(null) == \"abc\"` being of `BOOLEAN`\n-        query(\"from t | where to_string(null) == \\\"abc\\\"\");\n+        query(\"from test | where to_string(null) == \\\"abc\\\"\");\n \n         // Other DataTypes can contain null values\n         assertEquals(\"1:19: Condition expression needs to be boolean, found [KEYWORD]\", error(\"from test | where null::string\"));\n@@ -1114,27 +1114,27 @@ public void testInlineImpossibleConvert() {\n \n     public void testAggregateOnCounter() {\n         assertThat(\n-            error(\"FROM tests | STATS min(network.bytes_in)\", tsdb),\n+            error(\"FROM test | STATS min(network.bytes_in)\", tsdb),\n             equalTo(\n-                \"1:20: argument of [min(network.bytes_in)] must be\"\n+                \"1:19: argument of [min(network.bytes_in)] must be\"\n                     + \" [boolean, date, ip, string, version, aggregate_metric_double or numeric except counter types],\"\n                     + \" found value [network.bytes_in] type [counter_long]\"\n             )\n         );\n \n         assertThat(\n-            error(\"FROM tests | STATS max(network.bytes_in)\", tsdb),\n+            error(\"FROM test | STATS max(network.bytes_in)\", tsdb),\n             equalTo(\n-                \"1:20: argument of [max(network.bytes_in)] must be\"\n+                \"1:19: argument of [max(network.bytes_in)] must be\"\n                     + \" [boolean, date, ip, string, version, aggregate_metric_double or numeric except counter types],\"\n                     + \" found value [network.bytes_in] type [counter_long]\"\n             )\n         );\n \n         assertThat(\n-            error(\"FROM tests | STATS count(network.bytes_out)\", tsdb),\n+            error(\"FROM test | STATS count(network.bytes_out)\", tsdb),\n             equalTo(\n-                \"1:20: argument of [count(network.bytes_out)] must be [any type except counter types or dense_vector],\"\n+                \"1:19: argument of [count(network.bytes_out)] must be [any type except counter types or dense_vector],\"\n                     + \" found value [network.bytes_out] type [counter_long]\"\n             )\n         );\n@@ -1157,91 +1157,88 @@ public void testAggsResolutionWithUnresolvedGroupings() {\n             new String[] { \"avg\", \"count\", \"count_distinct\", \"min\", \"max\", \"median\", \"median_absolute_deviation\", \"sum\", \"values\" }\n         );\n \n-        assertThat(error(\"FROM tests | STATS \" + agg_func + \"(emp_no) by foobar\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n+        assertThat(error(\"FROM test | STATS \" + agg_func + \"(emp_no) by foobar\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n+        assertThat(error(\"FROM test | STATS \" + agg_func + \"(x) by foobar, x = emp_no\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n+        assertThat(error(\"FROM test | STATS \" + agg_func + \"(foobar) by foobar\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n         assertThat(\n-            error(\"FROM tests | STATS \" + agg_func + \"(x) by foobar, x = emp_no\"),\n-            matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\")\n-        );\n-        assertThat(error(\"FROM tests | STATS \" + agg_func + \"(foobar) by foobar\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n-        assertThat(\n-            error(\"FROM tests | STATS \" + agg_func + \"(foobar) by BUCKET(hire_date, 10)\"),\n+            error(\"FROM test | STATS \" + agg_func + \"(foobar) by BUCKET(hire_date, 10)\"),\n             matchesRegex(\n                 \"1:\\\\d+: function expects exactly four arguments when the first one is of type \\\\[DATETIME]\"\n                     + \" and the second of type \\\\[INTEGER]\\n\"\n                     + \"line 1:\\\\d+: Unknown column \\\\[foobar]\"\n             )\n         );\n-        assertThat(error(\"FROM tests | STATS \" + agg_func + \"(foobar) by emp_no\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n+        assertThat(error(\"FROM test | STATS \" + agg_func + \"(foobar) by emp_no\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n         // TODO: Ideally, we'd detect that count_distinct(x) doesn't require an error message.\n         assertThat(\n-            error(\"FROM tests | STATS \" + agg_func + \"(x) by x = foobar\"),\n+            error(\"FROM test | STATS \" + agg_func + \"(x) by x = foobar\"),\n             matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\\n\" + \"line 1:\\\\d+: Unknown column \\\\[x]\")\n         );\n     }\n \n     public void testNotAllowRateOutsideMetrics() {\n         assertThat(\n-            error(\"FROM tests | STATS avg(rate(network.bytes_in))\", tsdb),\n+            error(\"FROM test  | STATS avg(rate(network.bytes_in))\", tsdb),\n             equalTo(\"1:24: time_series aggregate[rate(network.bytes_in)] can only be used with the TS command\")\n         );\n         assertThat(\n-            error(\"FROM tests | STATS rate(network.bytes_in)\", tsdb),\n+            error(\"FROM test  | STATS rate(network.bytes_in)\", tsdb),\n             equalTo(\"1:20: time_series aggregate[rate(network.bytes_in)] can only be used with the TS command\")\n         );\n         assertThat(\n-            error(\"FROM tests | STATS max_over_time(network.connections)\", tsdb),\n+            error(\"FROM test  | STATS max_over_time(network.connections)\", tsdb),\n             equalTo(\"1:20: time_series aggregate[max_over_time(network.connections)] can only be used with the TS command\")\n         );\n         assertThat(\n-            error(\"FROM tests | EVAL r = rate(network.bytes_in)\", tsdb),\n+            error(\"FROM test  | EVAL r = rate(network.bytes_in)\", tsdb),\n             equalTo(\"1:23: aggregate function [rate(network.bytes_in)] not allowed outside STATS command\")\n         );\n     }\n \n     public void testTimeseriesAggregate() {\n         assertThat(\n-            error(\"TS tests | STATS rate(network.bytes_in)\", tsdb),\n+            error(\"TS test  | STATS rate(network.bytes_in)\", tsdb),\n             equalTo(\n                 \"1:18: time-series aggregate function [rate(network.bytes_in)] can only be used with the TS command \"\n                     + \"and inside another aggregate function\"\n             )\n         );\n         assertThat(\n-            error(\"TS tests | STATS avg_over_time(network.connections)\", tsdb),\n+            error(\"TS test  | STATS avg_over_time(network.connections)\", tsdb),\n             equalTo(\n                 \"1:18: time-series aggregate function [avg_over_time(network.connections)] can only be used \"\n                     + \"with the TS command and inside another aggregate function\"\n             )\n         );\n         assertThat(\n-            error(\"TS tests | STATS avg(rate(network.bytes_in)), rate(network.bytes_in)\", tsdb),\n+            error(\"TS test  | STATS avg(rate(network.bytes_in)), rate(network.bytes_in)\", tsdb),\n             equalTo(\n                 \"1:47: time-series aggregate function [rate(network.bytes_in)] can only be used \"\n                     + \"with the TS command and inside another aggregate function\"\n             )\n         );\n \n-        assertThat(error(\"TS tests | STATS max(avg(rate(network.bytes_in)))\", tsdb), equalTo(\"\"\"\n+        assertThat(error(\"TS test  | STATS max(avg(rate(network.bytes_in)))\", tsdb), equalTo(\"\"\"\n             1:22: nested aggregations [avg(rate(network.bytes_in))] \\\n             not allowed inside other aggregations [max(avg(rate(network.bytes_in)))]\n             line 1:12: cannot use aggregate function [avg(rate(network.bytes_in))] \\\n             inside over-time aggregation function [rate(network.bytes_in)]\"\"\"));\n \n-        assertThat(error(\"TS tests | STATS max(avg(rate(network.bytes_in)))\", tsdb), equalTo(\"\"\"\n+        assertThat(error(\"TS test  | STATS max(avg(rate(network.bytes_in)))\", tsdb), equalTo(\"\"\"\n             1:22: nested aggregations [avg(rate(network.bytes_in))] \\\n             not allowed inside other aggregations [max(avg(rate(network.bytes_in)))]\n             line 1:12: cannot use aggregate function [avg(rate(network.bytes_in))] \\\n             inside over-time aggregation function [rate(network.bytes_in)]\"\"\"));\n \n         assertThat(\n-            error(\"TS tests | STATS rate(network.bytes_in) BY bucket(@timestamp, 1 hour)\", tsdb),\n+            error(\"TS test  | STATS rate(network.bytes_in) BY bucket(@timestamp, 1 hour)\", tsdb),\n             equalTo(\n                 \"1:18: time-series aggregate function [rate(network.bytes_in)] can only be used \"\n                     + \"with the TS command and inside another aggregate function\"\n             )\n         );\n         assertThat(\n-            error(\"TS tests | STATS COUNT(*)\", tsdb),\n+            error(\"TS test  | STATS COUNT(*)\", tsdb),\n             equalTo(\"1:18: count_star [COUNT(*)] can't be used with TS command; use count on a field instead\")\n         );\n     }\n@@ -1733,45 +1730,45 @@ public void testConditionalFunctionsWithMixedNumericTypes() {\n \n             // counter\n             assertEquals(\n-                \"1:23: second argument of [\"\n+                \"1:22: second argument of [\"\n                     + functionName\n                     + \"(network.bytes_in, 0)] must be [counter_long], found value [0] type [integer]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(network.bytes_in, 0)\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(network.bytes_in, 0)\", tsdb)\n             );\n \n             assertEquals(\n-                \"1:23: second argument of [\"\n+                \"1:22: second argument of [\"\n                     + functionName\n                     + \"(network.bytes_in, to_long(0))] must be [counter_long], \"\n                     + \"found value [to_long(0)] type [long]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(network.bytes_in, to_long(0))\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(network.bytes_in, to_long(0))\", tsdb)\n             );\n             assertEquals(\n-                \"1:23: second argument of [\"\n+                \"1:22: second argument of [\"\n                     + functionName\n                     + \"(network.bytes_in, 0.0)] must be [counter_long], found value [0.0] type [double]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(network.bytes_in, 0.0)\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(network.bytes_in, 0.0)\", tsdb)\n             );\n \n             assertEquals(\n-                \"1:23: third argument of [\"\n+                \"1:22: third argument of [\"\n                     + functionName\n                     + \"(null, network.bytes_in, 0)] must be [counter_long], found value [0] type [integer]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(null, network.bytes_in, 0)\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(null, network.bytes_in, 0)\", tsdb)\n             );\n \n             assertEquals(\n-                \"1:23: third argument of [\"\n+                \"1:22: third argument of [\"\n                     + functionName\n                     + \"(null, network.bytes_in, to_long(0))] must be [counter_long], \"\n                     + \"found value [to_long(0)] type [long]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(null, network.bytes_in, to_long(0))\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(null, network.bytes_in, to_long(0))\", tsdb)\n             );\n             assertEquals(\n-                \"1:23: third argument of [\"\n+                \"1:22: third argument of [\"\n                     + functionName\n                     + \"(null, network.bytes_in, 0.0)] must be [counter_long], found value [0.0] type [double]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(null, network.bytes_in, 0.0)\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(null, network.bytes_in, 0.0)\", tsdb)\n             );\n         }\n \n@@ -1781,8 +1778,8 @@ public void testConditionalFunctionsWithMixedNumericTypes() {\n             error(\"from test | eval x = case(languages == 1, salary, height)\")\n         );\n         assertEquals(\n-            \"1:23: third argument of [case(name == \\\"a\\\", network.bytes_in, 0)] must be [counter_long], found value [0] type [integer]\",\n-            error(\"FROM tests | eval x = case(name == \\\"a\\\", network.bytes_in, 0)\", tsdb)\n+            \"1:22: third argument of [case(name == \\\"a\\\", network.bytes_in, 0)] must be [counter_long], found value [0] type [integer]\",\n+            error(\"FROM test | eval x = case(name == \\\"a\\\", network.bytes_in, 0)\", tsdb)\n         );\n     }\n \n@@ -1843,53 +1840,53 @@ public void testToDatePeriodTimeDurationInInvalidPosition() {\n     public void testToDatePeriodToTimeDurationWithInvalidType() {\n         assertEquals(\n             \"1:36: argument of [1.5::date_period] must be [date_period or string], found value [1.5] type [double]\",\n-            error(\"from types | EVAL x = birth_date + 1.5::date_period\")\n+            error(\"from test  | EVAL x = birth_date + 1.5::date_period\")\n         );\n         assertEquals(\n             \"1:37: argument of [to_timeduration(1)] must be [time_duration or string], found value [1] type [integer]\",\n-            error(\"from types  | EVAL x = birth_date - to_timeduration(1)\")\n+            error(\"from test   | EVAL x = birth_date - to_timeduration(1)\")\n         );\n         assertEquals(\n             \"1:45: argument of [x::date_period] must be [date_period or string], found value [x] type [double]\",\n-            error(\"from types | EVAL x = 1.5, y = birth_date + x::date_period\")\n+            error(\"from test  | EVAL x = 1.5, y = birth_date + x::date_period\")\n         );\n         assertEquals(\n             \"1:44: argument of [to_timeduration(x)] must be [time_duration or string], found value [x] type [integer]\",\n-            error(\"from types  | EVAL x = 1, y = birth_date - to_timeduration(x)\")\n+            error(\"from test   | EVAL x = 1, y = birth_date - to_timeduration(x)\")\n         );\n         assertEquals(\n             \"1:64: argument of [x::date_period] must be [date_period or string], found value [x] type [datetime]\",\n-            error(\"from types | EVAL x = \\\"2024-09-08\\\"::datetime, y = birth_date + x::date_period\")\n+            error(\"from test  | EVAL x = \\\"2024-09-08\\\"::datetime, y = birth_date + x::date_period\")\n         );\n         assertEquals(\n             \"1:65: argument of [to_timeduration(x)] must be [time_duration or string], found value [x] type [datetime]\",\n-            error(\"from types  | EVAL x = \\\"2024-09-08\\\"::datetime, y = birth_date - to_timeduration(x)\")\n+            error(\"from test   | EVAL x = \\\"2024-09-08\\\"::datetime, y = birth_date - to_timeduration(x)\")\n         );\n         assertEquals(\n             \"1:58: argument of [x::date_period] must be [date_period or string], found value [x] type [ip]\",\n-            error(\"from types | EVAL x = \\\"2024-09-08\\\"::ip, y = birth_date + x::date_period\")\n+            error(\"from test  | EVAL x = \\\"2024-09-08\\\"::ip, y = birth_date + x::date_period\")\n         );\n         assertEquals(\n             \"1:59: argument of [to_timeduration(x)] must be [time_duration or string], found value [x] type [ip]\",\n-            error(\"from types  | EVAL x = \\\"2024-09-08\\\"::ip, y = birth_date - to_timeduration(x)\")\n+            error(\"from test   | EVAL x = \\\"2024-09-08\\\"::ip, y = birth_date - to_timeduration(x)\")\n         );\n     }\n \n     public void testIntervalAsString() {\n         // DateTrunc\n         for (String interval : List.of(\"1 minu\", \"1 dy\", \"1.5 minutes\", \"0.5 days\", \"minutes 1\", \"day 5\")) {\n             assertThat(\n-                error(\"from types  | EVAL x = date_trunc(\\\"\" + interval + \"\\\", \\\"1991-06-26T00:00:00.000Z\\\")\"),\n+                error(\"from test   | EVAL x = date_trunc(\\\"\" + interval + \"\\\", \\\"1991-06-26T00:00:00.000Z\\\")\"),\n                 containsString(\"1:35: Cannot convert string [\" + interval + \"] to [DATE_PERIOD or TIME_DURATION]\")\n             );\n             assertThat(\n-                error(\"from types  | EVAL x = \\\"1991-06-26T00:00:00.000Z\\\", y = date_trunc(\\\"\" + interval + \"\\\", x::datetime)\"),\n+                error(\"from test   | EVAL x = \\\"1991-06-26T00:00:00.000Z\\\", y = date_trunc(\\\"\" + interval + \"\\\", x::datetime)\"),\n                 containsString(\"1:67: Cannot convert string [\" + interval + \"] to [DATE_PERIOD or TIME_DURATION]\")\n             );\n         }\n         for (String interval : List.of(\"1\", \"0.5\", \"invalid\")) {\n             assertThat(\n-                error(\"from types  | EVAL x = date_trunc(\\\"\" + interval + \"\\\", \\\"1991-06-26T00:00:00.000Z\\\")\"),\n+                error(\"from test   | EVAL x = date_trunc(\\\"\" + interval + \"\\\", \\\"1991-06-26T00:00:00.000Z\\\")\"),\n                 containsString(\n                     \"1:24: first argument of [date_trunc(\\\"\"\n                         + interval\n@@ -1899,7 +1896,7 @@ public void testIntervalAsString() {\n                 )\n             );\n             assertThat(\n-                error(\"from types  | EVAL x = \\\"1991-06-26T00:00:00.000Z\\\", y = date_trunc(\\\"\" + interval + \"\\\", x::datetime)\"),\n+                error(\"from test   | EVAL x = \\\"1991-06-26T00:00:00.000Z\\\", y = date_trunc(\\\"\" + interval + \"\\\", x::datetime)\"),\n                 containsString(\n                     \"1:56: first argument of [date_trunc(\\\"\"\n                         + interval\n@@ -2191,8 +2188,8 @@ public void testFilterByAggregate() {\n         );\n         assertEquals(\"1:23: aggregate function [max(a)] not allowed outside STATS command\", error(\"ROW a = 1 | WHERE 1 + max(a) > 0\"));\n         assertEquals(\n-            \"1:24: aggregate function [min(languages)] not allowed outside STATS command\",\n-            error(\"FROM employees | WHERE min(languages) > 2\")\n+            \"1:19: aggregate function [min(languages)] not allowed outside STATS command\",\n+            error(\"FROM test | WHERE min(languages) > 2\")\n         );\n         assertEquals(\n             \"1:19: aggregate function [present(gender)] not allowed outside STATS command\",\n@@ -2848,7 +2845,7 @@ public void testLimitBeforeInlineStats_WithFork() {\n \n         assertThat(\n             error(\n-                \"FROM employees\\n\"\n+                \"FROM test\\n\"\n                     + \"| KEEP emp_no, languages, gender\\n\"\n                     + \"| FORK (WHERE emp_no == 10048 OR emp_no == 10081)\\n\"\n                     + \"       (WHERE emp_no == 10081 OR emp_no == 10087)\\n\"\n@@ -2864,7 +2861,7 @@ public void testLimitBeforeInlineStats_WithFork() {\n \n         assertThat(\n             error(\n-                \"FROM employees\\n\"\n+                \"FROM test\\n\"\n                     + \"| KEEP emp_no, languages, gender\\n\"\n                     + \"| FORK (WHERE emp_no == 10048 OR emp_no == 10081)\\n\"\n                     + \"       (WHERE emp_no == 10081 OR emp_no == 10087)\\n\""
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/expression/function/CheckLicenseTests.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "patch": "@@ -42,7 +42,7 @@\n public class CheckLicenseTests extends ESTestCase {\n \n     private final EsqlParser parser = new EsqlParser();\n-    private final String esql = \"from tests | eval license() | LIMIT 10\";\n+    private final String esql = \"from test | eval license() | LIMIT 10\";\n \n     public void testLicense() {\n         for (License.OperationMode functionLicense : License.OperationMode.values()) {"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLocalPhysicalPlanOptimizerTests.java",
      "status": "modified",
      "additions": 10,
      "deletions": 3,
      "changes": 13,
      "patch": "@@ -47,6 +47,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n \n public class AbstractLocalPhysicalPlanOptimizerTests extends MapperServiceTestCase {\n     protected final Configuration config;\n@@ -101,7 +102,7 @@ public void init() {\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                timeSeriesIndex,\n+                indexResolutions(timeSeriesIndex),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -123,7 +124,7 @@ private Analyzer makeAnalyzer(String mappingFileName, EnrichResolution enrichRes\n             testAnalyzerContext(\n                 config,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()\n@@ -138,7 +139,13 @@ protected Analyzer makeAnalyzer(String mappingFileName) {\n \n     protected Analyzer makeAnalyzer(IndexResolution indexResolution) {\n         return new Analyzer(\n-            testAnalyzerContext(config, new EsqlFunctionRegistry(), indexResolution, new EnrichResolution(), emptyInferenceResolution()),\n+            testAnalyzerContext(\n+                config,\n+                new EsqlFunctionRegistry(),\n+                indexResolutions(indexResolution),\n+                new EnrichResolution(),\n+                emptyInferenceResolution()\n+            ),\n             new Verifier(new Metrics(new EsqlFunctionRegistry()), new XPackLicenseState(() -> 0L))\n         );\n     }"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLogicalPlanOptimizerTests.java",
      "status": "modified",
      "additions": 18,
      "deletions": 31,
      "changes": 49,
      "patch": "@@ -18,7 +18,6 @@\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n@@ -38,6 +37,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultInferenceResolution;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.type.DataType.KEYWORD;\n import static org.hamcrest.Matchers.containsString;\n \n@@ -105,31 +105,30 @@ public static void init() {\n             \"mapping-languages.json\"\n         );\n \n-        // Most tests used data from the test index, so we load it here, and use it in the plan() function.\n+        // Most tests use either \"test\" or \"employees\" as the index name, but for the same mapping\n         mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n+        EsIndex employees = new EsIndex(\"employees\", mapping, Map.of(\"employees\", IndexMode.STANDARD));\n         analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test, employees),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n             TEST_VERIFIER\n         );\n \n-        // Some tests use data from the airports index, so we load it here, and use it in the plan_airports() function.\n+        // Some tests use data from the airports index, so we load it here, and use it in the planAirports() function.\n         mappingAirports = loadMapping(\"mapping-airports.json\");\n         EsIndex airports = new EsIndex(\"airports\", mappingAirports, Map.of(\"airports\", IndexMode.STANDARD));\n-        IndexResolution getIndexResultAirports = IndexResolution.valid(airports);\n         analyzerAirports = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResultAirports,\n+                indexResolutions(airports),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()\n@@ -140,12 +139,11 @@ public static void init() {\n         // Some tests need additional types, so we load that index here and use it in the plan_types() function.\n         mappingTypes = loadMapping(\"mapping-all-types.json\");\n         EsIndex types = new EsIndex(\"types\", mappingTypes, Map.of(\"types\", IndexMode.STANDARD));\n-        IndexResolution getIndexResultTypes = IndexResolution.valid(types);\n         analyzerTypes = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResultTypes,\n+                indexResolutions(types),\n                 enrichResolution,\n                 defaultInferenceResolution()\n             ),\n@@ -155,25 +153,24 @@ public static void init() {\n         // Some tests use mappings from mapping-extra.json to be able to test more types so we load it here\n         mappingExtra = loadMapping(\"mapping-extra.json\");\n         EsIndex extra = new EsIndex(\"extra\", mappingExtra, Map.of(\"extra\", IndexMode.STANDARD));\n-        IndexResolution getIndexResultExtra = IndexResolution.valid(extra);\n         analyzerExtra = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResultExtra,\n+                indexResolutions(extra),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n             TEST_VERIFIER\n         );\n \n         metricMapping = loadMapping(\"k8s-mappings.json\");\n-        var metricsIndex = IndexResolution.valid(new EsIndex(\"k8s\", metricMapping, Map.of(\"k8s\", IndexMode.TIME_SERIES)));\n+        var metricsIndex = new EsIndex(\"k8s\", metricMapping, Map.of(\"k8s\", IndexMode.TIME_SERIES));\n         metricsAnalyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                metricsIndex,\n+                indexResolutions(metricsIndex),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -185,34 +182,30 @@ public static void init() {\n             \"partial_type_keyword\",\n             new EsField(\"partial_type_keyword\", KEYWORD, emptyMap(), true, EsField.TimeSeriesFieldType.NONE)\n         );\n-        var multiIndex = IndexResolution.valid(\n-            new EsIndex(\n-                \"multi_index\",\n-                multiIndexMapping,\n-                Map.of(\"test1\", IndexMode.STANDARD, \"test2\", IndexMode.STANDARD),\n-                Set.of(\"partial_type_keyword\")\n-            )\n+        var multiIndex = new EsIndex(\n+            \"multi_index\",\n+            multiIndexMapping,\n+            Map.of(\"test1\", IndexMode.STANDARD, \"test2\", IndexMode.STANDARD),\n+            Set.of(\"partial_type_keyword\")\n         );\n         multiIndexAnalyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                multiIndex,\n+                indexResolutions(multiIndex),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n             TEST_VERIFIER\n         );\n \n         var sampleDataMapping = loadMapping(\"mapping-sample_data.json\");\n-        var sampleDataIndex = IndexResolution.valid(\n-            new EsIndex(\"sample_data\", sampleDataMapping, Map.of(\"sample_data\", IndexMode.STANDARD))\n-        );\n+        var sampleDataIndex = new EsIndex(\"sample_data\", sampleDataMapping, Map.of(\"sample_data\", IndexMode.STANDARD));\n         sampleDataIndexAnalyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                sampleDataIndex,\n+                indexResolutions(sampleDataIndex),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -230,25 +223,19 @@ protected LogicalPlan plan(String query) {\n \n     protected LogicalPlan plan(String query, LogicalPlanOptimizer optimizer) {\n         var analyzed = analyzer.analyze(parser.createStatement(query));\n-        // System.out.println(analyzed);\n         var optimized = optimizer.optimize(analyzed);\n-        // System.out.println(optimized);\n         return optimized;\n     }\n \n     protected LogicalPlan planAirports(String query) {\n         var analyzed = analyzerAirports.analyze(parser.createStatement(query));\n-        // System.out.println(analyzed);\n         var optimized = logicalOptimizer.optimize(analyzed);\n-        // System.out.println(optimized);\n         return optimized;\n     }\n \n     protected LogicalPlan planExtra(String query) {\n         var analyzed = analyzerExtra.analyze(parser.createStatement(query));\n-        // System.out.println(analyzed);\n         var optimized = logicalOptimizer.optimize(analyzed);\n-        // System.out.println(optimized);\n         return optimized;\n     }\n "
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalLogicalPlanOptimizerTests.java",
      "status": "modified",
      "additions": 4,
      "deletions": 7,
      "changes": 11,
      "patch": "@@ -45,7 +45,6 @@\n import org.elasticsearch.xpack.esql.expression.predicate.nulls.IsNotNull;\n import org.elasticsearch.xpack.esql.expression.predicate.operator.arithmetic.Add;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.OptimizerRules;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.local.InferIsNotNull;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n@@ -97,6 +96,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.unboundLogicalOptimizerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.tree.Source.EMPTY;\n import static org.elasticsearch.xpack.esql.core.type.DataType.INTEGER;\n import static org.elasticsearch.xpack.esql.core.type.DataType.KEYWORD;\n@@ -124,14 +124,13 @@ public static void init() {\n \n         mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         logicalOptimizer = new LogicalPlanOptimizer(unboundLogicalOptimizerContext());\n \n         analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),\n@@ -518,14 +517,13 @@ public void testSparseDocument() throws Exception {\n         SearchStats searchStats = statsForExistingField(\"field000\", \"field001\", \"field002\", \"field003\", \"field004\");\n \n         EsIndex index = new EsIndex(\"large\", large, Map.of(\"large\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(index);\n         var logicalOptimizer = new LogicalPlanOptimizer(unboundLogicalOptimizerContext());\n \n         var analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(index),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),\n@@ -1114,13 +1112,12 @@ private static Analyzer analyzerWithUnionTypeMapping() {\n             Map.of(\"integer_long_field\", unionTypeField),\n             Map.of(\"test1\", IndexMode.STANDARD, \"test2\", IndexMode.STANDARD)\n         );\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n \n         return new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalPhysicalPlanOptimizerTests.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "patch": "@@ -2278,7 +2278,7 @@ public void testToDateNanosPushDown() {\n         plannerOptimizerDateDateNanosUnionTypes = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(indexWithUnionTypedFields));\n         var stats = EsqlTestUtils.statsForExistingField(\"date_and_date_nanos\", \"date_and_date_nanos_and_long\");\n         String query = \"\"\"\n-            from test*\n+            from index*\n             | where date_and_date_nanos < \"2025-01-01\" and date_and_date_nanos_and_long::date_nanos >= \"2024-01-01\\\"\"\"\";\n         var plan = plannerOptimizerDateDateNanosUnionTypes.plan(query, stats);\n "
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LogicalPlanOptimizerTests.java",
      "status": "modified",
      "additions": 27,
      "deletions": 28,
      "changes": 55,
      "patch": "@@ -97,7 +97,6 @@\n import org.elasticsearch.xpack.esql.expression.predicate.operator.comparison.LessThan;\n import org.elasticsearch.xpack.esql.expression.predicate.operator.comparison.NotEquals;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.LiteralsOnTheRight;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.OptimizerRules;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.PruneRedundantOrderBy;\n@@ -180,6 +179,7 @@\n import static org.elasticsearch.xpack.esql.analysis.Analyzer.NO_FIELDS;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.analyze;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultAnalyzer;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.expression.Literal.NULL;\n import static org.elasticsearch.xpack.esql.core.tree.Source.EMPTY;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DOUBLE;\n@@ -4298,7 +4298,7 @@ public void testIsNotNullConstraintForAliasedExpressions() {\n      */\n     public void testSpatialTypesAndStatsUseDocValues() {\n         var plan = planAirports(\"\"\"\n-            from test\n+            from airports\n             | stats centroid = st_centroid_agg(location)\n             \"\"\");\n \n@@ -4325,7 +4325,7 @@ public void testSpatialTypesAndStatsUseDocValues() {\n      */\n     public void testSpatialTypesAndStatsUseDocValuesWithEval() {\n         var plan = planAirports(\"\"\"\n-            from test\n+            from airports\n             | stats centroid = st_centroid_agg(to_geopoint(location))\n             \"\"\");\n \n@@ -4361,7 +4361,7 @@ public void testTrivialTypeConversionWrittenAway() {\n                 default -> \"to_\" + type;\n             };\n             var field = \"types.\" + type;\n-            var plan = planExtra(\"from test | eval new_\" + field + \" = \" + func + \"(\" + field + \")\");\n+            var plan = planExtra(\"from extra | eval new_\" + field + \" = \" + func + \"(\" + field + \")\");\n             var eval = as(plan, Eval.class);\n             var alias = as(eval.fields().get(0), Alias.class);\n             assertThat(func + \"(\" + field + \")\", alias.name(), equalTo(\"new_\" + field));\n@@ -5318,12 +5318,11 @@ private static boolean oneLeaveIsNull(Expression e) {\n \n     public void testEmptyMappingIndex() {\n         EsIndex empty = new EsIndex(\"empty_test\", emptyMap(), Map.of());\n-        IndexResolution getIndexResultAirports = IndexResolution.valid(empty);\n         var analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResultAirports,\n+                indexResolutions(empty),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -8571,7 +8570,7 @@ public void testSampleMerged() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n         var query = \"\"\"\n-            FROM TEST\n+            FROM test\n             | SAMPLE .3\n             | EVAL irrelevant1 = 1\n             | SAMPLE .5\n@@ -8601,7 +8600,7 @@ public void testSamplePushDown() {\n             \"GROK first_name \\\"%{WORD:bar}\\\"\",\n             \"DISSECT first_name \\\"%{z}\\\"\"\n         )) {\n-            var query = \"FROM TEST | \" + command + \" | SAMPLE .5\";\n+            var query = \"FROM test | \" + command + \" | SAMPLE .5\";\n             var optimized = optimizedPlan(query);\n \n             var unary = as(optimized, UnaryPlan.class);\n@@ -8616,7 +8615,7 @@ public void testSamplePushDown() {\n     public void testSamplePushDown_sort() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n-        var query = \"FROM TEST | WHERE emp_no > 0 | SAMPLE 0.5 | LIMIT 100\";\n+        var query = \"FROM test | WHERE emp_no > 0 | SAMPLE 0.5 | LIMIT 100\";\n         var optimized = optimizedPlan(query);\n \n         var limit = as(optimized, Limit.class);\n@@ -8630,7 +8629,7 @@ public void testSamplePushDown_sort() {\n     public void testSamplePushDown_where() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n-        var query = \"FROM TEST | SORT emp_no | SAMPLE 0.5 | LIMIT 100\";\n+        var query = \"FROM test | SORT emp_no | SAMPLE 0.5 | LIMIT 100\";\n         var optimized = optimizedPlan(query);\n \n         var topN = as(optimized, TopN.class);\n@@ -8644,7 +8643,7 @@ public void testSampleNoPushDown() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n         for (var command : List.of(\"LIMIT 100\", \"MV_EXPAND languages\", \"STATS COUNT()\")) {\n-            var query = \"FROM TEST | \" + command + \" | SAMPLE .5\";\n+            var query = \"FROM test | \" + command + \" | SAMPLE .5\";\n             var optimized = optimizedPlan(query);\n \n             var limit = as(optimized, Limit.class);\n@@ -8668,7 +8667,7 @@ public void testSampleNoPushDownLookupJoin() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n         var query = \"\"\"\n-            FROM TEST\n+            FROM test\n             | EVAL language_code = emp_no\n             | LOOKUP JOIN languages_lookup ON language_code\n             | SAMPLE .5\n@@ -8696,7 +8695,7 @@ public void testSampleNoPushDownChangePoint() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n         var query = \"\"\"\n-            FROM TEST\n+            FROM test\n             | CHANGE_POINT emp_no ON hire_date\n             | SAMPLE .5\n             \"\"\";\n@@ -8712,7 +8711,7 @@ public void testSampleNoPushDownChangePoint() {\n \n     public void testPushDownConjunctionsToKnnPrefilter() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2]) and integer > 10\n             \"\"\";\n         var optimized = planTypes(query);\n@@ -8730,7 +8729,7 @@ public void testPushDownConjunctionsToKnnPrefilter() {\n \n     public void testPushDownMultipleFiltersToKnnPrefilter() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2])\n             | where integer > 10\n             | where keyword == \"test\"\n@@ -8751,7 +8750,7 @@ public void testPushDownMultipleFiltersToKnnPrefilter() {\n \n     public void testNotPushDownDisjunctionsToKnnPrefilter() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2]) or integer > 10\n             \"\"\";\n         var optimized = planTypes(query);\n@@ -8778,7 +8777,7 @@ public void testPushDownConjunctionsAndNotDisjunctionsToKnnPrefilter() {\n          */\n         // Both conjunctions are pushed down to knn prefilters, disjunctions are not\n         var query = \"\"\"\n-            from test\n+            from types\n             | where\n                  ((knn(dense_vector, [0, 1, 2]) or integer > 10) and keyword == \"test\") and ((short < 5) or (double > 5.0))\n             \"\"\";\n@@ -8811,7 +8810,7 @@ public void testMorePushDownConjunctionsAndNotDisjunctionsToKnnPrefilter() {\n          */\n         // Just the conjunction is pushed down to knn prefilters, disjunctions are not\n         var query = \"\"\"\n-            from test\n+            from types\n             | where\n                  ((knn(dense_vector, [0, 1, 2]) and integer > 10) or keyword == \"test\") or ((short < 5) and (double > 5.0))\n             \"\"\";\n@@ -8838,7 +8837,7 @@ public void testMultipleKnnQueriesInPrefilters() {\n                     knn(dense_vector, [4, 5, 6], 10)\n          */\n         var query = \"\"\"\n-            from test\n+            from types\n             | where ((knn(dense_vector, [0, 1, 2]) or integer > 10) and ((keyword == \"test\") or knn(dense_vector, [4, 5, 6])))\n             \"\"\";\n         var optimized = planTypes(query);\n@@ -8870,7 +8869,7 @@ public void testMultipleKnnQueriesInPrefilters() {\n \n     public void testKnnImplicitLimit() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2])\n             \"\"\";\n         var optimized = planTypes(query);\n@@ -8883,7 +8882,7 @@ public void testKnnImplicitLimit() {\n \n     public void testKnnWithLimit() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2])\n             | limit 10\n             \"\"\";\n@@ -8897,7 +8896,7 @@ public void testKnnWithLimit() {\n \n     public void testKnnWithTopN() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | sort _score desc\n             | limit 10\n@@ -8912,7 +8911,7 @@ public void testKnnWithTopN() {\n \n     public void testKnnWithMultipleLimitsAfterTopN() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | limit 20\n             | sort _score desc\n@@ -8930,7 +8929,7 @@ public void testKnnWithMultipleLimitsAfterTopN() {\n \n     public void testKnnWithMultipleLimitsCombined() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | limit 20\n             | limit 10\n@@ -8946,7 +8945,7 @@ public void testKnnWithMultipleLimitsCombined() {\n \n     public void testKnnWithMultipleClauses() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2]) and match(keyword, \"test\")\n             | where knn(dense_vector, [1, 2, 3])\n             | sort _score\n@@ -8967,14 +8966,14 @@ public void testKnnWithMultipleClauses() {\n \n     public void testKnnWithStats() {\n         assertThat(\n-            typesError(\"from test | where knn(dense_vector, [0, 1, 2]) | stats c = count(*)\"),\n+            typesError(\"from types | where knn(dense_vector, [0, 1, 2]) | stats c = count(*)\"),\n             containsString(\"Knn function must be used with a LIMIT clause\")\n         );\n     }\n \n     public void testKnnWithRerankAmdTopN() {\n         assertThat(typesError(\"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | rerank \"some text\" on text with { \"inference_id\" : \"reranking-inference-id\" }\n             | sort _score desc\n@@ -8984,7 +8983,7 @@ public void testKnnWithRerankAmdTopN() {\n \n     public void testKnnWithRerankAmdLimit() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | rerank \"some text\" on text with { \"inference_id\" : \"reranking-inference-id\" }\n             | limit 100"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/PhysicalPlanOptimizerTests.java",
      "status": "modified",
      "additions": 32,
      "deletions": 18,
      "changes": 50,
      "patch": "@@ -189,6 +189,7 @@\n import static org.elasticsearch.xpack.esql.SerializationTestUtils.assertSerialization;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.analyze;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.expression.Expressions.name;\n import static org.elasticsearch.xpack.esql.core.expression.Expressions.names;\n import static org.elasticsearch.xpack.esql.core.expression.function.scalar.FunctionTestUtils.l;\n@@ -393,13 +394,23 @@ TestDataSource makeTestDataSource(\n         SearchStats stats\n     ) {\n         Map<String, EsField> mapping = loadMapping(mappingFileName);\n-        EsIndex index = new EsIndex(indexName, mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(index);\n+        EsIndex[] indexes = new EsIndex[1 + lookupResolution.size()];\n+        indexes[0] = new EsIndex(indexName, mapping, Map.of(indexName, IndexMode.STANDARD));\n+        for (int i = 0; i < lookupResolution.size(); i++) {\n+            indexes[i + 1] = lookupResolution.values().toArray(new IndexResolution[0])[i].get();\n+        }\n         Analyzer analyzer = new Analyzer(\n-            testAnalyzerContext(config, functionRegistry, getIndexResult, lookupResolution, enrichResolution, emptyInferenceResolution()),\n+            testAnalyzerContext(\n+                config,\n+                functionRegistry,\n+                indexResolutions(indexes),\n+                lookupResolution,\n+                enrichResolution,\n+                emptyInferenceResolution()\n+            ),\n             TEST_VERIFIER\n         );\n-        return new TestDataSource(mapping, index, analyzer, stats);\n+        return new TestDataSource(mapping, indexes[0], analyzer, stats);\n     }\n \n     TestDataSource makeTestDataSource(\n@@ -1440,7 +1451,7 @@ public void testPushMultipleBinaryLogicFilters() {\n      */\n     public void testPushMultipleFunctions() {\n         var plan = physicalPlan(\"\"\"\n-            from airports\n+            from test\n             | where starts_with(first_name, \"*Firs\") or ends_with(first_name, \"irst*\")\n             | where ends_with(last_name, \"ast\")\n             \"\"\");\n@@ -3700,7 +3711,7 @@ public void testSpatialTypesAndStatsCentroidUseDocValues() {\n             for (boolean withDocValues : new boolean[] { false, true }) {\n                 var testData = withDocValues ? airports : airportsNoDocValues;\n                 var fieldExtractPreference = withDocValues ? FieldExtractPreference.DOC_VALUES : FieldExtractPreference.NONE;\n-                var plan = physicalPlan(query, testData);\n+                var plan = physicalPlan(query.replace(\"airports\", testData.index.name()), testData);\n \n                 var limit = as(plan, LimitExec.class);\n                 var agg = as(limit.child(), AggregateExec.class);\n@@ -3763,7 +3774,7 @@ public void testSpatialTypesAndStatsExtentUseDocValues() {\n             for (boolean withDocValues : new boolean[] { false, true }) {\n                 var fieldExtractPreference = withDocValues ? FieldExtractPreference.DOC_VALUES : FieldExtractPreference.NONE;\n                 var testData = withDocValues ? airports : airportsNoDocValues;\n-                var plan = physicalPlan(query, testData);\n+                var plan = physicalPlan(query.replace(\"airports\", testData.index.name()), testData);\n \n                 var limit = as(plan, LimitExec.class);\n                 var agg = as(limit.child(), AggregateExec.class);\n@@ -3826,7 +3837,7 @@ public void testSpatialTypesAndStatsExtentAndCentroidUseDocValues() {\n             for (boolean withDocValues : new boolean[] { false, true }) {\n                 var fieldExtractPreference = withDocValues ? FieldExtractPreference.DOC_VALUES : FieldExtractPreference.NONE;\n                 var testData = withDocValues ? airports : airportsNoDocValues;\n-                var plan = physicalPlan(query, testData);\n+                var plan = physicalPlan(query.replace(\"airports\", testData.index.name()), testData);\n \n                 var limit = as(plan, LimitExec.class);\n                 var agg = as(limit.child(), AggregateExec.class);\n@@ -3875,7 +3886,7 @@ public void testSpatialTypesAndStatsExtentOfGeoShapeUsesBinaryExtraction() {\n         var query = \"FROM airports_city_boundaries | STATS extent = ST_EXTENT_AGG(city_boundary)\";\n         for (boolean useDocValues : new Boolean[] { true, false }) {\n             var testData = useDocValues ? airportsCityBoundaries : airportsCityBoundariesNoDocValues;\n-            var plan = physicalPlan(query, testData);\n+            var plan = physicalPlan(query.replace(\"airports_city_boundaries\", testData.index.name()), testData);\n \n             var limit = as(plan, LimitExec.class);\n             var agg = as(limit.child(), AggregateExec.class);\n@@ -3938,11 +3949,14 @@ public void testSpatialTypesAndStatsExtentOfShapesNegativeCases() {\n      */\n     public void testSpatialTypesAndStatsExtentOfCartesianShapesWithAndWithoutDocValues() {\n         for (boolean hasDocValues : new boolean[] { true, false }) {\n-            var query = \"\"\"\n-                FROM cartesian_multipolygons \\\n-                | STATS extent = ST_EXTENT_AGG(shape)\"\"\";\n-            var testData = hasDocValues ? cartesianMultipolygons : cartesianMultipolygonsNoDocValues;\n-            var fieldExtractPreference = hasDocValues ? FieldExtractPreference.EXTRACT_SPATIAL_BOUNDS : FieldExtractPreference.NONE;\n+            var query = \"FROM cartesian_multipolygons | STATS extent = ST_EXTENT_AGG(shape)\";\n+            var testData = cartesianMultipolygons;\n+            var fieldExtractPreference = FieldExtractPreference.EXTRACT_SPATIAL_BOUNDS;\n+            if (hasDocValues == false) {\n+                query = \"FROM cartesian_multipolygons_no_doc_values | STATS extent = ST_EXTENT_AGG(shape)\";\n+                testData = cartesianMultipolygonsNoDocValues;\n+                fieldExtractPreference = FieldExtractPreference.NONE;\n+            }\n             var plan = physicalPlan(query, testData);\n \n             var limit = as(plan, LimitExec.class);\n@@ -3990,15 +4004,15 @@ public void testSpatialTypesAndStatsExtentOfCartesianShapesWithAndWithoutDocValu\n      */\n     public void testMixedSpatialBoundsAndPointsExtracted() {\n         var query = \"\"\"\n-            FROM airports_city_boundaries \\\n+            FROM INDEX \\\n             | STATS extent = ST_EXTENT_AGG(city_boundary), centroid = ST_CENTROID_AGG(city_location)\"\"\";\n         for (boolean pointDocValues : new Boolean[] { true, false }) {\n             for (boolean shapeDocValues : new Boolean[] { true, false }) {\n                 var testData = pointDocValues\n                     ? (shapeDocValues ? airportsCityBoundaries : airportsCityBoundariesNoShapeDocValues)\n                     : (shapeDocValues ? airportsCityBoundariesNoPointDocValues : airportsCityBoundariesNoDocValues);\n                 var msg = \"DocValues[point:\" + pointDocValues + \", shape:\" + shapeDocValues + \"]\";\n-                var plan = physicalPlan(query, testData);\n+                var plan = physicalPlan(query.replace(\"INDEX\", testData.index.name()), testData);\n \n                 var limit = as(plan, LimitExec.class);\n                 var agg = as(limit.child(), AggregateExec.class);\n@@ -4289,7 +4303,7 @@ public void testSpatialTypesAndStatsUseDocValuesMultiAggregationsGrouped() {\n             var plan = this.physicalPlan(\"\"\"\n                 FROM airports\n                 | STATS centroid=ST_CENTROID_AGG(location), count=COUNT() BY scalerank\n-                \"\"\", testData);\n+                \"\"\".replace(\"airports\", testData.index.name()), testData);\n \n             var limit = as(plan, LimitExec.class);\n             var agg = as(limit.child(), AggregateExec.class);\n@@ -4856,7 +4870,7 @@ public void testPushSpatialIntersectsStringToSourceAndUseDocValuesForCentroid()\n                     var testData = useDocValues\n                         ? (isIndexed ? airports : airportsNotIndexed)\n                         : (isIndexed ? airportsNoDocValues : airportsNotIndexedNorDocValues);\n-                    var plan = this.physicalPlan(query, testData);\n+                    var plan = this.physicalPlan(query.replace(\"airports\", testData.index.name()), testData);\n                     var limit = as(plan, LimitExec.class);\n                     var agg = as(limit.child(), AggregateExec.class);\n                     assertThat(\"No groupings in aggregation\", agg.groupings().size(), equalTo(0));"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/HoistRemoteEnrichTopNTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 3,
      "changes": 5,
      "patch": "@@ -17,7 +17,6 @@\n import org.elasticsearch.xpack.esql.expression.Order;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.AbstractLogicalPlanOptimizerTests;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.Eval;\n@@ -34,6 +33,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.is;\n import static org.hamcrest.Matchers.startsWith;\n@@ -127,12 +127,11 @@ private LogicalPlan planWithPolicyOverride(String query) {\n         );\n         var mapping = loadMapping(\"mapping-host_inventory.json\");\n         EsIndex inventory = new EsIndex(\"host_inventory\", mapping, Map.of(\"host_inventory\", IndexMode.STANDARD));\n-        IndexResolution resolution = IndexResolution.valid(inventory);\n         var analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                resolution,\n+                indexResolutions(inventory),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PropagateInlineEvalsTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 3,
      "changes": 5,
      "patch": "@@ -18,7 +18,6 @@\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.AbstractLogicalPlanOptimizerTests;\n import org.elasticsearch.xpack.esql.optimizer.LogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n@@ -42,6 +41,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultInferenceResolution;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.hamcrest.Matchers.contains;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.is;\n@@ -57,12 +57,11 @@ public static void init() {\n         parser = new EsqlParser();\n         mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 defaultLookupResolution(),\n                 new EnrichResolution(),\n                 defaultInferenceResolution()"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PushDownJoinPastProjectTests.java",
      "status": "modified",
      "additions": 5,
      "deletions": 5,
      "changes": 10,
      "patch": "@@ -174,7 +174,7 @@ public void testShadowingAfterPushdown() {\n     // \\_EsRelation[test_lookup][LOOKUP][emp_no{f}#37, languages{f}#40, salary{f}#42]\n     public void testShadowingAfterPushdown2() {\n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | RENAME emp_no AS x, salary AS salary2\n             | EVAL y = x, gender = last_name\n             | RENAME y AS languages, gender AS ln\n@@ -247,7 +247,7 @@ public void testShadowingAfterPushdownExpressionJoin() {\n         );\n \n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | RENAME languages as lang2\n             | EVAL y = emp_no\n             | RENAME y AS lang\n@@ -295,7 +295,7 @@ public void testShadowingAfterPushdownExpressionJoinKeepOrig() {\n         );\n \n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | RENAME languages as lang2\n             | EVAL y = emp_no\n             | RENAME y AS lang\n@@ -347,7 +347,7 @@ public void testShadowingAfterPushdownRenameExpressionJoin() {\n         );\n \n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | RENAME languages AS lang\n             | LOOKUP JOIN test_lookup ON lang == languages\n             | KEEP languages, emp_no, salary\n@@ -393,7 +393,7 @@ public void testShadowingAfterPushdownEvalExpressionJoin() {\n         );\n \n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | EVAL lang = languages + 0\n             | DROP languages\n             | LOOKUP JOIN test_lookup ON lang == languages"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/local/IgnoreNullMetricsTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 3,
      "changes": 5,
      "patch": "@@ -24,7 +24,6 @@\n import org.elasticsearch.xpack.esql.expression.predicate.logical.Or;\n import org.elasticsearch.xpack.esql.expression.predicate.nulls.IsNotNull;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.LocalLogicalOptimizerContext;\n import org.elasticsearch.xpack.esql.optimizer.LocalLogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.optimizer.LogicalOptimizerContext;\n@@ -49,6 +48,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.unboundLogicalOptimizerContext;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.instanceOf;\n \n@@ -84,12 +84,11 @@ private static void init() {\n             new EsField(\"_tsid\", DataType.TSID_DATA_TYPE, Map.of(), true, EsField.TimeSeriesFieldType.NONE)\n         );\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.TIME_SERIES));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/parser/AbstractStatementParserTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "patch": "@@ -34,7 +34,7 @@\n import static org.elasticsearch.xpack.esql.expression.function.FunctionResolutionStrategy.DEFAULT;\n import static org.hamcrest.Matchers.containsString;\n \n-abstract class AbstractStatementParserTests extends ESTestCase {\n+public abstract class AbstractStatementParserTests extends ESTestCase {\n \n     EsqlParser parser = new EsqlParser();\n \n@@ -52,7 +52,7 @@ LogicalPlan statement(String query, String arg) {\n         return statement(LoggerMessageFormat.format(null, query, arg), new QueryParams());\n     }\n \n-    LogicalPlan statement(String e) {\n+    protected LogicalPlan statement(String e) {\n         return statement(e, new QueryParams());\n     }\n "
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/FilterTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 3,
      "changes": 5,
      "patch": "@@ -28,7 +28,6 @@\n import org.elasticsearch.xpack.esql.core.util.Queries;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.io.stream.ExpressionQueryBuilder;\n import org.elasticsearch.xpack.esql.io.stream.PlanStreamInput;\n import org.elasticsearch.xpack.esql.io.stream.PlanStreamOutput;\n@@ -61,6 +60,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.unboundLogicalOptimizerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.SerializationTestUtils.assertSerialization;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.querydsl.query.Query.unscore;\n import static org.elasticsearch.xpack.esql.core.util.Queries.Clause.FILTER;\n import static org.elasticsearch.xpack.esql.core.util.Queries.Clause.MUST;\n@@ -86,7 +86,6 @@ public static void init() {\n \n         Map<String, EsField> mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         logicalOptimizer = new LogicalPlanOptimizer(unboundLogicalOptimizerContext());\n         TransportVersion minimumVersion = logicalOptimizer.context().minimumVersion();\n         physicalPlanOptimizer = new PhysicalPlanOptimizer(new PhysicalOptimizerContext(EsqlTestUtils.TEST_CFG, minimumVersion));\n@@ -96,7 +95,7 @@ public static void init() {\n             new AnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 Map.of(),\n                 EsqlTestUtils.emptyPolicyResolution(),\n                 emptyInferenceResolution(),"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/PlanConcurrencyCalculatorTests.java",
      "status": "modified",
      "additions": 25,
      "deletions": 25,
      "changes": 50,
      "patch": "@@ -36,76 +36,76 @@\n public class PlanConcurrencyCalculatorTests extends ESTestCase {\n     public void testSimpleLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             \"\"\", 9);\n     }\n \n     public void testLimitZero() {\n-        assertConcurrency(\"FROM x | LIMIT 0\", null);\n+        assertConcurrency(\"FROM test | LIMIT 0\", null);\n     }\n \n     public void testBiggestPragmaOverride() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             \"\"\", Integer.MAX_VALUE, Integer.MAX_VALUE);\n     }\n \n     public void testSmallestPragmaOverride() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             \"\"\", 1, 1);\n     }\n \n     public void testPragmaOverrideWithUnsupportedCommands() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | WHERE salary * 2 > 5\n             | LIMIT 512\n             \"\"\", 1, 1);\n     }\n \n     public void testImplicitLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             \"\"\", 9);\n     }\n \n     public void testStats() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | STATS COUNT(salary)\n             \"\"\", null);\n     }\n \n     public void testStatsWithLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             | STATS COUNT(salary)\n             \"\"\", 9);\n     }\n \n     public void testSortBeforeLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | SORT salary\n             \"\"\", null);\n     }\n \n     public void testSortAfterLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             | SORT salary\n             \"\"\", 9);\n     }\n \n     public void testStatsWithSortBeforeLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | SORT salary\n             | LIMIT 512\n             | STATS COUNT(salary)\n@@ -114,7 +114,7 @@ public void testStatsWithSortBeforeLimit() {\n \n     public void testStatsWithSortAfterLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | SORT salary\n             | LIMIT 512\n             | STATS COUNT(salary)\n@@ -123,39 +123,39 @@ public void testStatsWithSortAfterLimit() {\n \n     public void testWhereBeforeLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | WHERE salary * 2 > 5\n             | LIMIT 512\n             \"\"\", null);\n     }\n \n     public void testWhereAfterLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             | WHERE salary * 2 > 5\n             \"\"\", 9);\n     }\n \n     public void testWherePushedToLuceneQueryBeforeLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | WHERE first_name LIKE \"A%\"\n             | LIMIT 512\n             \"\"\", null);\n     }\n \n     public void testWherePushedToLuceneQueryAfterLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             | WHERE first_name LIKE \"A%\"\n             \"\"\", 9);\n     }\n \n     public void testExpand() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 2048\n             | MV_EXPAND salary\n             | LIMIT 512\n@@ -164,63 +164,63 @@ public void testExpand() {\n \n     public void testEval() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | EVAL x=salary*2\n             | LIMIT 512\n             \"\"\", 9);\n     }\n \n     public void testRename() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | RENAME salary as x\n             | LIMIT 512\n             \"\"\", 9);\n     }\n \n     public void testKeep() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | KEEP salary\n             | LIMIT 512\n             \"\"\", 9);\n     }\n \n     public void testDrop() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | DROP salary\n             | LIMIT 512\n             \"\"\", 9);\n     }\n \n     public void testDissect() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | DISSECT first_name \"%{a} %{b}\"\n             | LIMIT 512\n             \"\"\", 9);\n     }\n \n     public void testGrok() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | GROK first_name \"%{EMAILADDRESS:email}\"\n             | LIMIT 512\n             \"\"\", 9);\n     }\n \n     public void testEnrich() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | ENRICH languages ON first_name\n             | LIMIT 512\n             \"\"\", 9);\n     }\n \n     public void testLookup() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | RENAME salary as language_code\n             | LOOKUP JOIN languages_lookup on language_code\n             | LIMIT 512"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/QueryTranslatorTests.java",
      "status": "modified",
      "additions": 21,
      "deletions": 21,
      "changes": 42,
      "patch": "@@ -32,6 +32,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexWithDateDateNanosUnionType;\n import static org.hamcrest.Matchers.containsString;\n import static org.hamcrest.Matchers.matchesRegex;\n@@ -45,16 +46,15 @@ public class QueryTranslatorTests extends ESTestCase {\n \n     private static TestPlannerOptimizer plannerOptimizerDateDateNanosUnionTypes;\n \n-    private static Analyzer makeAnalyzer(String mappingFileName) {\n+    private static Analyzer makeAnalyzer(String indexName, String mappingFileName) {\n         var mapping = loadMapping(mappingFileName);\n-        EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n+        EsIndex test = new EsIndex(indexName, mapping, Map.of(indexName, IndexMode.STANDARD));\n \n         return new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),\n@@ -67,7 +67,7 @@ public static Analyzer makeAnalyzer(IndexResolution indexResolution) {\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                indexResolution,\n+                indexResolutions(indexResolution),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),\n@@ -77,8 +77,8 @@ public static Analyzer makeAnalyzer(IndexResolution indexResolution) {\n \n     @BeforeClass\n     public static void init() {\n-        plannerOptimizer = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(\"mapping-all-types.json\"));\n-        plannerOptimizerIPs = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(\"mapping-hosts.json\"));\n+        plannerOptimizer = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(\"test\", \"mapping-all-types.json\"));\n+        plannerOptimizerIPs = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(\"hosts\", \"mapping-hosts.json\"));\n     }\n \n     @Override\n@@ -331,35 +331,35 @@ public void testToDateNanos() {\n \n         // == term\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos == \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos == \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"term\":{\"date_and_date_nanos\":{\"value\":\"2025-01-01T00:00:00.000Z\",\"boost\":0.0}}}\"\"\"));\n \n         // != term\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"bool\":{\"must_not\":[{\"term\":{\"date_and_date_nanos\":{\"value\":\"2025-01-01T00:00:00.000Z\",\"boost\":0.0}}}],\\\n             \"boost\":0.0}}\"\"\"));\n \n         // > range\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos > \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos > \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"range\":{\"date_and_date_nanos\":{\"gt\":\"2025-01-01T00:00:00.000Z\",\"time_zone\":\"Z\",\\\n             \"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0}}}\"\"\"));\n \n         // >= range\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos >= \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos >= \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"range\":{\"date_and_date_nanos\":{\"gte\":\"2025-01-01T00:00:00.000Z\",\"time_zone\":\"Z\",\\\n             \"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0}}}\"\"\"));\n \n         // < range\n         assertQueryTranslationDateDateNanosUnionTypes(\n             \"\"\"\n-                FROM test* | WHERE date_and_date_nanos < \"2025-01-01\" and date_and_date_nanos_and_long::date_nanos > \"2025-01-01\\\"\"\"\",\n+                FROM index* | WHERE date_and_date_nanos < \"2025-01-01\" and date_and_date_nanos_and_long::date_nanos > \"2025-01-01\\\"\"\"\",\n             stats,\n             containsString(\"\"\"\n                 \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n@@ -369,21 +369,21 @@ public void testToDateNanos() {\n \n         // <= range\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos <= \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos <= \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"range\":{\"date_and_date_nanos\":{\"lte\":\"2025-01-01T00:00:00.000Z\",\"time_zone\":\"Z\",\\\n             \"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0}}}\"\"\"));\n \n         // <= and >=\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos <= \"2025-01-01\" and date_and_date_nanos > \"2020-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos <= \"2025-01-01\" and date_and_date_nanos > \"2020-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"range\":{\"date_and_date_nanos\":{\"gt\":\"2020-01-01T00:00:00.000Z\",\"lte\":\"2025-01-01T00:00:00.000Z\",\"time_zone\":\"Z\",\\\n             \"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0}}}\"\"\"));\n \n         // >= or <\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos >= \"2025-01-01\" or date_and_date_nanos < \"2020-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos >= \"2025-01-01\" or date_and_date_nanos < \"2020-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"range\":\\\\{\"date_and_date_nanos\":\\\\{\"gte\":\"2025-01-01T00:00:00.000Z\",\\\n             \"time_zone\":\"Z\",\"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -392,7 +392,7 @@ public void testToDateNanos() {\n \n         // > or =\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos > \"2025-01-01\" or date_and_date_nanos == \"2020-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos > \"2025-01-01\" or date_and_date_nanos == \"2020-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"range\":\\\\{\"date_and_date_nanos\":\\\\{\"gt\":\"2025-01-01T00:00:00.000Z\",\\\n             \"time_zone\":\"Z\",\"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -401,7 +401,7 @@ public void testToDateNanos() {\n \n         // < or !=\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos < \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos < \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"range\":\\\\{\"date_and_date_nanos\":\\\\{\"lt\":\"2020-01-01T00:00:00.000Z\",\\\n             \"time_zone\":\"Z\",\"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -410,7 +410,7 @@ public void testToDateNanos() {\n \n         // == or ==\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos == \"2020-01-01\" or date_and_date_nanos == \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos == \"2020-01-01\" or date_and_date_nanos == \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"term\":\\\\{\"date_and_date_nanos\":\\\\{\"value\":\"2020-01-01T00:00:00.000Z\",\\\n             \"boost\":0.0.*\"\"\" + \"\"\"\n@@ -419,7 +419,7 @@ public void testToDateNanos() {\n \n         // != or !=\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos != \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos != \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"must_not\".*\"term\":\\\\{\"date_and_date_nanos\":\\\\{\"value\":\\\n             \"2020-01-01T00:00:00.000Z\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -428,7 +428,7 @@ public void testToDateNanos() {\n \n         // = or !=\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos == \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos == \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"term\":\\\\{\"date_and_date_nanos\":\\\\{\"value\":\\\n             \"2020-01-01T00:00:00.000Z\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -438,7 +438,7 @@ public void testToDateNanos() {\n         // explicit casting\n         assertQueryTranslationDateDateNanosUnionTypes(\n             \"\"\"\n-                FROM test* | WHERE date_and_date_nanos::datetime < \"2025-12-31\" and date_and_date_nanos > \"2025-01-01\\\"\"\"\",\n+                FROM index* | WHERE date_and_date_nanos::datetime < \"2025-12-31\" and date_and_date_nanos > \"2025-01-01\\\"\"\"\",\n             stats,\n             containsString(\"\"\"\n                 \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/ClusterRequestTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 3,
      "changes": 5,
      "patch": "@@ -24,7 +24,6 @@\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.LogicalOptimizerContext;\n import org.elasticsearch.xpack.esql.optimizer.LogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n@@ -45,6 +44,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.unboundLogicalOptimizerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n \n public class ClusterRequestTests extends AbstractWireSerializingTestCase<ClusterComputeRequest> {\n \n@@ -171,15 +171,14 @@ private static String randomQuery() {\n     static Versioned<LogicalPlan> parse(String query) {\n         Map<String, EsField> mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         LogicalOptimizerContext context = unboundLogicalOptimizerContext();\n         TransportVersion minimumVersion = context.minimumVersion();\n         var logicalOptimizer = new LogicalPlanOptimizer(context);\n         var analyzer = new Analyzer(\n             new AnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 Map.of(),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution(),"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/DataNodeRequestSerializationTests.java",
      "status": "modified",
      "additions": 8,
      "deletions": 3,
      "changes": 11,
      "patch": "@@ -25,7 +25,6 @@\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.LogicalOptimizerContext;\n import org.elasticsearch.xpack.esql.optimizer.LogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.optimizer.PhysicalOptimizerContext;\n@@ -50,6 +49,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n \n public class DataNodeRequestSerializationTests extends AbstractWireSerializingTestCase<DataNodeRequest> {\n     @Override\n@@ -302,9 +302,14 @@ protected DataNodeRequest mutateInstance(DataNodeRequest in) throws IOException\n     static Versioned<LogicalPlan> parse(String query) {\n         Map<String, EsField> mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         var analyzer = new Analyzer(\n-            testAnalyzerContext(TEST_CFG, new EsqlFunctionRegistry(), getIndexResult, emptyPolicyResolution(), emptyInferenceResolution()),\n+            testAnalyzerContext(\n+                TEST_CFG,\n+                new EsqlFunctionRegistry(),\n+                indexResolutions(test),\n+                emptyPolicyResolution(),\n+                emptyInferenceResolution()\n+            ),\n             TEST_VERIFIER\n         );\n         TransportVersion minimumVersion = analyzer.context().minimumVersion();"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtilsTests.java",
      "status": "modified",
      "additions": 7,
      "deletions": 7,
      "changes": 14,
      "patch": "@@ -224,7 +224,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n \n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), Map.of());\n \n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -267,7 +267,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n             );\n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), Map.of());\n \n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -309,7 +309,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n             var failures = Map.of(REMOTE1_ALIAS, List.of(failure));\n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), failures);\n \n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -350,7 +350,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n             var failure = new FieldCapabilitiesFailure(new String[] { \"logs-a\" }, new NoSeedNodeLeftException(\"unable to connect\"));\n             var failures = Map.of(REMOTE1_ALIAS, List.of(failure));\n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), failures);\n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -399,7 +399,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n             var failures = Map.of(REMOTE1_ALIAS, List.of(failure));\n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), failures);\n \n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -713,7 +713,7 @@ private void assertLicenseCheckPasses(\n         String... expectedRemotes\n     ) {\n         var executionInfo = new EsqlExecutionInfo(true);\n-        initCrossClusterState(indicesGrouper, createLicenseState(status), pattern, executionInfo);\n+        initCrossClusterState(indicesGrouper, createLicenseState(status), Set.of(pattern), executionInfo);\n         assertThat(executionInfo.clusterAliases(), containsInAnyOrder(expectedRemotes));\n     }\n \n@@ -728,7 +728,7 @@ private void assertLicenseCheckFails(\n             equalTo(\n                 \"A valid Enterprise license is required to run ES|QL cross-cluster searches. License found: \" + expectedErrorMessageSuffix\n             ),\n-            () -> initCrossClusterState(indicesGrouper, createLicenseState(licenseStatus), pattern, new EsqlExecutionInfo(true))\n+            () -> initCrossClusterState(indicesGrouper, createLicenseState(licenseStatus), Set.of(pattern), new EsqlExecutionInfo(true))\n         );\n         assertThat(e.status(), equalTo(RestStatus.BAD_REQUEST));\n     }"
    },
    {
      "filename": "x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/telemetry/VerifierMetricsTests.java",
      "status": "modified",
      "additions": 7,
      "deletions": 1,
      "changes": 8,
      "patch": "@@ -7,13 +7,15 @@\n \n package org.elasticsearch.xpack.esql.telemetry;\n \n+import org.elasticsearch.index.IndexMode;\n import org.elasticsearch.license.XPackLicenseState;\n import org.elasticsearch.test.ESTestCase;\n import org.elasticsearch.xpack.core.watcher.common.stats.Counters;\n import org.elasticsearch.xpack.esql.action.EsqlCapabilities;\n import org.elasticsearch.xpack.esql.analysis.Verifier;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.expression.function.FunctionDefinition;\n+import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n \n import java.util.HashMap;\n@@ -23,6 +25,8 @@\n \n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.analyzer;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.telemetry.FeatureMetric.DISSECT;\n import static org.elasticsearch.xpack.esql.telemetry.FeatureMetric.DROP;\n import static org.elasticsearch.xpack.esql.telemetry.FeatureMetric.ENRICH;\n@@ -833,7 +837,9 @@ private Counters esql(String esql, Verifier v) {\n             metrics = new Metrics(new EsqlFunctionRegistry());\n             verifier = new Verifier(metrics, new XPackLicenseState(() -> 0L));\n         }\n-        analyzer(verifier).analyze(parser.createStatement(esql));\n+        IndexResolution metricsIndex = loadMapping(\"mapping-basic.json\", \"metrics\", IndexMode.TIME_SERIES);\n+        IndexResolution employees = loadMapping(\"mapping-basic.json\", \"employees\");\n+        analyzer(indexResolutions(metricsIndex, employees), verifier).analyze(parser.createStatement(esql));\n \n         return metrics == null ? null : metrics.stats();\n     }"
    }
  ],
  "diff": "diff --git a/benchmarks/src/main/java/org/elasticsearch/benchmark/_nightly/esql/QueryPlanningBenchmark.java b/benchmarks/src/main/java/org/elasticsearch/benchmark/_nightly/esql/QueryPlanningBenchmark.java\nindex 7d79e00406637..05535323bfeeb 100644\n--- a/benchmarks/src/main/java/org/elasticsearch/benchmark/_nightly/esql/QueryPlanningBenchmark.java\n+++ b/benchmarks/src/main/java/org/elasticsearch/benchmark/_nightly/esql/QueryPlanningBenchmark.java\n@@ -14,8 +14,13 @@\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.index.IndexMode;\n import org.elasticsearch.license.XPackLicenseState;\n-import org.elasticsearch.xpack.esql.analysis.*;\n+import org.elasticsearch.xpack.esql.analysis.Analyzer;\n+import org.elasticsearch.xpack.esql.analysis.AnalyzerContext;\n+import org.elasticsearch.xpack.esql.analysis.AnalyzerSettings;\n+import org.elasticsearch.xpack.esql.analysis.EnrichResolution;\n+import org.elasticsearch.xpack.esql.analysis.Verifier;\n import org.elasticsearch.xpack.esql.core.expression.FoldContext;\n+import org.elasticsearch.xpack.esql.core.tree.Source;\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.core.util.DateUtils;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n@@ -26,6 +31,7 @@\n import org.elasticsearch.xpack.esql.optimizer.LogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n import org.elasticsearch.xpack.esql.parser.QueryParams;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n import org.elasticsearch.xpack.esql.plugin.QueryPragmas;\n import org.elasticsearch.xpack.esql.session.Configuration;\n@@ -108,7 +114,7 @@ public void setup() {\n             new AnalyzerContext(\n                 config,\n                 functionRegistry,\n-                IndexResolution.valid(esIndex),\n+                Map.of(new IndexPattern(Source.EMPTY, esIndex.name()), IndexResolution.valid(esIndex)),\n                 Map.of(),\n                 new EnrichResolution(),\n                 InferenceResolution.EMPTY,\ndiff --git a/x-pack/plugin/esql/qa/server/src/main/java/org/elasticsearch/xpack/esql/qa/rest/EsqlSpecTestCase.java b/x-pack/plugin/esql/qa/server/src/main/java/org/elasticsearch/xpack/esql/qa/rest/EsqlSpecTestCase.java\nindex 2ecd089dedd2f..bee67b1486192 100644\n--- a/x-pack/plugin/esql/qa/server/src/main/java/org/elasticsearch/xpack/esql/qa/rest/EsqlSpecTestCase.java\n+++ b/x-pack/plugin/esql/qa/server/src/main/java/org/elasticsearch/xpack/esql/qa/rest/EsqlSpecTestCase.java\n@@ -51,6 +51,7 @@\n import java.util.Locale;\n import java.util.Map;\n import java.util.TreeMap;\n+import java.util.concurrent.Callable;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n import java.util.stream.LongStream;\n@@ -122,23 +123,59 @@ protected EsqlSpecTestCase(\n         this.mode = randomFrom(Mode.values());\n     }\n \n-    private static boolean dataLoaded = false;\n+    private static class Protected {\n+        private volatile boolean completed = false;\n+        private volatile boolean started = false;\n+        private volatile Throwable failure = null;\n+\n+        private void protectedBlock(Callable<Void> callable) {\n+            if (completed) {\n+                return;\n+            }\n+            // In case tests get run in parallel, we ensure only one setup is run, and other tests wait for this\n+            synchronized (this) {\n+                if (completed) {\n+                    return;\n+                }\n+                if (started) {\n+                    // Should only happen if a previous test setup failed, possibly with partial setup, let's fail fast the current test\n+                    if (failure != null) {\n+                        fail(failure, \"Previous test setup failed: \" + failure.getMessage());\n+                    }\n+                    fail(\"Previous test setup failed with unknown error\");\n+                }\n+                started = true;\n+                try {\n+                    callable.call();\n+                    completed = true;\n+                } catch (Throwable t) {\n+                    failure = t;\n+                    fail(failure, \"Current test setup failed: \" + failure.getMessage());\n+                }\n+            }\n+        }\n+\n+        private synchronized void reset() {\n+            completed = false;\n+            started = false;\n+            failure = null;\n+        }\n+    }\n+\n+    private static final Protected INGEST = new Protected();\n     protected static boolean testClustersOk = true;\n \n     @Before\n-    public void setup() throws IOException {\n+    public void setup() {\n         assumeTrue(\"test clusters were broken\", testClustersOk);\n-        boolean supportsLookup = supportsIndexModeLookup();\n-        boolean supportsSourceMapping = supportsSourceFieldMapping();\n-        boolean supportsInferenceTestService = supportsInferenceTestService();\n-        if (dataLoaded == false) {\n-            if (supportsInferenceTestService) {\n+        INGEST.protectedBlock(() -> {\n+            // Inference endpoints must be created before ingesting any datasets that rely on them (mapping of inference_id)\n+            if (supportsInferenceTestService()) {\n                 createInferenceEndpoints(adminClient());\n             }\n-\n-            loadDataSetIntoEs(client(), supportsLookup, supportsSourceMapping, supportsInferenceTestService);\n-            dataLoaded = true;\n-        }\n+            loadDataSetIntoEs(client(), supportsIndexModeLookup(), supportsSourceFieldMapping(), supportsInferenceTestService());\n+            return null;\n+        });\n     }\n \n     @AfterClass\n@@ -147,7 +184,6 @@ public static void wipeTestData() throws IOException {\n             return;\n         }\n         try {\n-            dataLoaded = false;\n             adminClient().performRequest(new Request(\"DELETE\", \"/*\"));\n         } catch (ResponseException e) {\n             // 404 here just means we had no indexes\n@@ -155,7 +191,7 @@ public static void wipeTestData() throws IOException {\n                 throw e;\n             }\n         }\n-\n+        INGEST.reset();\n         deleteInferenceEndpoints(adminClient());\n     }\n \ndiff --git a/x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/CsvTestsDataLoader.java b/x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/CsvTestsDataLoader.java\nindex 96f8ffdcccbbe..ef3514308a436 100644\n--- a/x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/CsvTestsDataLoader.java\n+++ b/x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/CsvTestsDataLoader.java\n@@ -78,8 +78,9 @@ public class CsvTestsDataLoader {\n     private static final TestDataset LANGUAGES = new TestDataset(\"languages\");\n     private static final TestDataset LANGUAGES_LOOKUP = LANGUAGES.withIndex(\"languages_lookup\").withSetting(\"lookup-settings.json\");\n     private static final TestDataset LANGUAGES_NON_UNIQUE_KEY = new TestDataset(\"languages_non_unique_key\");\n-    private static final TestDataset LANGUAGES_LOOKUP_NON_UNIQUE_KEY = LANGUAGES_NON_UNIQUE_KEY.withIndex(\"languages_lookup_non_unique_key\")\n-        .withSetting(\"lookup-settings.json\");\n+    private static final TestDataset LANGUAGES_LOOKUP_NON_UNIQUE_KEY = LANGUAGES_LOOKUP.withIndex(\"languages_lookup_non_unique_key\")\n+        .withData(\"languages_non_unique_key.csv\")\n+        .withDynamicTypeMapping(Map.of(\"country\", \"text\"));\n     private static final TestDataset LANGUAGES_NESTED_FIELDS = new TestDataset(\n         \"languages_nested_fields\",\n         \"mapping-languages_nested_fields.json\",\n@@ -423,11 +424,13 @@ private static void loadDataSetIntoEs(\n         Logger logger = LogManager.getLogger(CsvTestsDataLoader.class);\n \n         Set<String> loadedDatasets = new HashSet<>();\n+        logger.info(\"Loading test datasets\");\n         for (var dataset : availableDatasetsForEs(supportsIndexModeLookup, supportsSourceFieldMapping, inferenceEnabled, timeSeriesOnly)) {\n             load(client, dataset, logger, indexCreator);\n             loadedDatasets.add(dataset.indexName);\n         }\n         forceMerge(client, loadedDatasets, logger);\n+        logger.info(\"Loading enrich policies\");\n         for (var policy : ENRICH_POLICIES) {\n             loadEnrichPolicy(client, policy.policyName, policy.policyFileName, logger);\n         }\n@@ -569,6 +572,7 @@ private static void deleteInferenceEndpoint(RestClient client, String inferenceI\n     }\n \n     private static void loadEnrichPolicy(RestClient client, String policyName, String policyFileName, Logger logger) throws IOException {\n+        logger.info(\"Loading enrich policy [{}] from file [{}]\", policyName, policyFileName);\n         URL policyMapping = getResource(\"/\" + policyFileName);\n         String entity = readTextFile(policyMapping);\n         Request request = new Request(\"PUT\", \"/_enrich/policy/\" + policyName);\n@@ -588,6 +592,7 @@ private static URL getResource(String name) {\n     }\n \n     private static void load(RestClient client, TestDataset dataset, Logger logger, IndexCreator indexCreator) throws IOException {\n+        logger.info(\"Loading dataset [{}] into ES index [{}]\", dataset.dataFileName, dataset.indexName);\n         URL mapping = getResource(\"/\" + dataset.mappingFileName);\n         Settings indexSettings = dataset.readSettingsFile();\n         indexCreator.createIndex(client, dataset.indexName, readMappingFile(mapping, dataset.typeMapping), indexSettings);\n@@ -854,15 +859,16 @@ public record TestDataset(\n         String dataFileName,\n         String settingFileName,\n         boolean allowSubFields,\n-        @Nullable Map<String, String> typeMapping,\n+        @Nullable Map<String, String> typeMapping, // Override mappings read from mappings file\n+        @Nullable Map<String, String> dynamicTypeMapping, // Define mappings not in the mapping files, but available from field-caps\n         boolean requiresInferenceEndpoint\n     ) {\n         public TestDataset(String indexName, String mappingFileName, String dataFileName) {\n-            this(indexName, mappingFileName, dataFileName, null, true, null, false);\n+            this(indexName, mappingFileName, dataFileName, null, true, null, null, false);\n         }\n \n         public TestDataset(String indexName) {\n-            this(indexName, \"mapping-\" + indexName + \".json\", indexName + \".csv\", null, true, null, false);\n+            this(indexName, \"mapping-\" + indexName + \".json\", indexName + \".csv\", null, true, null, null, false);\n         }\n \n         public TestDataset withIndex(String indexName) {\n@@ -873,6 +879,7 @@ public TestDataset withIndex(String indexName) {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -885,6 +892,7 @@ public TestDataset withData(String dataFileName) {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -897,6 +905,7 @@ public TestDataset noData() {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -909,6 +918,7 @@ public TestDataset withSetting(String settingFileName) {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -921,6 +931,7 @@ public TestDataset noSubfields() {\n                 settingFileName,\n                 false,\n                 typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n@@ -933,12 +944,35 @@ public TestDataset withTypeMapping(Map<String, String> typeMapping) {\n                 settingFileName,\n                 allowSubFields,\n                 typeMapping,\n+                dynamicTypeMapping,\n+                requiresInferenceEndpoint\n+            );\n+        }\n+\n+        public TestDataset withDynamicTypeMapping(Map<String, String> dynamicTypeMapping) {\n+            return new TestDataset(\n+                indexName,\n+                mappingFileName,\n+                dataFileName,\n+                settingFileName,\n+                allowSubFields,\n+                typeMapping,\n+                dynamicTypeMapping,\n                 requiresInferenceEndpoint\n             );\n         }\n \n         public TestDataset withInferenceEndpoint(boolean needsInference) {\n-            return new TestDataset(indexName, mappingFileName, dataFileName, settingFileName, allowSubFields, typeMapping, needsInference);\n+            return new TestDataset(\n+                indexName,\n+                mappingFileName,\n+                dataFileName,\n+                settingFileName,\n+                allowSubFields,\n+                typeMapping,\n+                dynamicTypeMapping,\n+                needsInference\n+            );\n         }\n \n         private Settings readSettingsFile() throws IOException {\ndiff --git a/x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/EsqlTestUtils.java b/x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/EsqlTestUtils.java\nindex acf4492bcc1aa..a0f40813bb99f 100644\n--- a/x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/EsqlTestUtils.java\n+++ b/x-pack/plugin/esql/qa/testFixtures/src/main/java/org/elasticsearch/xpack/esql/EsqlTestUtils.java\n@@ -102,6 +102,7 @@\n import org.elasticsearch.xpack.esql.inference.InferenceService;\n import org.elasticsearch.xpack.esql.optimizer.LogicalOptimizerContext;\n import org.elasticsearch.xpack.esql.parser.QueryParam;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.EsRelation;\n import org.elasticsearch.xpack.esql.plan.logical.Explain;\n@@ -451,11 +452,11 @@ public static TransportVersion randomMinimumVersion() {\n     public static AnalyzerContext testAnalyzerContext(\n         Configuration configuration,\n         EsqlFunctionRegistry functionRegistry,\n-        IndexResolution indexResolution,\n+        Map<IndexPattern, IndexResolution> indexResolutions,\n         EnrichResolution enrichResolution,\n         InferenceResolution inferenceResolution\n     ) {\n-        return testAnalyzerContext(configuration, functionRegistry, indexResolution, Map.of(), enrichResolution, inferenceResolution);\n+        return testAnalyzerContext(configuration, functionRegistry, indexResolutions, Map.of(), enrichResolution, inferenceResolution);\n     }\n \n     /**\n@@ -464,7 +465,7 @@ public static AnalyzerContext testAnalyzerContext(\n     public static AnalyzerContext testAnalyzerContext(\n         Configuration configuration,\n         EsqlFunctionRegistry functionRegistry,\n-        IndexResolution indexResolution,\n+        Map<IndexPattern, IndexResolution> indexResolutions,\n         Map<String, IndexResolution> lookupResolution,\n         EnrichResolution enrichResolution,\n         InferenceResolution inferenceResolution\n@@ -472,7 +473,7 @@ public static AnalyzerContext testAnalyzerContext(\n         return new AnalyzerContext(\n             configuration,\n             functionRegistry,\n-            indexResolution,\n+            indexResolutions,\n             lookupResolution,\n             enrichResolution,\n             inferenceResolution,\ndiff --git a/x-pack/plugin/esql/qa/testFixtures/src/main/resources/inlinestats.csv-spec b/x-pack/plugin/esql/qa/testFixtures/src/main/resources/inlinestats.csv-spec\nindex 7ec65467e7e98..586a0d87cee71 100644\n--- a/x-pack/plugin/esql/qa/testFixtures/src/main/resources/inlinestats.csv-spec\n+++ b/x-pack/plugin/esql/qa/testFixtures/src/main/resources/inlinestats.csv-spec\n@@ -4150,6 +4150,7 @@ required_capability: inline_stats\n required_capability: fix_join_output_merging\n \n FROM languages_lookup_non_unique_key\n+| EVAL country = MV_SORT(country)\n | KEEP country, language_name\n | EVAL language_code = null::integer\n | INLINE STATS MAX(language_code) BY language_code\n@@ -4157,7 +4158,7 @@ FROM languages_lookup_non_unique_key\n | LIMIT 5\n ;\n \n-country:text      |language_name:keyword |MAX(language_code):integer |language_code:integer\n+country:keyword   |language_name:keyword |MAX(language_code):integer |language_code:integer\n Atlantis          |null                  |null                       |null\n [Austria, Germany]|German                |null                       |null\n Canada            |English               |null                       |null\ndiff --git a/x-pack/plugin/esql/qa/testFixtures/src/main/resources/lookup-join.csv-spec b/x-pack/plugin/esql/qa/testFixtures/src/main/resources/lookup-join.csv-spec\nindex 610269f63b4be..b4318ee4687da 100644\n--- a/x-pack/plugin/esql/qa/testFixtures/src/main/resources/lookup-join.csv-spec\n+++ b/x-pack/plugin/esql/qa/testFixtures/src/main/resources/lookup-join.csv-spec\n@@ -247,11 +247,12 @@ FROM employees\n | EVAL language_code = emp_no % 10\n | LOOKUP JOIN languages_lookup_non_unique_key ON language_code\n | WHERE emp_no > 10090 AND emp_no < 10096\n+| EVAL country = MV_SORT(country)\n | SORT emp_no, country\n | KEEP emp_no, language_code, language_name, country\n ;\n \n-emp_no:integer | language_code:integer | language_name:keyword | country:text\n+emp_no:integer | language_code:integer | language_name:keyword | country:keyword\n     10091      | 1                     | English               | Canada\n     10091      | 1                     | null                  | United Kingdom\n     10091      | 1                     | English               | United States of America\n@@ -272,11 +273,12 @@ FROM employees\n | LIMIT 5\n | EVAL language_code = emp_no % 10\n | LOOKUP JOIN languages_lookup_non_unique_key ON language_code\n+| EVAL country = MV_SORT(country)\n | KEEP emp_no, language_code, language_name, country\n ;\n \n ignoreOrder:true\n-emp_no:integer | language_code:integer | language_name:keyword | country:text\n+emp_no:integer | language_code:integer | language_name:keyword | country:keyword\n 10001          | 1                     | English               | Canada\n 10001          | 1                     | English               | null\n 10001          | 1                     | null                  | United Kingdom\n@@ -324,7 +326,7 @@ ROW language_code = 2\n \n ignoreOrder:true\n language_code:integer | country:text       | language_name:keyword\n-2                     | [Austria, Germany] | German\n+2                     | [Germany, Austria] | German\n 2                     | Switzerland        | German\n 2                     | null               | German\n ;\ndiff --git a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/Analyzer.java b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/Analyzer.java\nindex beb9015097415..a1774c5ddcf77 100644\n--- a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/Analyzer.java\n+++ b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/Analyzer.java\n@@ -247,12 +247,10 @@ private static class ResolveTable extends ParameterizedAnalyzerRule<UnresolvedRe\n \n         @Override\n         protected LogicalPlan rule(UnresolvedRelation plan, AnalyzerContext context) {\n-            return resolveIndex(\n-                plan,\n-                plan.indexMode().equals(IndexMode.LOOKUP)\n-                    ? context.lookupResolution().get(plan.indexPattern().indexPattern())\n-                    : context.indexResolution()\n-            );\n+            IndexResolution indexResolution = plan.indexMode().equals(IndexMode.LOOKUP)\n+                ? context.lookupResolution().get(plan.indexPattern().indexPattern())\n+                : context.indexResolution().get(plan.indexPattern());\n+            return resolveIndex(plan, indexResolution);\n         }\n \n         private LogicalPlan resolveIndex(UnresolvedRelation plan, IndexResolution indexResolution) {\n@@ -270,6 +268,7 @@ private LogicalPlan resolveIndex(UnresolvedRelation plan, IndexResolution indexR\n                         plan.telemetryLabel()\n                     );\n             }\n+            // assert indexResolution.matches(plan.indexPattern().indexPattern()) : \"Expected index resolution to match the index pattern\";\n             IndexPattern table = plan.indexPattern();\n             if (indexResolution.matches(table.indexPattern()) == false) {\n                 // TODO: fix this (and tests), or drop check (seems SQL-inherited, where's also defective)\n@@ -537,7 +536,7 @@ protected LogicalPlan rule(LogicalPlan plan, AnalyzerContext context) {\n             }\n \n             if (plan instanceof Insist i) {\n-                return resolveInsist(i, childrenOutput, context.indexResolution());\n+                return resolveInsist(i, childrenOutput, context);\n             }\n \n             if (plan instanceof Fuse fuse) {\n@@ -958,15 +957,27 @@ private List<Attribute> resolveUsingColumns(List<Attribute> cols, List<Attribute\n             return resolved;\n         }\n \n-        private LogicalPlan resolveInsist(Insist insist, List<Attribute> childrenOutput, IndexResolution indexResolution) {\n+        private LogicalPlan resolveInsist(Insist insist, List<Attribute> childrenOutput, AnalyzerContext context) {\n             List<Attribute> list = new ArrayList<>();\n+            List<IndexResolution> resolutions = collectIndexResolutions(insist, context);\n             for (Attribute a : insist.insistedAttributes()) {\n-                list.add(resolveInsistAttribute(a, childrenOutput, indexResolution));\n+                list.add(resolveInsistAttribute(a, childrenOutput, resolutions));\n             }\n             return insist.withAttributes(list);\n         }\n \n-        private Attribute resolveInsistAttribute(Attribute attribute, List<Attribute> childrenOutput, IndexResolution indexResolution) {\n+        private List<IndexResolution> collectIndexResolutions(LogicalPlan plan, AnalyzerContext context) {\n+            List<IndexResolution> resolutions = new ArrayList<>();\n+            plan.forEachDown(EsRelation.class, e -> {\n+                var resolution = context.indexResolution().get(new IndexPattern(e.source(), e.indexPattern()));\n+                if (resolution != null) {\n+                    resolutions.add(resolution);\n+                }\n+            });\n+            return resolutions;\n+        }\n+\n+        private Attribute resolveInsistAttribute(Attribute attribute, List<Attribute> childrenOutput, List<IndexResolution> indices) {\n             Attribute resolvedCol = maybeResolveAttribute((UnresolvedAttribute) attribute, childrenOutput);\n             // Field isn't mapped anywhere.\n             if (resolvedCol instanceof UnresolvedAttribute) {\n@@ -974,7 +985,8 @@ private Attribute resolveInsistAttribute(Attribute attribute, List<Attribute> ch\n             }\n \n             // Field is partially unmapped.\n-            if (resolvedCol instanceof FieldAttribute fa && indexResolution.get().isPartiallyUnmappedField(fa.name())) {\n+            // TODO: Should the check for partially unmapped fields be done specific to each sub-query in a fork?\n+            if (resolvedCol instanceof FieldAttribute fa && indices.stream().anyMatch(r -> r.get().isPartiallyUnmappedField(fa.name()))) {\n                 return fa.dataType() == KEYWORD ? insistKeyword(fa) : invalidInsistAttribute(fa);\n             }\n \ndiff --git a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/AnalyzerContext.java b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/AnalyzerContext.java\nindex da74cd2bd779c..adebb69407e15 100644\n--- a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/AnalyzerContext.java\n+++ b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/AnalyzerContext.java\n@@ -11,6 +11,7 @@\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.inference.InferenceResolution;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.session.Configuration;\n import org.elasticsearch.xpack.esql.session.EsqlSession;\n \n@@ -19,7 +20,7 @@\n public record AnalyzerContext(\n     Configuration configuration,\n     EsqlFunctionRegistry functionRegistry,\n-    IndexResolution indexResolution,\n+    Map<IndexPattern, IndexResolution> indexResolution,\n     Map<String, IndexResolution> lookupResolution,\n     EnrichResolution enrichResolution,\n     InferenceResolution inferenceResolution,\n@@ -29,7 +30,7 @@ public record AnalyzerContext(\n     public AnalyzerContext(\n         Configuration configuration,\n         EsqlFunctionRegistry functionRegistry,\n-        IndexResolution indexResolution,\n+        Map<IndexPattern, IndexResolution> indexResolution,\n         Map<String, IndexResolution> lookupResolution,\n         EnrichResolution enrichResolution,\n         InferenceResolution inferenceResolution,\n@@ -52,7 +53,7 @@ public AnalyzerContext(Configuration configuration, EsqlFunctionRegistry functio\n         this(\n             configuration,\n             functionRegistry,\n-            result.indices(),\n+            result.indexResolution(),\n             result.lookupIndices(),\n             result.enrichResolution(),\n             result.inferenceResolution(),\ndiff --git a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/PreAnalyzer.java b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/PreAnalyzer.java\nindex 2488172cb184a..baa9a9519b231 100644\n--- a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/PreAnalyzer.java\n+++ b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/analysis/PreAnalyzer.java\n@@ -16,7 +16,9 @@\n import org.elasticsearch.xpack.esql.plan.logical.UnresolvedRelation;\n \n import java.util.ArrayList;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n \n /**\n  * This class is part of the planner.  Acts somewhat like a linker, to find the indices and enrich policies referenced by the query.\n@@ -24,14 +26,13 @@\n public class PreAnalyzer {\n \n     public record PreAnalysis(\n-        IndexMode indexMode,\n-        IndexPattern indexPattern,\n+        Map<IndexPattern, IndexMode> indexes,\n         List<Enrich> enriches,\n         List<IndexPattern> lookupIndices,\n         boolean supportsAggregateMetricDouble,\n         boolean supportsDenseVector\n     ) {\n-        public static final PreAnalysis EMPTY = new PreAnalysis(null, null, List.of(), List.of(), false, false);\n+        public static final PreAnalysis EMPTY = new PreAnalysis(Map.of(), List.of(), List.of(), false, false);\n     }\n \n     public PreAnalysis preAnalyze(LogicalPlan plan) {\n@@ -43,17 +44,19 @@ public PreAnalysis preAnalyze(LogicalPlan plan) {\n     }\n \n     protected PreAnalysis doPreAnalyze(LogicalPlan plan) {\n-        Holder<IndexMode> indexMode = new Holder<>();\n-        Holder<IndexPattern> indexPattern = new Holder<>();\n+        Map<IndexPattern, IndexMode> indexes = new HashMap<>();\n         List<IndexPattern> lookupIndices = new ArrayList<>();\n         plan.forEachUp(UnresolvedRelation.class, p -> {\n             if (p.indexMode() == IndexMode.LOOKUP) {\n                 lookupIndices.add(p.indexPattern());\n-            } else if (indexMode.get() == null || indexMode.get() == p.indexMode()) {\n-                indexMode.set(p.indexMode());\n-                indexPattern.set(p.indexPattern());\n+            } else if (indexes.containsKey(p.indexPattern()) == false || indexes.get(p.indexPattern()) == p.indexMode()) {\n+                indexes.put(p.indexPattern(), p.indexMode());\n             } else {\n-                throw new IllegalStateException(\"index mode is already set\");\n+                IndexMode m1 = p.indexMode();\n+                IndexMode m2 = indexes.get(p.indexPattern());\n+                throw new IllegalStateException(\n+                    \"index pattern '\" + p.indexPattern() + \"' found with with different index mode: \" + m2 + \" != \" + m1\n+                );\n             }\n         });\n \n@@ -71,6 +74,11 @@ protected PreAnalysis doPreAnalyze(LogicalPlan plan) {\n          */\n         Holder<Boolean> supportsAggregateMetricDouble = new Holder<>(false);\n         Holder<Boolean> supportsDenseVector = new Holder<>(false);\n+        indexes.forEach((ip, mode) -> {\n+            if (mode == IndexMode.TIME_SERIES) {\n+                supportsAggregateMetricDouble.set(true);\n+            }\n+        });\n         plan.forEachDown(p -> p.forEachExpression(UnresolvedFunction.class, fn -> {\n             if (fn.name().equalsIgnoreCase(\"knn\")\n                 || fn.name().equalsIgnoreCase(\"to_dense_vector\")\n@@ -90,13 +98,6 @@ protected PreAnalysis doPreAnalyze(LogicalPlan plan) {\n         // mark plan as preAnalyzed (if it were marked, there would be no analysis)\n         plan.forEachUp(LogicalPlan::setPreAnalyzed);\n \n-        return new PreAnalysis(\n-            indexMode.get(),\n-            indexPattern.get(),\n-            unresolvedEnriches,\n-            lookupIndices,\n-            indexMode.get() == IndexMode.TIME_SERIES || supportsAggregateMetricDouble.get(),\n-            supportsDenseVector.get()\n-        );\n+        return new PreAnalysis(indexes, unresolvedEnriches, lookupIndices, supportsAggregateMetricDouble.get(), supportsDenseVector.get());\n     }\n }\ndiff --git a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtils.java b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtils.java\nindex 4f74561495c58..a97b13a61a71e 100644\n--- a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtils.java\n+++ b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtils.java\n@@ -33,6 +33,7 @@\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n \n import java.util.ArrayList;\n+import java.util.Collection;\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n@@ -186,7 +187,7 @@ static void updateExecutionInfoWithUnavailableClusters(\n \n     static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n         EsqlExecutionInfo executionInfo,\n-        IndexResolution indexResolution,\n+        Collection<IndexResolution> indexResolutions,\n         boolean usedFilter\n     ) {\n         if (executionInfo.clusterInfo.isEmpty()) {\n@@ -195,8 +196,10 @@ static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n         // Get the clusters which are still running, and we will check whether they have any matching indices.\n         // NOTE: we assume that updateExecutionInfoWithUnavailableClusters() was already run and took care of unavailable clusters.\n         final Set<String> clustersWithNoMatchingIndices = executionInfo.getRunningClusterAliases().collect(toSet());\n-        for (String indexName : indexResolution.resolvedIndices()) {\n-            clustersWithNoMatchingIndices.remove(RemoteClusterAware.parseClusterAlias(indexName));\n+        for (IndexResolution indexResolution : indexResolutions) {\n+            for (String indexName : indexResolution.resolvedIndices()) {\n+                clustersWithNoMatchingIndices.remove(RemoteClusterAware.parseClusterAlias(indexName));\n+            }\n         }\n         /*\n          * Rules enforced at planning time around non-matching indices\n@@ -234,20 +237,22 @@ static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n                 }\n             } else {\n                 // We check for the valid resolution because if we have empty resolution it's still an error.\n-                if (indexResolution.isValid()) {\n-                    List<FieldCapabilitiesFailure> failures = indexResolution.failures().getOrDefault(c, List.of());\n-                    // No matching indices, no concrete index requested, and no error in field-caps; just mark as done.\n-                    if (failures.isEmpty()) {\n-                        markClusterWithFinalStateAndNoShards(executionInfo, c, Cluster.Status.SUCCESSFUL, null);\n-                    } else {\n-                        // skip reporting index_not_found exceptions to avoid spamming users with such errors\n-                        // when queries use a remote cluster wildcard, e.g., `*:my-logs*`.\n-                        Exception nonIndexNotFound = failures.stream()\n-                            .map(FieldCapabilitiesFailure::getException)\n-                            .filter(ex -> ExceptionsHelper.unwrap(ex, IndexNotFoundException.class) == null)\n-                            .findAny()\n-                            .orElse(null);\n-                        markClusterWithFinalStateAndNoShards(executionInfo, c, Cluster.Status.SKIPPED, nonIndexNotFound);\n+                for (IndexResolution indexResolution : indexResolutions) {\n+                    if (indexResolution.isValid()) {\n+                        List<FieldCapabilitiesFailure> failures = indexResolution.failures().getOrDefault(c, List.of());\n+                        // No matching indices, no concrete index requested, and no error in field-caps; just mark as done.\n+                        if (failures.isEmpty()) {\n+                            markClusterWithFinalStateAndNoShards(executionInfo, c, Cluster.Status.SUCCESSFUL, null);\n+                        } else {\n+                            // skip reporting index_not_found exceptions to avoid spamming users with such errors\n+                            // when queries use a remote cluster wildcard, e.g., `*:my-logs*`.\n+                            Exception nonIndexNotFound = failures.stream()\n+                                .map(FieldCapabilitiesFailure::getException)\n+                                .filter(ex -> ExceptionsHelper.unwrap(ex, IndexNotFoundException.class) == null)\n+                                .findAny()\n+                                .orElse(null);\n+                            markClusterWithFinalStateAndNoShards(executionInfo, c, Cluster.Status.SKIPPED, nonIndexNotFound);\n+                        }\n                     }\n                 }\n             }\n@@ -258,8 +263,11 @@ static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n     }\n \n     // Filter-less version, mainly for testing where we don't need filter support\n-    static void updateExecutionInfoWithClustersWithNoMatchingIndices(EsqlExecutionInfo executionInfo, IndexResolution indexResolution) {\n-        updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution, false);\n+    static void updateExecutionInfoWithClustersWithNoMatchingIndices(\n+        EsqlExecutionInfo executionInfo,\n+        Set<IndexResolution> indexResolutions\n+    ) {\n+        updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolutions, false);\n     }\n \n     // visible for testing\n@@ -304,24 +312,31 @@ static void updateExecutionInfoAtEndOfPlanning(EsqlExecutionInfo execInfo) {\n     /**\n      * Checks the index expression for the presence of remote clusters.\n      * If found, it will ensure that the caller has a valid Enterprise (or Trial) license on the querying cluster\n-     * as well as initialize corresponding cluster state in execution info.\n+     * as well as initialize the corresponding cluster state in execution info.\n      * @throws org.elasticsearch.ElasticsearchStatusException if the license is not valid (or present) for ES|QL CCS search.\n      */\n     public static void initCrossClusterState(\n         IndicesExpressionGrouper indicesGrouper,\n         XPackLicenseState licenseState,\n-        IndexPattern indexPattern,\n+        Set<IndexPattern> indexPatterns,\n         EsqlExecutionInfo executionInfo\n     ) throws ElasticsearchStatusException {\n-        if (indexPattern == null) {\n+        if (indexPatterns.isEmpty()) {\n             return;\n         }\n         try {\n-            var groupedIndices = indicesGrouper.groupIndices(\n-                IndicesOptions.DEFAULT,\n-                Strings.splitStringByCommaToArray(indexPattern.indexPattern()),\n-                false\n-            );\n+            // TODO it is not safe to concat multiple index patterns in case any of them contains exclusion.\n+            // This is going to be resolved in #136804\n+            String[] indexExpressions = indexPatterns.stream()\n+                .map(indexPattern -> Strings.splitStringByCommaToArray(indexPattern.indexPattern()))\n+                .reduce((a, b) -> {\n+                    String[] combined = new String[a.length + b.length];\n+                    System.arraycopy(a, 0, combined, 0, a.length);\n+                    System.arraycopy(b, 0, combined, a.length, b.length);\n+                    return combined;\n+                })\n+                .get();\n+            var groupedIndices = indicesGrouper.groupIndices(IndicesOptions.DEFAULT, indexExpressions, false);\n \n             executionInfo.clusterInfoInitializing(true);\n             // initialize the cluster entries in EsqlExecutionInfo before throwing the invalid license error\ndiff --git a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlSession.java b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlSession.java\nindex d694588bf18c4..ed88903dd5e0f 100644\n--- a/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlSession.java\n+++ b/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/session/EsqlSession.java\n@@ -459,9 +459,24 @@ private EsqlStatement parse(String query, QueryParams params) {\n     static void handleFieldCapsFailures(\n         boolean allowPartialResults,\n         EsqlExecutionInfo executionInfo,\n-        Map<String, List<FieldCapabilitiesFailure>> failures\n+        Map<IndexPattern, IndexResolution> indexResolutions\n     ) throws Exception {\n         FailureCollector failureCollector = new FailureCollector();\n+        for (IndexResolution indexResolution : indexResolutions.values()) {\n+            handleFieldCapsFailures(allowPartialResults, executionInfo, indexResolution.failures(), failureCollector);\n+        }\n+        Exception failure = failureCollector.getFailure();\n+        if (failure != null) {\n+            throw failure;\n+        }\n+    }\n+\n+    static void handleFieldCapsFailures(\n+        boolean allowPartialResults,\n+        EsqlExecutionInfo executionInfo,\n+        Map<String, List<FieldCapabilitiesFailure>> failures,\n+        FailureCollector failureCollector\n+    ) throws Exception {\n         for (var e : failures.entrySet()) {\n             String clusterAlias = e.getKey();\n             EsqlExecutionInfo.Cluster cluster = executionInfo.getCluster(clusterAlias);\n@@ -491,10 +506,6 @@ static void handleFieldCapsFailures(\n                 );\n             }\n         }\n-        Exception failure = failureCollector.getFailure();\n-        if (failure != null) {\n-            throw failure;\n-        }\n     }\n \n     public void analyzedPlan(\n@@ -532,14 +543,19 @@ private void resolveIndicesAndAnalyze(\n         PreAnalysisResult result,\n         ActionListener<Versioned<LogicalPlan>> logicalPlanListener\n     ) {\n-        EsqlCCSUtils.initCrossClusterState(indicesExpressionGrouper, verifier.licenseState(), preAnalysis.indexPattern(), executionInfo);\n+        EsqlCCSUtils.initCrossClusterState(\n+            indicesExpressionGrouper,\n+            verifier.licenseState(),\n+            preAnalysis.indexes().keySet(),\n+            executionInfo\n+        );\n \n         // The main index pattern dictates on which nodes the query can be executed, so we use the minimum transport version from this field\n         // caps request.\n         SubscribableListener.<PreAnalysisResult>newForked(\n-            l -> preAnalyzeMainIndicesAndRetrieveMinTransportVersion(preAnalysis, executionInfo, result, requestFilter, l)\n+            l -> preAnalyzeMainIndices(preAnalysis.indexes().entrySet().iterator(), preAnalysis, executionInfo, result, requestFilter, l)\n         ).andThenApply(r -> {\n-            if (r.indices.isValid()\n+            if (r.indexResolution.isEmpty() == false // Rule out ROW case with no FROM clauses\n                 && executionInfo.isCrossClusterSearch()\n                 && executionInfo.getRunningClusterAliases().findAny().isEmpty()) {\n                 LOGGER.debug(\"No more clusters to search, ending analysis stage\");\n@@ -779,7 +795,35 @@ private void validateRemoteVersions(EsqlExecutionInfo executionInfo) {\n         });\n     }\n \n-    private void preAnalyzeMainIndicesAndRetrieveMinTransportVersion(\n+    private void preAnalyzeMainIndices(\n+        Iterator<Map.Entry<IndexPattern, IndexMode>> indexPatterns,\n+        PreAnalyzer.PreAnalysis preAnalysis,\n+        EsqlExecutionInfo executionInfo,\n+        PreAnalysisResult result,\n+        QueryBuilder requestFilter,\n+        ActionListener<PreAnalysisResult> listener\n+    ) {\n+        if (indexPatterns.hasNext()) {\n+            var index = indexPatterns.next();\n+            preAnalyzeMainIndices(\n+                index.getKey(),\n+                index.getValue(),\n+                preAnalysis,\n+                executionInfo,\n+                result,\n+                requestFilter,\n+                listener.delegateFailureAndWrap((l, r) -> {\n+                    preAnalyzeMainIndices(indexPatterns, preAnalysis, executionInfo, r, requestFilter, l);\n+                })\n+            );\n+        } else {\n+            listener.onResponse(result);\n+        }\n+    }\n+\n+    private void preAnalyzeMainIndices(\n+        IndexPattern indexPattern,\n+        IndexMode indexMode,\n         PreAnalyzer.PreAnalysis preAnalysis,\n         EsqlExecutionInfo executionInfo,\n         PreAnalysisResult result,\n@@ -791,42 +835,36 @@ private void preAnalyzeMainIndicesAndRetrieveMinTransportVersion(\n             ThreadPool.Names.SEARCH_COORDINATION,\n             ThreadPool.Names.SYSTEM_READ\n         );\n-        if (preAnalysis.indexPattern() != null) {\n-            if (executionInfo.clusterAliases().isEmpty()) {\n-                // return empty resolution if the expression is pure CCS and resolved no remote clusters (like no-such-cluster*:index)\n-                listener.onResponse(\n-                    result.withIndices(IndexResolution.valid(new EsIndex(preAnalysis.indexPattern().indexPattern(), Map.of(), Map.of())))\n-                        .withMinimumTransportVersion(TransportVersion.current())\n-                );\n-            } else {\n-                indexResolver.resolveAsMergedMappingAndRetrieveMinimumVersion(\n-                    preAnalysis.indexPattern().indexPattern(),\n-                    result.fieldNames,\n-                    // Maybe if no indices are returned, retry without index mode and provide a clearer error message.\n-                    switch (preAnalysis.indexMode()) {\n-                        case IndexMode.TIME_SERIES -> {\n-                            var indexModeFilter = new TermQueryBuilder(IndexModeFieldMapper.NAME, IndexMode.TIME_SERIES.getName());\n-                            yield requestFilter != null\n-                                ? new BoolQueryBuilder().filter(requestFilter).filter(indexModeFilter)\n-                                : indexModeFilter;\n-                        }\n-                        default -> requestFilter;\n-                    },\n-                    preAnalysis.indexMode() == IndexMode.TIME_SERIES,\n-                    preAnalysis.supportsAggregateMetricDouble(),\n-                    preAnalysis.supportsDenseVector(),\n-                    listener.delegateFailureAndWrap((l, indexResolution) -> {\n-                        EsqlCCSUtils.updateExecutionInfoWithUnavailableClusters(executionInfo, indexResolution.inner().failures());\n-                        l.onResponse(\n-                            result.withIndices(indexResolution.inner()).withMinimumTransportVersion(indexResolution.minimumVersion())\n-                        );\n-                    })\n-                );\n-            }\n-        } else {\n-            // occurs when dealing with local relations (row a = 1)\n+        // TODO: This is not yet index specific, but that will not matter as soon as #136804 is dealt with\n+        if (executionInfo.clusterAliases().isEmpty()) {\n+            // return empty resolution if the expression is pure CCS and resolved no remote clusters (like no-such-cluster*:index)\n             listener.onResponse(\n-                result.withIndices(IndexResolution.invalid(\"[none specified]\")).withMinimumTransportVersion(TransportVersion.current())\n+                result.withIndices(indexPattern, IndexResolution.valid(new EsIndex(indexPattern.indexPattern(), Map.of(), Map.of())))\n+            );\n+        } else {\n+            indexResolver.resolveAsMergedMappingAndRetrieveMinimumVersion(\n+                indexPattern.indexPattern(),\n+                result.fieldNames,\n+                // Maybe if no indices are returned, retry without index mode and provide a clearer error message.\n+                switch (indexMode) {\n+                    case IndexMode.TIME_SERIES -> {\n+                        var indexModeFilter = new TermQueryBuilder(IndexModeFieldMapper.NAME, IndexMode.TIME_SERIES.getName());\n+                        yield requestFilter != null\n+                            ? new BoolQueryBuilder().filter(requestFilter).filter(indexModeFilter)\n+                            : indexModeFilter;\n+                    }\n+                    default -> requestFilter;\n+                },\n+                indexMode == IndexMode.TIME_SERIES,\n+                preAnalysis.supportsAggregateMetricDouble(),\n+                preAnalysis.supportsDenseVector(),\n+                listener.delegateFailureAndWrap((l, indexResolution) -> {\n+                    EsqlCCSUtils.updateExecutionInfoWithUnavailableClusters(executionInfo, indexResolution.inner().failures());\n+                    l.onResponse(\n+                        result.withIndices(indexPattern, indexResolution.inner())\n+                            .withMinimumTransportVersion(indexResolution.minimumVersion())\n+                    );\n+                })\n             );\n         }\n     }\n@@ -843,10 +881,14 @@ private void analyzeWithRetry(\n     ) {\n         LOGGER.debug(\"Analyzing the plan ({})\", description);\n         try {\n-            if (result.indices.isValid() || requestFilter != null) {\n+            if (result.indexResolution.values().stream().anyMatch(IndexResolution::isValid) || requestFilter != null) {\n                 // We won't run this check with no filter and no valid indices since this may lead to false positive - missing index report\n                 // when the resolution result is not valid for a different reason.\n-                EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, result.indices, requestFilter != null);\n+                EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(\n+                    executionInfo,\n+                    result.indexResolution.values(),\n+                    requestFilter != null\n+                );\n             }\n             LogicalPlan plan = analyzedPlan(parsed, configuration, result, executionInfo);\n             LOGGER.debug(\"Analyzed plan ({}):\\n{}\", description, plan);\n@@ -900,7 +942,7 @@ private PhysicalPlan logicalPlanToPhysicalPlan(\n \n     private LogicalPlan analyzedPlan(LogicalPlan parsed, Configuration configuration, PreAnalysisResult r, EsqlExecutionInfo executionInfo)\n         throws Exception {\n-        handleFieldCapsFailures(configuration.allowPartialResults(), executionInfo, r.indices.failures());\n+        handleFieldCapsFailures(configuration.allowPartialResults(), executionInfo, r.indexResolution());\n         Analyzer analyzer = new Analyzer(new AnalyzerContext(configuration, functionRegistry, r), verifier);\n         LogicalPlan plan = analyzer.analyze(parsed);\n         plan.setAnalyzed();\n@@ -946,7 +988,7 @@ private PhysicalPlan optimizedPhysicalPlan(LogicalPlan optimizedPlan, PhysicalPl\n     public record PreAnalysisResult(\n         Set<String> fieldNames,\n         Set<String> wildcardJoinIndices,\n-        IndexResolution indices,\n+        Map<IndexPattern, IndexResolution> indexResolution,\n         Map<String, IndexResolution> lookupIndices,\n         EnrichResolution enrichResolution,\n         InferenceResolution inferenceResolution,\n@@ -954,21 +996,22 @@ public record PreAnalysisResult(\n     ) {\n \n         public PreAnalysisResult(Set<String> fieldNames, Set<String> wildcardJoinIndices) {\n-            this(fieldNames, wildcardJoinIndices, null, new HashMap<>(), null, InferenceResolution.EMPTY, null);\n-        }\n-\n-        PreAnalysisResult withIndices(IndexResolution indices) {\n-            return new PreAnalysisResult(\n+            this(\n                 fieldNames,\n                 wildcardJoinIndices,\n-                indices,\n-                lookupIndices,\n-                enrichResolution,\n-                inferenceResolution,\n-                minimumTransportVersion\n+                new HashMap<>(),\n+                new HashMap<>(),\n+                null,\n+                InferenceResolution.EMPTY,\n+                TransportVersion.current()\n             );\n         }\n \n+        PreAnalysisResult withIndices(IndexPattern indexPattern, IndexResolution indices) {\n+            indexResolution.put(indexPattern, indices);\n+            return this;\n+        }\n+\n         PreAnalysisResult addLookupIndexResolution(String index, IndexResolution indexResolution) {\n             lookupIndices.put(index, indexResolution);\n             return this;\n@@ -978,7 +1021,7 @@ PreAnalysisResult withEnrichResolution(EnrichResolution enrichResolution) {\n             return new PreAnalysisResult(\n                 fieldNames,\n                 wildcardJoinIndices,\n-                indices,\n+                indexResolution,\n                 lookupIndices,\n                 enrichResolution,\n                 inferenceResolution,\n@@ -990,7 +1033,7 @@ PreAnalysisResult withInferenceResolution(InferenceResolution inferenceResolutio\n             return new PreAnalysisResult(\n                 fieldNames,\n                 wildcardJoinIndices,\n-                indices,\n+                indexResolution,\n                 lookupIndices,\n                 enrichResolution,\n                 inferenceResolution,\n@@ -999,10 +1042,16 @@ PreAnalysisResult withInferenceResolution(InferenceResolution inferenceResolutio\n         }\n \n         PreAnalysisResult withMinimumTransportVersion(TransportVersion minimumTransportVersion) {\n+            if (this.minimumTransportVersion != null) {\n+                if (this.minimumTransportVersion.equals(minimumTransportVersion)) {\n+                    return this;\n+                }\n+                minimumTransportVersion = TransportVersion.min(this.minimumTransportVersion, minimumTransportVersion);\n+            }\n             return new PreAnalysisResult(\n                 fieldNames,\n                 wildcardJoinIndices,\n-                indices,\n+                indexResolution,\n                 lookupIndices,\n                 enrichResolution,\n                 inferenceResolution,\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/CsvTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/CsvTests.java\nindex f90547f57c0ff..e87f21bcdc7d0 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/CsvTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/CsvTests.java\n@@ -60,6 +60,7 @@\n import org.elasticsearch.xpack.esql.analysis.PreAnalyzer;\n import org.elasticsearch.xpack.esql.core.expression.Attribute;\n import org.elasticsearch.xpack.esql.core.expression.FoldContext;\n+import org.elasticsearch.xpack.esql.core.tree.Source;\n import org.elasticsearch.xpack.esql.core.type.DataType;\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.core.type.InvalidMappedField;\n@@ -79,6 +80,7 @@\n import org.elasticsearch.xpack.esql.optimizer.LogicalPreOptimizerContext;\n import org.elasticsearch.xpack.esql.optimizer.TestLocalPhysicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n import org.elasticsearch.xpack.esql.plan.physical.ChangePointExec;\n@@ -414,6 +416,16 @@ protected void assertResults(ExpectedResults expected, ActualResults actual, boo\n         CsvAssert.assertResults(expected, actual, ignoreOrder, logger);\n     }\n \n+    private static Map<IndexPattern, IndexResolution> loadIndexResolution(\n+        Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> datasets\n+    ) {\n+        Map<IndexPattern, IndexResolution> indexResolutions = new HashMap<>();\n+        for (var entry : datasets.entrySet()) {\n+            indexResolutions.put(entry.getKey(), loadIndexResolution(entry.getValue()));\n+        }\n+        return indexResolutions;\n+    }\n+\n     private static IndexResolution loadIndexResolution(CsvTestsDataLoader.MultiIndexTestDataset datasets) {\n         var indexNames = datasets.datasets().stream().map(CsvTestsDataLoader.TestDataset::indexName);\n         Map<String, IndexMode> indexModes = indexNames.collect(Collectors.toMap(x -> x, x -> IndexMode.STANDARD));\n@@ -429,21 +441,30 @@ private static IndexResolution loadIndexResolution(CsvTestsDataLoader.MultiIndex\n \n     private static Map<String, EsField> createMappingForIndex(CsvTestsDataLoader.TestDataset dataset) {\n         var mapping = new TreeMap<>(loadMapping(dataset.mappingFileName()));\n-        if (dataset.typeMapping() == null) {\n-            return mapping;\n+        if (dataset.typeMapping() != null) {\n+            for (var entry : dataset.typeMapping().entrySet()) {\n+                if (mapping.containsKey(entry.getKey())) {\n+                    DataType dataType = DataType.fromTypeName(entry.getValue());\n+                    EsField field = mapping.get(entry.getKey());\n+                    EsField editedField = new EsField(\n+                        field.getName(),\n+                        dataType,\n+                        field.getProperties(),\n+                        field.isAggregatable(),\n+                        field.getTimeSeriesFieldType()\n+                    );\n+                    mapping.put(entry.getKey(), editedField);\n+                }\n+            }\n         }\n-        for (var entry : dataset.typeMapping().entrySet()) {\n-            if (mapping.containsKey(entry.getKey())) {\n-                DataType dataType = DataType.fromTypeName(entry.getValue());\n-                EsField field = mapping.get(entry.getKey());\n-                EsField editedField = new EsField(\n-                    field.getName(),\n-                    dataType,\n-                    field.getProperties(),\n-                    field.isAggregatable(),\n-                    field.getTimeSeriesFieldType()\n-                );\n-                mapping.put(entry.getKey(), editedField);\n+        // Add dynamic mappings, but only if they are not already mapped\n+        if (dataset.dynamicTypeMapping() != null) {\n+            for (var entry : dataset.dynamicTypeMapping().entrySet()) {\n+                if (mapping.containsKey(entry.getKey()) == false) {\n+                    DataType dataType = DataType.fromTypeName(entry.getValue());\n+                    EsField editedField = new EsField(entry.getKey(), dataType, Map.of(), false, EsField.TimeSeriesFieldType.NONE);\n+                    mapping.put(entry.getKey(), editedField);\n+                }\n             }\n         }\n         return mapping;\n@@ -526,7 +547,7 @@ private static EnrichPolicy loadEnrichPolicyMapping(String policyFileName) {\n \n     private LogicalPlan analyzedPlan(\n         LogicalPlan parsed,\n-        CsvTestsDataLoader.MultiIndexTestDataset datasets,\n+        Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> datasets,\n         TransportVersion minimumVersion\n     ) {\n         var indexResolution = loadIndexResolution(datasets);\n@@ -549,46 +570,65 @@ private LogicalPlan analyzedPlan(\n         return plan;\n     }\n \n-    private static CsvTestsDataLoader.MultiIndexTestDataset testDatasets(LogicalPlan parsed) {\n+    private Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> testDatasets(LogicalPlan parsed) {\n         var preAnalysis = new PreAnalyzer().preAnalyze(parsed);\n-        if (preAnalysis.indexPattern() == null) {\n+        if (preAnalysis.indexes().isEmpty()) {\n             // If the data set doesn't matter we'll just grab one we know works. Employees is fine.\n-            return CsvTestsDataLoader.MultiIndexTestDataset.of(CSV_DATASET_MAP.get(\"employees\"));\n+            return Map.of(\n+                new IndexPattern(Source.EMPTY, \"employees\"),\n+                CsvTestsDataLoader.MultiIndexTestDataset.of(CSV_DATASET_MAP.get(\"employees\"))\n+            );\n         }\n \n-        String indexName = preAnalysis.indexPattern().indexPattern();\n-        List<CsvTestsDataLoader.TestDataset> datasets = new ArrayList<>();\n-        if (indexName.endsWith(\"*\")) {\n-            String indexPrefix = indexName.substring(0, indexName.length() - 1);\n-            for (var entry : CSV_DATASET_MAP.entrySet()) {\n-                if (entry.getKey().startsWith(indexPrefix)) {\n-                    datasets.add(entry.getValue());\n+        List<String> missing = new ArrayList<>();\n+        Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> all = new HashMap<>();\n+        for (IndexPattern indexPattern : preAnalysis.indexes().keySet()) {\n+            List<CsvTestsDataLoader.TestDataset> datasets = new ArrayList<>();\n+            String indexName = indexPattern.indexPattern();\n+            if (indexName.endsWith(\"*\")) {\n+                String indexPrefix = indexName.substring(0, indexName.length() - 1);\n+                for (var entry : CSV_DATASET_MAP.entrySet()) {\n+                    if (entry.getKey().startsWith(indexPrefix)) {\n+                        datasets.add(entry.getValue());\n+                    }\n                 }\n-            }\n-        } else {\n-            for (String index : indexName.split(\",\")) {\n-                var dataset = CSV_DATASET_MAP.get(index);\n-                if (dataset == null) {\n-                    throw new IllegalArgumentException(\"unknown CSV dataset for table [\" + index + \"]\");\n+            } else {\n+                for (String index : indexName.split(\",\")) {\n+                    var dataset = CSV_DATASET_MAP.get(index);\n+                    if (dataset == null) {\n+                        throw new IllegalArgumentException(\"unknown CSV dataset for table [\" + index + \"]\");\n+                    }\n+                    datasets.add(dataset);\n                 }\n-                datasets.add(dataset);\n             }\n+            if (datasets.isEmpty() == false) {\n+                all.put(indexPattern, new CsvTestsDataLoader.MultiIndexTestDataset(indexName, datasets));\n+            } else {\n+                missing.add(indexName);\n+            }\n+        }\n+        if (all.isEmpty()) {\n+            throw new IllegalArgumentException(\"Found no CSV datasets for table [\" + preAnalysis.indexes() + \"]\");\n         }\n-        if (datasets.isEmpty()) {\n-            throw new IllegalArgumentException(\"unknown CSV dataset for table [\" + indexName + \"]\");\n+        if (missing.isEmpty() == false) {\n+            throw new IllegalArgumentException(\"Did not find datasets for tables: \" + missing);\n         }\n-        return new CsvTestsDataLoader.MultiIndexTestDataset(indexName, datasets);\n+        return all;\n     }\n \n     private static TestPhysicalOperationProviders testOperationProviders(\n         FoldContext foldCtx,\n-        CsvTestsDataLoader.MultiIndexTestDataset datasets\n+        Map<IndexPattern, CsvTestsDataLoader.MultiIndexTestDataset> allDatasets\n     ) throws Exception {\n         var indexPages = new ArrayList<TestPhysicalOperationProviders.IndexPage>();\n-        for (CsvTestsDataLoader.TestDataset dataset : datasets.datasets()) {\n-            var testData = loadPageFromCsv(CsvTests.class.getResource(\"/data/\" + dataset.dataFileName()), dataset.typeMapping());\n-            Set<String> mappedFields = loadMapping(dataset.mappingFileName()).keySet();\n-            indexPages.add(new TestPhysicalOperationProviders.IndexPage(dataset.indexName(), testData.v1(), testData.v2(), mappedFields));\n+        for (CsvTestsDataLoader.MultiIndexTestDataset datasets : allDatasets.values()) {\n+            for (CsvTestsDataLoader.TestDataset dataset : datasets.datasets()) {\n+                var testData = loadPageFromCsv(CsvTests.class.getResource(\"/data/\" + dataset.dataFileName()), dataset.typeMapping());\n+                Set<String> mappedFields = loadMapping(dataset.mappingFileName()).keySet();\n+                indexPages.add(\n+                    new TestPhysicalOperationProviders.IndexPage(dataset.indexName(), testData.v1(), testData.v2(), mappedFields)\n+                );\n+            }\n         }\n         return TestPhysicalOperationProviders.create(foldCtx, indexPages);\n     }\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTestUtils.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTestUtils.java\nindex d6cd6ee3ead84..4b46c26f56f35 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTestUtils.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTestUtils.java\n@@ -12,6 +12,7 @@\n import org.elasticsearch.test.ESTestCase;\n import org.elasticsearch.xpack.core.enrich.EnrichPolicy;\n import org.elasticsearch.xpack.esql.EsqlTestUtils;\n+import org.elasticsearch.xpack.esql.core.tree.Source;\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.core.type.InvalidMappedField;\n import org.elasticsearch.xpack.esql.enrich.ResolvedEnrichPolicy;\n@@ -22,18 +23,23 @@\n import org.elasticsearch.xpack.esql.inference.ResolvedInference;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n import org.elasticsearch.xpack.esql.parser.QueryParams;\n+import org.elasticsearch.xpack.esql.plan.IndexPattern;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n+import org.elasticsearch.xpack.esql.plan.logical.UnresolvedRelation;\n import org.elasticsearch.xpack.esql.session.Configuration;\n \n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.HashMap;\n import java.util.LinkedHashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n import java.util.function.Predicate;\n import java.util.function.Supplier;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n \n import static org.elasticsearch.xpack.core.enrich.EnrichPolicy.GEO_MATCH_TYPE;\n import static org.elasticsearch.xpack.core.enrich.EnrichPolicy.MATCH_TYPE;\n@@ -55,10 +61,16 @@ public static Analyzer expandedDefaultAnalyzer() {\n         return analyzer(expandedDefaultIndexResolution());\n     }\n \n+    /** Simplest analyzer with a single index, which must be valid */\n     public static Analyzer analyzer(IndexResolution indexResolution) {\n         return analyzer(indexResolution, TEST_VERIFIER);\n     }\n \n+    /** Simple analyzer with multiple indexes, which may also be invalid */\n+    public static Analyzer analyzer(Map<IndexPattern, IndexResolution> indexResolutions) {\n+        return analyzer(indexResolutions, defaultLookupResolution(), defaultEnrichResolution(), TEST_VERIFIER, TEST_CFG);\n+    }\n+\n     public static Analyzer analyzer(IndexResolution indexResolution, Map<String, IndexResolution> lookupResolution) {\n         return analyzer(indexResolution, lookupResolution, TEST_VERIFIER);\n     }\n@@ -77,11 +89,11 @@ public static Analyzer analyzer(\n         EnrichResolution enrichResolution,\n         Verifier verifier\n     ) {\n-        return analyzer(indexResolution, lookupResolution, enrichResolution, verifier, TEST_CFG);\n+        return analyzer(indexResolutions(indexResolution), lookupResolution, enrichResolution, verifier, TEST_CFG);\n     }\n \n     public static Analyzer analyzer(\n-        IndexResolution indexResolution,\n+        Map<IndexPattern, IndexResolution> indexResolutions,\n         Map<String, IndexResolution> lookupResolution,\n         EnrichResolution enrichResolution,\n         Verifier verifier,\n@@ -91,7 +103,7 @@ public static Analyzer analyzer(\n             testAnalyzerContext(\n                 config,\n                 new EsqlFunctionRegistry(),\n-                indexResolution,\n+                mergeIndexResolutions(indexResolutions, defaultSubqueryResolution()),\n                 lookupResolution,\n                 enrichResolution,\n                 defaultInferenceResolution()\n@@ -100,22 +112,25 @@ public static Analyzer analyzer(\n         );\n     }\n \n-    public static Analyzer analyzer(IndexResolution indexResolution, Verifier verifier, Configuration config) {\n-        return analyzer(indexResolution, defaultLookupResolution(), defaultEnrichResolution(), verifier, config);\n+    private static Map<IndexPattern, IndexResolution> mergeIndexResolutions(\n+        Map<IndexPattern, IndexResolution> indexResolutions,\n+        Map<IndexPattern, IndexResolution> more\n+    ) {\n+        Map<IndexPattern, IndexResolution> combined = new HashMap<>(indexResolutions);\n+        combined.putAll(more);\n+        return combined;\n+    }\n+\n+    public static Analyzer analyzer(Map<IndexPattern, IndexResolution> indexResolutions, Verifier verifier, Configuration config) {\n+        return analyzer(indexResolutions, defaultLookupResolution(), defaultEnrichResolution(), verifier, config);\n     }\n \n     public static Analyzer analyzer(Verifier verifier) {\n-        return new Analyzer(\n-            testAnalyzerContext(\n-                EsqlTestUtils.TEST_CFG,\n-                new EsqlFunctionRegistry(),\n-                analyzerDefaultMapping(),\n-                defaultLookupResolution(),\n-                defaultEnrichResolution(),\n-                defaultInferenceResolution()\n-            ),\n-            verifier\n-        );\n+        return analyzer(analyzerDefaultMapping(), defaultLookupResolution(), defaultEnrichResolution(), verifier, EsqlTestUtils.TEST_CFG);\n+    }\n+\n+    public static Analyzer analyzer(Map<IndexPattern, IndexResolution> indexResolutions, Verifier verifier) {\n+        return analyzer(indexResolutions, defaultLookupResolution(), defaultEnrichResolution(), verifier, EsqlTestUtils.TEST_CFG);\n     }\n \n     public static LogicalPlan analyze(String query) {\n@@ -123,11 +138,14 @@ public static LogicalPlan analyze(String query) {\n     }\n \n     public static LogicalPlan analyze(String query, String mapping) {\n-        return analyze(query, \"test\", mapping);\n+        return analyze(query, indexFromQuery(query), mapping);\n     }\n \n     public static LogicalPlan analyze(String query, String index, String mapping) {\n-        return analyze(query, analyzer(loadMapping(mapping, index), TEST_VERIFIER, configuration(query)));\n+        Map<IndexPattern, IndexResolution> indexResolutions = index == null\n+            ? Map.of()\n+            : Map.of(new IndexPattern(Source.EMPTY, index), loadMapping(mapping, index));\n+        return analyze(query, analyzer(indexResolutions, TEST_VERIFIER, configuration(query)));\n     }\n \n     public static LogicalPlan analyze(String query, Analyzer analyzer) {\n@@ -138,12 +156,40 @@ public static LogicalPlan analyze(String query, Analyzer analyzer) {\n         return analyzed;\n     }\n \n+    private static final Pattern indexFromPattern = Pattern.compile(\"(?i)FROM\\\\s+([\\\\w-]+)\");\n+\n+    private static String indexFromQuery(String query) {\n+        // Extract the index name from the FROM clause of the query using regexp\n+        Matcher matcher = indexFromPattern.matcher(query);\n+        if (matcher.find()) {\n+            return matcher.group(1);\n+        }\n+        return null;\n+    }\n+\n     public static LogicalPlan analyze(String query, String mapping, QueryParams params) {\n+        return analyze(query, indexFromQuery(query), mapping, params);\n+    }\n+\n+    public static LogicalPlan analyze(String query, String index, String mapping, QueryParams params) {\n         var plan = new EsqlParser().createStatement(query, params);\n-        var analyzer = analyzer(loadMapping(mapping, \"test\"), TEST_VERIFIER, configuration(query));\n+        var indexResolutions = Map.of(new IndexPattern(Source.EMPTY, index), loadMapping(mapping, index));\n+        var analyzer = analyzer(indexResolutions, TEST_VERIFIER, configuration(query));\n         return analyzer.analyze(plan);\n     }\n \n+    public static UnresolvedRelation unresolvedRelation(String index) {\n+        return new UnresolvedRelation(\n+            Source.EMPTY,\n+            new IndexPattern(Source.EMPTY, index),\n+            false,\n+            List.of(),\n+            IndexMode.STANDARD,\n+            null,\n+            \"FROM\"\n+        );\n+    }\n+\n     public static IndexResolution loadMapping(String resource, String indexName, IndexMode indexMode) {\n         EsIndex test = new EsIndex(indexName, EsqlTestUtils.loadMapping(resource), Map.of(indexName, indexMode));\n         return IndexResolution.valid(test);\n@@ -154,8 +200,30 @@ public static IndexResolution loadMapping(String resource, String indexName) {\n         return IndexResolution.valid(test);\n     }\n \n-    public static IndexResolution analyzerDefaultMapping() {\n-        return loadMapping(\"mapping-basic.json\", \"test\");\n+    public static Map<IndexPattern, IndexResolution> analyzerDefaultMapping() {\n+        // Most tests use either \"test\" or \"employees\" as the index name, but for the same mapping\n+        return Map.of(\n+            new IndexPattern(Source.EMPTY, \"test\"),\n+            loadMapping(\"mapping-basic.json\", \"test\"),\n+            new IndexPattern(Source.EMPTY, \"employees\"),\n+            loadMapping(\"mapping-basic.json\", \"employees\")\n+        );\n+    }\n+\n+    public static Map<IndexPattern, IndexResolution> indexResolutions(EsIndex... indexes) {\n+        Map<IndexPattern, IndexResolution> map = new HashMap<>();\n+        for (EsIndex index : indexes) {\n+            map.put(new IndexPattern(Source.EMPTY, index.name()), IndexResolution.valid(index));\n+        }\n+        return map;\n+    }\n+\n+    public static Map<IndexPattern, IndexResolution> indexResolutions(IndexResolution... indexes) {\n+        Map<IndexPattern, IndexResolution> map = new HashMap<>();\n+        for (IndexResolution index : indexes) {\n+            map.put(new IndexPattern(Source.EMPTY, index.get().name()), index);\n+        }\n+        return map;\n     }\n \n     public static IndexResolution expandedDefaultIndexResolution() {\n@@ -232,6 +300,17 @@ public static InferenceResolution defaultInferenceResolution() {\n             .build();\n     }\n \n+    public static Map<IndexPattern, IndexResolution> defaultSubqueryResolution() {\n+        return Map.of(\n+            new IndexPattern(Source.EMPTY, \"languages\"),\n+            loadMapping(\"mapping-languages.json\", \"languages\"),\n+            new IndexPattern(Source.EMPTY, \"sample_data\"),\n+            loadMapping(\"mapping-sample_data.json\", \"sample_data\"),\n+            new IndexPattern(Source.EMPTY, \"test_mixed_types\"),\n+            loadMapping(\"mapping-default-incompatible.json\", \"test_mixed_types\")\n+        );\n+    }\n+\n     public static String randomInferenceId() {\n         return ESTestCase.randomFrom(VALID_INFERENCE_IDS);\n     }\n@@ -308,7 +387,7 @@ public static IndexResolution indexWithDateDateNanosUnionType() {\n         EsField dateDateNanosField = new InvalidMappedField(dateDateNanos, typesToIndices1);\n         EsField dateDateNanosLongField = new InvalidMappedField(dateDateNanosLong, typesToIndices2);\n         EsIndex index = new EsIndex(\n-            \"test*\",\n+            \"index*\",\n             Map.of(dateDateNanos, dateDateNanosField, dateDateNanosLong, dateDateNanosLongField),\n             Map.of(\"index1\", IndexMode.STANDARD, \"index2\", IndexMode.STANDARD, \"index3\", IndexMode.STANDARD)\n         );\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTests.java\nindex 62cd898386870..46c8b73213abe 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/AnalyzerTests.java\n@@ -131,10 +131,12 @@\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.analyzerDefaultMapping;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultEnrichResolution;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultInferenceResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexWithDateDateNanosUnionType;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.randomInferenceIdOtherThan;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.tsdbIndexResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.unresolvedRelation;\n import static org.elasticsearch.xpack.esql.core.tree.Source.EMPTY;\n import static org.elasticsearch.xpack.esql.core.type.DataType.AGGREGATE_METRIC_DOUBLE;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DATETIME;\n@@ -142,6 +144,7 @@\n import static org.elasticsearch.xpack.esql.core.type.DataType.DATE_PERIOD;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DENSE_VECTOR;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DOUBLE;\n+import static org.elasticsearch.xpack.esql.core.type.DataType.INTEGER;\n import static org.elasticsearch.xpack.esql.core.type.DataType.KEYWORD;\n import static org.elasticsearch.xpack.esql.core.type.DataType.LONG;\n import static org.elasticsearch.xpack.esql.core.type.DataType.UNSUPPORTED;\n@@ -162,16 +165,7 @@\n //@TestLogging(value = \"org.elasticsearch.xpack.esql.analysis:TRACE\", reason = \"debug\")\n public class AnalyzerTests extends ESTestCase {\n \n-    private static final UnresolvedRelation UNRESOLVED_RELATION = new UnresolvedRelation(\n-        EMPTY,\n-        new IndexPattern(EMPTY, \"idx\"),\n-        false,\n-        List.of(),\n-        IndexMode.STANDARD,\n-        null,\n-        \"FROM\"\n-    );\n-\n+    private static final UnresolvedRelation UNRESOLVED_RELATION = unresolvedRelation(\"idx\");\n     private static final int MAX_LIMIT = AnalyzerSettings.QUERY_RESULT_TRUNCATION_MAX_SIZE.getDefault(Settings.EMPTY);\n     private static final int DEFAULT_LIMIT = AnalyzerSettings.QUERY_RESULT_TRUNCATION_DEFAULT_SIZE.getDefault(Settings.EMPTY);\n     private static final int DEFAULT_TIMESERIES_LIMIT = AnalyzerSettings.QUERY_TIMESERIES_RESULT_TRUNCATION_DEFAULT_SIZE.getDefault(\n@@ -188,7 +182,7 @@ public void testIndexResolution() {\n     }\n \n     public void testFailOnUnresolvedIndex() {\n-        Analyzer analyzer = analyzer(IndexResolution.invalid(\"Unknown index [idx]\"));\n+        Analyzer analyzer = analyzer(Map.of(new IndexPattern(Source.EMPTY, \"idx\"), IndexResolution.invalid(\"Unknown index [idx]\")));\n \n         VerificationException e = expectThrows(VerificationException.class, () -> analyzer.analyze(UNRESOLVED_RELATION));\n \n@@ -199,7 +193,7 @@ public void testIndexWithClusterResolution() {\n         EsIndex idx = new EsIndex(\"cluster:idx\", Map.of());\n         Analyzer analyzer = analyzer(IndexResolution.valid(idx));\n \n-        var plan = analyzer.analyze(UNRESOLVED_RELATION);\n+        var plan = analyzer.analyze(unresolvedRelation(\"cluster:idx\"));\n         var limit = as(plan, Limit.class);\n \n         assertEquals(new EsRelation(EMPTY, idx.name(), IndexMode.STANDARD, idx.indexNameWithModes(), NO_FIELDS), limit.child());\n@@ -268,7 +262,7 @@ public void testRowAttributeResolution() {\n         var plan = analyzer.analyze(\n             new Eval(\n                 EMPTY,\n-                new Row(EMPTY, List.of(new Alias(EMPTY, \"emp_no\", new Literal(EMPTY, 1, DataType.INTEGER)))),\n+                new Row(EMPTY, List.of(new Alias(EMPTY, \"emp_no\", new Literal(EMPTY, 1, INTEGER)))),\n                 List.of(new Alias(EMPTY, \"e\", new UnresolvedAttribute(EMPTY, \"emp_no\")))\n             )\n         );\n@@ -410,16 +404,16 @@ public void testNoProjection() {\n                 from test\n                 \"\"\",\n             DataType.KEYWORD,\n-            DataType.INTEGER,\n+            INTEGER,\n             DataType.KEYWORD,\n             DataType.TEXT,\n             DATETIME,\n             DataType.TEXT,\n             DataType.KEYWORD,\n-            DataType.INTEGER,\n+            INTEGER,\n             DataType.KEYWORD,\n             DataType.LONG,\n-            DataType.INTEGER\n+            INTEGER\n         );\n     }\n \n@@ -1687,7 +1681,7 @@ public void testEnrichPolicyWithError() {\n         AnalyzerContext context = testAnalyzerContext(\n             configuration(\"from test\"),\n             new EsqlFunctionRegistry(),\n-            testIndex,\n+            indexResolutions(testIndex),\n             enrichResolution,\n             emptyInferenceResolution()\n         );\n@@ -1843,7 +1837,7 @@ public void testEnrichFieldsIncludeMatchField() {\n         AnalyzerContext context = testAnalyzerContext(\n             configuration(query),\n             new EsqlFunctionRegistry(),\n-            testIndex,\n+            indexResolutions(testIndex),\n             enrichResolution,\n             emptyInferenceResolution()\n         );\n@@ -1924,7 +1918,7 @@ public void testUnresolvedMvExpand() {\n \n     public void testRegularStats() {\n         var plan = analyze(\"\"\"\n-            from tests\n+            from test\n             | stats by salary\n             \"\"\");\n \n@@ -2644,7 +2638,7 @@ private void validateConditionalFunctions(LogicalPlan plan) {\n         assertEquals(projection.dataType(), DataType.DOUBLE);\n         projection = as(projections.get(1), ReferenceAttribute.class);\n         assertEquals(projection.name(), \"y\");\n-        assertEquals(projection.dataType(), DataType.INTEGER);\n+        assertEquals(projection.dataType(), INTEGER);\n         projection = as(projections.get(2), ReferenceAttribute.class);\n         assertEquals(projection.name(), \"z\");\n         assertEquals(projection.dataType(), DataType.LONG);\n@@ -3053,7 +3047,7 @@ public void testFromEnrichAndMatchColonUsage() {\n             | EVAL x = to_string(languages)\n             | ENRICH _any:languages ON x\n             | WHERE first_name: \"Anna\"\n-            \"\"\", \"mapping-default.json\");\n+            \"\"\", \"*:test\", \"mapping-default.json\");\n         var limit = as(plan, Limit.class);\n         var filter = as(limit.child(), Filter.class);\n         var match = as(filter.condition(), MatchOperator.class);\n@@ -3062,7 +3056,7 @@ public void testFromEnrichAndMatchColonUsage() {\n         assertEquals(enrich.policy().getMatchField(), \"language_code\");\n         var eval = as(enrich.child(), Eval.class);\n         var esRelation = as(eval.child(), EsRelation.class);\n-        assertEquals(esRelation.indexPattern(), \"test\");\n+        assertEquals(esRelation.indexPattern(), \"*:test\"); // This tests nothing, as whatever appears here comes from the test itself\n     }\n \n     public void testFunctionNamedParamsAsFunctionArgument() {\n@@ -3120,7 +3114,7 @@ public void testResolveInsist_fieldExists_insistedOutputContainsNoUnmappedFields\n \n         Attribute last = plan.output().getLast();\n         assertThat(last.name(), is(\"emp_no\"));\n-        assertThat(last.dataType(), is(DataType.INTEGER));\n+        assertThat(last.dataType(), is(INTEGER));\n         assertThat(\n             plan.output()\n                 .stream()\n@@ -3157,7 +3151,7 @@ public void testResolveInsist_multiIndexFieldPartiallyMappedWithSingleKeywordTyp\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3172,7 +3166,7 @@ public void testResolveInsist_multiIndexFieldPartiallyMappedWithSingleKeywordTyp\n         );\n \n         String query = \"FROM foo, bar | INSIST_üêî message\";\n-        var plan = analyze(query, analyzer(resolution, TEST_VERIFIER, configuration(query)));\n+        var plan = analyze(query, analyzer(indexResolutions(resolution), TEST_VERIFIER, configuration(query)));\n         var limit = as(plan, Limit.class);\n         var insist = as(limit.child(), Insist.class);\n         var attribute = (FieldAttribute) EsqlTestUtils.singleValue(insist.output());\n@@ -3184,7 +3178,7 @@ public void testResolveInsist_multiIndexFieldExistsWithSingleTypeButIsNotKeyword\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3212,7 +3206,7 @@ public void testResolveInsist_multiIndexFieldPartiallyExistsWithMultiTypesNoKeyw\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3240,7 +3234,7 @@ public void testResolveInsist_multiIndexSameMapping_fieldIsMapped() {\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3265,7 +3259,7 @@ public void testResolveInsist_multiIndexFieldPartiallyExistsWithMultiTypesWithKe\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3294,7 +3288,7 @@ public void testResolveInsist_multiIndexFieldPartiallyExistsWithMultiTypesWithCa\n         assumeTrue(\"Requires UNMAPPED FIELDS\", EsqlCapabilities.Cap.UNMAPPED_FIELDS.isEnabled());\n \n         IndexResolution resolution = IndexResolver.mergedMappings(\n-            \"foo, bar\",\n+            \"foo,bar\",\n             new IndexResolver.FieldsInfo(\n                 new FieldCapabilitiesResponse(\n                     List.of(\n@@ -3310,7 +3304,7 @@ public void testResolveInsist_multiIndexFieldPartiallyExistsWithMultiTypesWithCa\n         );\n         VerificationException e = expectThrows(\n             VerificationException.class,\n-            () -> analyze(\"FROM multi_index | INSIST_üêî message | EVAL message = message :: keyword\", analyzer(resolution, TEST_VERIFIER))\n+            () -> analyze(\"FROM foo, bar | INSIST_üêî message | EVAL message = message :: keyword\", analyzer(resolution, TEST_VERIFIER))\n         );\n         // This isn't the most informative error, but it'll do for now.\n         assertThat(\n@@ -3810,7 +3804,7 @@ private static LogicalPlan analyzeWithEmptyFieldCapsResponse(String query) throw\n         );\n         IndexResolver.FieldsInfo caps = new IndexResolver.FieldsInfo(new FieldCapabilitiesResponse(idxResponses, List.of()), true, true);\n         IndexResolution resolution = IndexResolver.mergedMappings(\"test*\", caps);\n-        var analyzer = analyzer(resolution, TEST_VERIFIER, configuration(query));\n+        var analyzer = analyzer(indexResolutions(resolution), TEST_VERIFIER, configuration(query));\n         return analyze(query, analyzer);\n     }\n \n@@ -4427,7 +4421,7 @@ public void testImplicitCastingForDateAndDateNanosFields() {\n         // Validate if a union typed field is cast to a type explicitly, implicit casting won't be applied again, and include some cases of\n         // nested casting as well.\n         LogicalPlan plan = analyze(\"\"\"\n-            FROM tests\n+            FROM index*\n             | Eval a = date_and_date_nanos, b = date_and_date_nanos::datetime, c = date_and_date_nanos::date_nanos,\n                    d = date_and_date_nanos::datetime::datetime, e = date_and_date_nanos::datetime::date_nanos,\n                    f = date_and_date_nanos::date_nanos::datetime, g = date_and_date_nanos::date_nanos::date_nanos,\n@@ -4535,7 +4529,7 @@ public void testImplicitCastingForDateAndDateNanosFields() {\n         fa = as(toDateNanos.field(), FieldAttribute.class);\n         verifyNameAndTypeAndMultiTypeEsField(fa.name(), fa.dataType(), \"$$date_and_date_nanos$converted_to$long\", LONG, fa);\n         EsRelation esRelation = as(eval.child(), EsRelation.class);\n-        assertEquals(\"test*\", esRelation.indexPattern());\n+        assertEquals(\"index*\", esRelation.indexPattern());\n     }\n \n     public void testGroupingOverridesInStats() {\n@@ -4628,12 +4622,11 @@ public void testImplicitCastingForAggregateMetricDouble() {\n             Map.of(\"k8s\", IndexMode.TIME_SERIES, \"k8s-downsampled\", IndexMode.TIME_SERIES),\n             Set.of()\n         );\n-        var indexResolution = IndexResolution.valid(esIndex);\n         var analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                indexResolution,\n+                indexResolutions(esIndex),\n                 defaultEnrichResolution(),\n                 defaultInferenceResolution()\n             ),\n@@ -4697,6 +4690,6 @@ static Literal string(String value) {\n     }\n \n     static Literal literal(int value) {\n-        return new Literal(EMPTY, value, DataType.INTEGER);\n+        return new Literal(EMPTY, value, INTEGER);\n     }\n }\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/ParsingTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/ParsingTests.java\nindex 606db6fb8fb2c..ae3426178e36b 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/ParsingTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/ParsingTests.java\n@@ -45,6 +45,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.emptyInferenceResolution;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.emptyPolicyResolution;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.instanceOf;\n@@ -56,7 +57,13 @@ public class ParsingTests extends ESTestCase {\n \n     private final IndexResolution defaultIndex = loadIndexResolution(\"mapping-basic.json\");\n     private final Analyzer defaultAnalyzer = new Analyzer(\n-        testAnalyzerContext(TEST_CFG, new EsqlFunctionRegistry(), defaultIndex, emptyPolicyResolution(), emptyInferenceResolution()),\n+        testAnalyzerContext(\n+            TEST_CFG,\n+            new EsqlFunctionRegistry(),\n+            indexResolutions(defaultIndex),\n+            emptyPolicyResolution(),\n+            emptyInferenceResolution()\n+        ),\n         TEST_VERIFIER\n     );\n \ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/VerifierTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/VerifierTests.java\nindex b35258978b72c..0992489b6086d 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/VerifierTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/analysis/VerifierTests.java\n@@ -1006,10 +1006,10 @@ public void testFilterNullField() {\n         query(\"from test | where null::boolean\");\n \n         // Provide `NULL` type in `EVAL`\n-        query(\"from t | EVAL x = null | where x\");\n+        query(\"from test | EVAL x = null | where x\");\n \n         // `to_string(null)` is of `KEYWORD` type null, resulting in `to_string(null) == \"abc\"` being of `BOOLEAN`\n-        query(\"from t | where to_string(null) == \\\"abc\\\"\");\n+        query(\"from test | where to_string(null) == \\\"abc\\\"\");\n \n         // Other DataTypes can contain null values\n         assertEquals(\"1:19: Condition expression needs to be boolean, found [KEYWORD]\", error(\"from test | where null::string\"));\n@@ -1114,27 +1114,27 @@ public void testInlineImpossibleConvert() {\n \n     public void testAggregateOnCounter() {\n         assertThat(\n-            error(\"FROM tests | STATS min(network.bytes_in)\", tsdb),\n+            error(\"FROM test | STATS min(network.bytes_in)\", tsdb),\n             equalTo(\n-                \"1:20: argument of [min(network.bytes_in)] must be\"\n+                \"1:19: argument of [min(network.bytes_in)] must be\"\n                     + \" [boolean, date, ip, string, version, aggregate_metric_double or numeric except counter types],\"\n                     + \" found value [network.bytes_in] type [counter_long]\"\n             )\n         );\n \n         assertThat(\n-            error(\"FROM tests | STATS max(network.bytes_in)\", tsdb),\n+            error(\"FROM test | STATS max(network.bytes_in)\", tsdb),\n             equalTo(\n-                \"1:20: argument of [max(network.bytes_in)] must be\"\n+                \"1:19: argument of [max(network.bytes_in)] must be\"\n                     + \" [boolean, date, ip, string, version, aggregate_metric_double or numeric except counter types],\"\n                     + \" found value [network.bytes_in] type [counter_long]\"\n             )\n         );\n \n         assertThat(\n-            error(\"FROM tests | STATS count(network.bytes_out)\", tsdb),\n+            error(\"FROM test | STATS count(network.bytes_out)\", tsdb),\n             equalTo(\n-                \"1:20: argument of [count(network.bytes_out)] must be [any type except counter types or dense_vector],\"\n+                \"1:19: argument of [count(network.bytes_out)] must be [any type except counter types or dense_vector],\"\n                     + \" found value [network.bytes_out] type [counter_long]\"\n             )\n         );\n@@ -1157,91 +1157,88 @@ public void testAggsResolutionWithUnresolvedGroupings() {\n             new String[] { \"avg\", \"count\", \"count_distinct\", \"min\", \"max\", \"median\", \"median_absolute_deviation\", \"sum\", \"values\" }\n         );\n \n-        assertThat(error(\"FROM tests | STATS \" + agg_func + \"(emp_no) by foobar\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n+        assertThat(error(\"FROM test | STATS \" + agg_func + \"(emp_no) by foobar\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n+        assertThat(error(\"FROM test | STATS \" + agg_func + \"(x) by foobar, x = emp_no\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n+        assertThat(error(\"FROM test | STATS \" + agg_func + \"(foobar) by foobar\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n         assertThat(\n-            error(\"FROM tests | STATS \" + agg_func + \"(x) by foobar, x = emp_no\"),\n-            matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\")\n-        );\n-        assertThat(error(\"FROM tests | STATS \" + agg_func + \"(foobar) by foobar\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n-        assertThat(\n-            error(\"FROM tests | STATS \" + agg_func + \"(foobar) by BUCKET(hire_date, 10)\"),\n+            error(\"FROM test | STATS \" + agg_func + \"(foobar) by BUCKET(hire_date, 10)\"),\n             matchesRegex(\n                 \"1:\\\\d+: function expects exactly four arguments when the first one is of type \\\\[DATETIME]\"\n                     + \" and the second of type \\\\[INTEGER]\\n\"\n                     + \"line 1:\\\\d+: Unknown column \\\\[foobar]\"\n             )\n         );\n-        assertThat(error(\"FROM tests | STATS \" + agg_func + \"(foobar) by emp_no\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n+        assertThat(error(\"FROM test | STATS \" + agg_func + \"(foobar) by emp_no\"), matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\"));\n         // TODO: Ideally, we'd detect that count_distinct(x) doesn't require an error message.\n         assertThat(\n-            error(\"FROM tests | STATS \" + agg_func + \"(x) by x = foobar\"),\n+            error(\"FROM test | STATS \" + agg_func + \"(x) by x = foobar\"),\n             matchesRegex(\"1:\\\\d+: Unknown column \\\\[foobar]\\n\" + \"line 1:\\\\d+: Unknown column \\\\[x]\")\n         );\n     }\n \n     public void testNotAllowRateOutsideMetrics() {\n         assertThat(\n-            error(\"FROM tests | STATS avg(rate(network.bytes_in))\", tsdb),\n+            error(\"FROM test  | STATS avg(rate(network.bytes_in))\", tsdb),\n             equalTo(\"1:24: time_series aggregate[rate(network.bytes_in)] can only be used with the TS command\")\n         );\n         assertThat(\n-            error(\"FROM tests | STATS rate(network.bytes_in)\", tsdb),\n+            error(\"FROM test  | STATS rate(network.bytes_in)\", tsdb),\n             equalTo(\"1:20: time_series aggregate[rate(network.bytes_in)] can only be used with the TS command\")\n         );\n         assertThat(\n-            error(\"FROM tests | STATS max_over_time(network.connections)\", tsdb),\n+            error(\"FROM test  | STATS max_over_time(network.connections)\", tsdb),\n             equalTo(\"1:20: time_series aggregate[max_over_time(network.connections)] can only be used with the TS command\")\n         );\n         assertThat(\n-            error(\"FROM tests | EVAL r = rate(network.bytes_in)\", tsdb),\n+            error(\"FROM test  | EVAL r = rate(network.bytes_in)\", tsdb),\n             equalTo(\"1:23: aggregate function [rate(network.bytes_in)] not allowed outside STATS command\")\n         );\n     }\n \n     public void testTimeseriesAggregate() {\n         assertThat(\n-            error(\"TS tests | STATS rate(network.bytes_in)\", tsdb),\n+            error(\"TS test  | STATS rate(network.bytes_in)\", tsdb),\n             equalTo(\n                 \"1:18: time-series aggregate function [rate(network.bytes_in)] can only be used with the TS command \"\n                     + \"and inside another aggregate function\"\n             )\n         );\n         assertThat(\n-            error(\"TS tests | STATS avg_over_time(network.connections)\", tsdb),\n+            error(\"TS test  | STATS avg_over_time(network.connections)\", tsdb),\n             equalTo(\n                 \"1:18: time-series aggregate function [avg_over_time(network.connections)] can only be used \"\n                     + \"with the TS command and inside another aggregate function\"\n             )\n         );\n         assertThat(\n-            error(\"TS tests | STATS avg(rate(network.bytes_in)), rate(network.bytes_in)\", tsdb),\n+            error(\"TS test  | STATS avg(rate(network.bytes_in)), rate(network.bytes_in)\", tsdb),\n             equalTo(\n                 \"1:47: time-series aggregate function [rate(network.bytes_in)] can only be used \"\n                     + \"with the TS command and inside another aggregate function\"\n             )\n         );\n \n-        assertThat(error(\"TS tests | STATS max(avg(rate(network.bytes_in)))\", tsdb), equalTo(\"\"\"\n+        assertThat(error(\"TS test  | STATS max(avg(rate(network.bytes_in)))\", tsdb), equalTo(\"\"\"\n             1:22: nested aggregations [avg(rate(network.bytes_in))] \\\n             not allowed inside other aggregations [max(avg(rate(network.bytes_in)))]\n             line 1:12: cannot use aggregate function [avg(rate(network.bytes_in))] \\\n             inside over-time aggregation function [rate(network.bytes_in)]\"\"\"));\n \n-        assertThat(error(\"TS tests | STATS max(avg(rate(network.bytes_in)))\", tsdb), equalTo(\"\"\"\n+        assertThat(error(\"TS test  | STATS max(avg(rate(network.bytes_in)))\", tsdb), equalTo(\"\"\"\n             1:22: nested aggregations [avg(rate(network.bytes_in))] \\\n             not allowed inside other aggregations [max(avg(rate(network.bytes_in)))]\n             line 1:12: cannot use aggregate function [avg(rate(network.bytes_in))] \\\n             inside over-time aggregation function [rate(network.bytes_in)]\"\"\"));\n \n         assertThat(\n-            error(\"TS tests | STATS rate(network.bytes_in) BY bucket(@timestamp, 1 hour)\", tsdb),\n+            error(\"TS test  | STATS rate(network.bytes_in) BY bucket(@timestamp, 1 hour)\", tsdb),\n             equalTo(\n                 \"1:18: time-series aggregate function [rate(network.bytes_in)] can only be used \"\n                     + \"with the TS command and inside another aggregate function\"\n             )\n         );\n         assertThat(\n-            error(\"TS tests | STATS COUNT(*)\", tsdb),\n+            error(\"TS test  | STATS COUNT(*)\", tsdb),\n             equalTo(\"1:18: count_star [COUNT(*)] can't be used with TS command; use count on a field instead\")\n         );\n     }\n@@ -1733,45 +1730,45 @@ public void testConditionalFunctionsWithMixedNumericTypes() {\n \n             // counter\n             assertEquals(\n-                \"1:23: second argument of [\"\n+                \"1:22: second argument of [\"\n                     + functionName\n                     + \"(network.bytes_in, 0)] must be [counter_long], found value [0] type [integer]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(network.bytes_in, 0)\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(network.bytes_in, 0)\", tsdb)\n             );\n \n             assertEquals(\n-                \"1:23: second argument of [\"\n+                \"1:22: second argument of [\"\n                     + functionName\n                     + \"(network.bytes_in, to_long(0))] must be [counter_long], \"\n                     + \"found value [to_long(0)] type [long]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(network.bytes_in, to_long(0))\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(network.bytes_in, to_long(0))\", tsdb)\n             );\n             assertEquals(\n-                \"1:23: second argument of [\"\n+                \"1:22: second argument of [\"\n                     + functionName\n                     + \"(network.bytes_in, 0.0)] must be [counter_long], found value [0.0] type [double]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(network.bytes_in, 0.0)\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(network.bytes_in, 0.0)\", tsdb)\n             );\n \n             assertEquals(\n-                \"1:23: third argument of [\"\n+                \"1:22: third argument of [\"\n                     + functionName\n                     + \"(null, network.bytes_in, 0)] must be [counter_long], found value [0] type [integer]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(null, network.bytes_in, 0)\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(null, network.bytes_in, 0)\", tsdb)\n             );\n \n             assertEquals(\n-                \"1:23: third argument of [\"\n+                \"1:22: third argument of [\"\n                     + functionName\n                     + \"(null, network.bytes_in, to_long(0))] must be [counter_long], \"\n                     + \"found value [to_long(0)] type [long]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(null, network.bytes_in, to_long(0))\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(null, network.bytes_in, to_long(0))\", tsdb)\n             );\n             assertEquals(\n-                \"1:23: third argument of [\"\n+                \"1:22: third argument of [\"\n                     + functionName\n                     + \"(null, network.bytes_in, 0.0)] must be [counter_long], found value [0.0] type [double]\",\n-                error(\"FROM tests | eval x = \" + functionName + \"(null, network.bytes_in, 0.0)\", tsdb)\n+                error(\"FROM test | eval x = \" + functionName + \"(null, network.bytes_in, 0.0)\", tsdb)\n             );\n         }\n \n@@ -1781,8 +1778,8 @@ public void testConditionalFunctionsWithMixedNumericTypes() {\n             error(\"from test | eval x = case(languages == 1, salary, height)\")\n         );\n         assertEquals(\n-            \"1:23: third argument of [case(name == \\\"a\\\", network.bytes_in, 0)] must be [counter_long], found value [0] type [integer]\",\n-            error(\"FROM tests | eval x = case(name == \\\"a\\\", network.bytes_in, 0)\", tsdb)\n+            \"1:22: third argument of [case(name == \\\"a\\\", network.bytes_in, 0)] must be [counter_long], found value [0] type [integer]\",\n+            error(\"FROM test | eval x = case(name == \\\"a\\\", network.bytes_in, 0)\", tsdb)\n         );\n     }\n \n@@ -1843,35 +1840,35 @@ public void testToDatePeriodTimeDurationInInvalidPosition() {\n     public void testToDatePeriodToTimeDurationWithInvalidType() {\n         assertEquals(\n             \"1:36: argument of [1.5::date_period] must be [date_period or string], found value [1.5] type [double]\",\n-            error(\"from types | EVAL x = birth_date + 1.5::date_period\")\n+            error(\"from test  | EVAL x = birth_date + 1.5::date_period\")\n         );\n         assertEquals(\n             \"1:37: argument of [to_timeduration(1)] must be [time_duration or string], found value [1] type [integer]\",\n-            error(\"from types  | EVAL x = birth_date - to_timeduration(1)\")\n+            error(\"from test   | EVAL x = birth_date - to_timeduration(1)\")\n         );\n         assertEquals(\n             \"1:45: argument of [x::date_period] must be [date_period or string], found value [x] type [double]\",\n-            error(\"from types | EVAL x = 1.5, y = birth_date + x::date_period\")\n+            error(\"from test  | EVAL x = 1.5, y = birth_date + x::date_period\")\n         );\n         assertEquals(\n             \"1:44: argument of [to_timeduration(x)] must be [time_duration or string], found value [x] type [integer]\",\n-            error(\"from types  | EVAL x = 1, y = birth_date - to_timeduration(x)\")\n+            error(\"from test   | EVAL x = 1, y = birth_date - to_timeduration(x)\")\n         );\n         assertEquals(\n             \"1:64: argument of [x::date_period] must be [date_period or string], found value [x] type [datetime]\",\n-            error(\"from types | EVAL x = \\\"2024-09-08\\\"::datetime, y = birth_date + x::date_period\")\n+            error(\"from test  | EVAL x = \\\"2024-09-08\\\"::datetime, y = birth_date + x::date_period\")\n         );\n         assertEquals(\n             \"1:65: argument of [to_timeduration(x)] must be [time_duration or string], found value [x] type [datetime]\",\n-            error(\"from types  | EVAL x = \\\"2024-09-08\\\"::datetime, y = birth_date - to_timeduration(x)\")\n+            error(\"from test   | EVAL x = \\\"2024-09-08\\\"::datetime, y = birth_date - to_timeduration(x)\")\n         );\n         assertEquals(\n             \"1:58: argument of [x::date_period] must be [date_period or string], found value [x] type [ip]\",\n-            error(\"from types | EVAL x = \\\"2024-09-08\\\"::ip, y = birth_date + x::date_period\")\n+            error(\"from test  | EVAL x = \\\"2024-09-08\\\"::ip, y = birth_date + x::date_period\")\n         );\n         assertEquals(\n             \"1:59: argument of [to_timeduration(x)] must be [time_duration or string], found value [x] type [ip]\",\n-            error(\"from types  | EVAL x = \\\"2024-09-08\\\"::ip, y = birth_date - to_timeduration(x)\")\n+            error(\"from test   | EVAL x = \\\"2024-09-08\\\"::ip, y = birth_date - to_timeduration(x)\")\n         );\n     }\n \n@@ -1879,17 +1876,17 @@ public void testIntervalAsString() {\n         // DateTrunc\n         for (String interval : List.of(\"1 minu\", \"1 dy\", \"1.5 minutes\", \"0.5 days\", \"minutes 1\", \"day 5\")) {\n             assertThat(\n-                error(\"from types  | EVAL x = date_trunc(\\\"\" + interval + \"\\\", \\\"1991-06-26T00:00:00.000Z\\\")\"),\n+                error(\"from test   | EVAL x = date_trunc(\\\"\" + interval + \"\\\", \\\"1991-06-26T00:00:00.000Z\\\")\"),\n                 containsString(\"1:35: Cannot convert string [\" + interval + \"] to [DATE_PERIOD or TIME_DURATION]\")\n             );\n             assertThat(\n-                error(\"from types  | EVAL x = \\\"1991-06-26T00:00:00.000Z\\\", y = date_trunc(\\\"\" + interval + \"\\\", x::datetime)\"),\n+                error(\"from test   | EVAL x = \\\"1991-06-26T00:00:00.000Z\\\", y = date_trunc(\\\"\" + interval + \"\\\", x::datetime)\"),\n                 containsString(\"1:67: Cannot convert string [\" + interval + \"] to [DATE_PERIOD or TIME_DURATION]\")\n             );\n         }\n         for (String interval : List.of(\"1\", \"0.5\", \"invalid\")) {\n             assertThat(\n-                error(\"from types  | EVAL x = date_trunc(\\\"\" + interval + \"\\\", \\\"1991-06-26T00:00:00.000Z\\\")\"),\n+                error(\"from test   | EVAL x = date_trunc(\\\"\" + interval + \"\\\", \\\"1991-06-26T00:00:00.000Z\\\")\"),\n                 containsString(\n                     \"1:24: first argument of [date_trunc(\\\"\"\n                         + interval\n@@ -1899,7 +1896,7 @@ public void testIntervalAsString() {\n                 )\n             );\n             assertThat(\n-                error(\"from types  | EVAL x = \\\"1991-06-26T00:00:00.000Z\\\", y = date_trunc(\\\"\" + interval + \"\\\", x::datetime)\"),\n+                error(\"from test   | EVAL x = \\\"1991-06-26T00:00:00.000Z\\\", y = date_trunc(\\\"\" + interval + \"\\\", x::datetime)\"),\n                 containsString(\n                     \"1:56: first argument of [date_trunc(\\\"\"\n                         + interval\n@@ -2191,8 +2188,8 @@ public void testFilterByAggregate() {\n         );\n         assertEquals(\"1:23: aggregate function [max(a)] not allowed outside STATS command\", error(\"ROW a = 1 | WHERE 1 + max(a) > 0\"));\n         assertEquals(\n-            \"1:24: aggregate function [min(languages)] not allowed outside STATS command\",\n-            error(\"FROM employees | WHERE min(languages) > 2\")\n+            \"1:19: aggregate function [min(languages)] not allowed outside STATS command\",\n+            error(\"FROM test | WHERE min(languages) > 2\")\n         );\n         assertEquals(\n             \"1:19: aggregate function [present(gender)] not allowed outside STATS command\",\n@@ -2848,7 +2845,7 @@ public void testLimitBeforeInlineStats_WithFork() {\n \n         assertThat(\n             error(\n-                \"FROM employees\\n\"\n+                \"FROM test\\n\"\n                     + \"| KEEP emp_no, languages, gender\\n\"\n                     + \"| FORK (WHERE emp_no == 10048 OR emp_no == 10081)\\n\"\n                     + \"       (WHERE emp_no == 10081 OR emp_no == 10087)\\n\"\n@@ -2864,7 +2861,7 @@ public void testLimitBeforeInlineStats_WithFork() {\n \n         assertThat(\n             error(\n-                \"FROM employees\\n\"\n+                \"FROM test\\n\"\n                     + \"| KEEP emp_no, languages, gender\\n\"\n                     + \"| FORK (WHERE emp_no == 10048 OR emp_no == 10081)\\n\"\n                     + \"       (WHERE emp_no == 10081 OR emp_no == 10087)\\n\"\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/expression/function/CheckLicenseTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/expression/function/CheckLicenseTests.java\nindex 733c23af12966..e70d428e16beb 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/expression/function/CheckLicenseTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/expression/function/CheckLicenseTests.java\n@@ -42,7 +42,7 @@\n public class CheckLicenseTests extends ESTestCase {\n \n     private final EsqlParser parser = new EsqlParser();\n-    private final String esql = \"from tests | eval license() | LIMIT 10\";\n+    private final String esql = \"from test | eval license() | LIMIT 10\";\n \n     public void testLicense() {\n         for (License.OperationMode functionLicense : License.OperationMode.values()) {\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLocalPhysicalPlanOptimizerTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLocalPhysicalPlanOptimizerTests.java\nindex 8c887aca9dcce..d7fc5b9a6009e 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLocalPhysicalPlanOptimizerTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLocalPhysicalPlanOptimizerTests.java\n@@ -47,6 +47,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n \n public class AbstractLocalPhysicalPlanOptimizerTests extends MapperServiceTestCase {\n     protected final Configuration config;\n@@ -101,7 +102,7 @@ public void init() {\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                timeSeriesIndex,\n+                indexResolutions(timeSeriesIndex),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -123,7 +124,7 @@ private Analyzer makeAnalyzer(String mappingFileName, EnrichResolution enrichRes\n             testAnalyzerContext(\n                 config,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()\n@@ -138,7 +139,13 @@ protected Analyzer makeAnalyzer(String mappingFileName) {\n \n     protected Analyzer makeAnalyzer(IndexResolution indexResolution) {\n         return new Analyzer(\n-            testAnalyzerContext(config, new EsqlFunctionRegistry(), indexResolution, new EnrichResolution(), emptyInferenceResolution()),\n+            testAnalyzerContext(\n+                config,\n+                new EsqlFunctionRegistry(),\n+                indexResolutions(indexResolution),\n+                new EnrichResolution(),\n+                emptyInferenceResolution()\n+            ),\n             new Verifier(new Metrics(new EsqlFunctionRegistry()), new XPackLicenseState(() -> 0L))\n         );\n     }\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLogicalPlanOptimizerTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLogicalPlanOptimizerTests.java\nindex 93e987decb9c4..498c138bb92bc 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLogicalPlanOptimizerTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/AbstractLogicalPlanOptimizerTests.java\n@@ -18,7 +18,6 @@\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.LogicalPlan;\n@@ -38,6 +37,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultInferenceResolution;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.type.DataType.KEYWORD;\n import static org.hamcrest.Matchers.containsString;\n \n@@ -105,15 +105,15 @@ public static void init() {\n             \"mapping-languages.json\"\n         );\n \n-        // Most tests used data from the test index, so we load it here, and use it in the plan() function.\n+        // Most tests use either \"test\" or \"employees\" as the index name, but for the same mapping\n         mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n+        EsIndex employees = new EsIndex(\"employees\", mapping, Map.of(\"employees\", IndexMode.STANDARD));\n         analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test, employees),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()\n@@ -121,15 +121,14 @@ public static void init() {\n             TEST_VERIFIER\n         );\n \n-        // Some tests use data from the airports index, so we load it here, and use it in the plan_airports() function.\n+        // Some tests use data from the airports index, so we load it here, and use it in the planAirports() function.\n         mappingAirports = loadMapping(\"mapping-airports.json\");\n         EsIndex airports = new EsIndex(\"airports\", mappingAirports, Map.of(\"airports\", IndexMode.STANDARD));\n-        IndexResolution getIndexResultAirports = IndexResolution.valid(airports);\n         analyzerAirports = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResultAirports,\n+                indexResolutions(airports),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()\n@@ -140,12 +139,11 @@ public static void init() {\n         // Some tests need additional types, so we load that index here and use it in the plan_types() function.\n         mappingTypes = loadMapping(\"mapping-all-types.json\");\n         EsIndex types = new EsIndex(\"types\", mappingTypes, Map.of(\"types\", IndexMode.STANDARD));\n-        IndexResolution getIndexResultTypes = IndexResolution.valid(types);\n         analyzerTypes = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResultTypes,\n+                indexResolutions(types),\n                 enrichResolution,\n                 defaultInferenceResolution()\n             ),\n@@ -155,12 +153,11 @@ public static void init() {\n         // Some tests use mappings from mapping-extra.json to be able to test more types so we load it here\n         mappingExtra = loadMapping(\"mapping-extra.json\");\n         EsIndex extra = new EsIndex(\"extra\", mappingExtra, Map.of(\"extra\", IndexMode.STANDARD));\n-        IndexResolution getIndexResultExtra = IndexResolution.valid(extra);\n         analyzerExtra = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResultExtra,\n+                indexResolutions(extra),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -168,12 +165,12 @@ public static void init() {\n         );\n \n         metricMapping = loadMapping(\"k8s-mappings.json\");\n-        var metricsIndex = IndexResolution.valid(new EsIndex(\"k8s\", metricMapping, Map.of(\"k8s\", IndexMode.TIME_SERIES)));\n+        var metricsIndex = new EsIndex(\"k8s\", metricMapping, Map.of(\"k8s\", IndexMode.TIME_SERIES));\n         metricsAnalyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                metricsIndex,\n+                indexResolutions(metricsIndex),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -185,19 +182,17 @@ public static void init() {\n             \"partial_type_keyword\",\n             new EsField(\"partial_type_keyword\", KEYWORD, emptyMap(), true, EsField.TimeSeriesFieldType.NONE)\n         );\n-        var multiIndex = IndexResolution.valid(\n-            new EsIndex(\n-                \"multi_index\",\n-                multiIndexMapping,\n-                Map.of(\"test1\", IndexMode.STANDARD, \"test2\", IndexMode.STANDARD),\n-                Set.of(\"partial_type_keyword\")\n-            )\n+        var multiIndex = new EsIndex(\n+            \"multi_index\",\n+            multiIndexMapping,\n+            Map.of(\"test1\", IndexMode.STANDARD, \"test2\", IndexMode.STANDARD),\n+            Set.of(\"partial_type_keyword\")\n         );\n         multiIndexAnalyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                multiIndex,\n+                indexResolutions(multiIndex),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -205,14 +200,12 @@ public static void init() {\n         );\n \n         var sampleDataMapping = loadMapping(\"mapping-sample_data.json\");\n-        var sampleDataIndex = IndexResolution.valid(\n-            new EsIndex(\"sample_data\", sampleDataMapping, Map.of(\"sample_data\", IndexMode.STANDARD))\n-        );\n+        var sampleDataIndex = new EsIndex(\"sample_data\", sampleDataMapping, Map.of(\"sample_data\", IndexMode.STANDARD));\n         sampleDataIndexAnalyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                sampleDataIndex,\n+                indexResolutions(sampleDataIndex),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -230,25 +223,19 @@ protected LogicalPlan plan(String query) {\n \n     protected LogicalPlan plan(String query, LogicalPlanOptimizer optimizer) {\n         var analyzed = analyzer.analyze(parser.createStatement(query));\n-        // System.out.println(analyzed);\n         var optimized = optimizer.optimize(analyzed);\n-        // System.out.println(optimized);\n         return optimized;\n     }\n \n     protected LogicalPlan planAirports(String query) {\n         var analyzed = analyzerAirports.analyze(parser.createStatement(query));\n-        // System.out.println(analyzed);\n         var optimized = logicalOptimizer.optimize(analyzed);\n-        // System.out.println(optimized);\n         return optimized;\n     }\n \n     protected LogicalPlan planExtra(String query) {\n         var analyzed = analyzerExtra.analyze(parser.createStatement(query));\n-        // System.out.println(analyzed);\n         var optimized = logicalOptimizer.optimize(analyzed);\n-        // System.out.println(optimized);\n         return optimized;\n     }\n \ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalLogicalPlanOptimizerTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalLogicalPlanOptimizerTests.java\nindex 1ef512a070d14..df7e7189dce0d 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalLogicalPlanOptimizerTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalLogicalPlanOptimizerTests.java\n@@ -45,7 +45,6 @@\n import org.elasticsearch.xpack.esql.expression.predicate.nulls.IsNotNull;\n import org.elasticsearch.xpack.esql.expression.predicate.operator.arithmetic.Add;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.OptimizerRules;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.local.InferIsNotNull;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n@@ -97,6 +96,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.unboundLogicalOptimizerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.tree.Source.EMPTY;\n import static org.elasticsearch.xpack.esql.core.type.DataType.INTEGER;\n import static org.elasticsearch.xpack.esql.core.type.DataType.KEYWORD;\n@@ -124,14 +124,13 @@ public static void init() {\n \n         mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         logicalOptimizer = new LogicalPlanOptimizer(unboundLogicalOptimizerContext());\n \n         analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),\n@@ -518,14 +517,13 @@ public void testSparseDocument() throws Exception {\n         SearchStats searchStats = statsForExistingField(\"field000\", \"field001\", \"field002\", \"field003\", \"field004\");\n \n         EsIndex index = new EsIndex(\"large\", large, Map.of(\"large\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(index);\n         var logicalOptimizer = new LogicalPlanOptimizer(unboundLogicalOptimizerContext());\n \n         var analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(index),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),\n@@ -1114,13 +1112,12 @@ private static Analyzer analyzerWithUnionTypeMapping() {\n             Map.of(\"integer_long_field\", unionTypeField),\n             Map.of(\"test1\", IndexMode.STANDARD, \"test2\", IndexMode.STANDARD)\n         );\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n \n         return new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalPhysicalPlanOptimizerTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalPhysicalPlanOptimizerTests.java\nindex d45e178b8ff32..8c6cb43b86539 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalPhysicalPlanOptimizerTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LocalPhysicalPlanOptimizerTests.java\n@@ -2278,7 +2278,7 @@ public void testToDateNanosPushDown() {\n         plannerOptimizerDateDateNanosUnionTypes = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(indexWithUnionTypedFields));\n         var stats = EsqlTestUtils.statsForExistingField(\"date_and_date_nanos\", \"date_and_date_nanos_and_long\");\n         String query = \"\"\"\n-            from test*\n+            from index*\n             | where date_and_date_nanos < \"2025-01-01\" and date_and_date_nanos_and_long::date_nanos >= \"2024-01-01\\\"\"\"\";\n         var plan = plannerOptimizerDateDateNanosUnionTypes.plan(query, stats);\n \ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LogicalPlanOptimizerTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LogicalPlanOptimizerTests.java\nindex 73492becdcb41..c9819c2730fca 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LogicalPlanOptimizerTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LogicalPlanOptimizerTests.java\n@@ -97,7 +97,6 @@\n import org.elasticsearch.xpack.esql.expression.predicate.operator.comparison.LessThan;\n import org.elasticsearch.xpack.esql.expression.predicate.operator.comparison.NotEquals;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.LiteralsOnTheRight;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.OptimizerRules;\n import org.elasticsearch.xpack.esql.optimizer.rules.logical.PruneRedundantOrderBy;\n@@ -180,6 +179,7 @@\n import static org.elasticsearch.xpack.esql.analysis.Analyzer.NO_FIELDS;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.analyze;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultAnalyzer;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.expression.Literal.NULL;\n import static org.elasticsearch.xpack.esql.core.tree.Source.EMPTY;\n import static org.elasticsearch.xpack.esql.core.type.DataType.DOUBLE;\n@@ -4298,7 +4298,7 @@ public void testIsNotNullConstraintForAliasedExpressions() {\n      */\n     public void testSpatialTypesAndStatsUseDocValues() {\n         var plan = planAirports(\"\"\"\n-            from test\n+            from airports\n             | stats centroid = st_centroid_agg(location)\n             \"\"\");\n \n@@ -4325,7 +4325,7 @@ public void testSpatialTypesAndStatsUseDocValues() {\n      */\n     public void testSpatialTypesAndStatsUseDocValuesWithEval() {\n         var plan = planAirports(\"\"\"\n-            from test\n+            from airports\n             | stats centroid = st_centroid_agg(to_geopoint(location))\n             \"\"\");\n \n@@ -4361,7 +4361,7 @@ public void testTrivialTypeConversionWrittenAway() {\n                 default -> \"to_\" + type;\n             };\n             var field = \"types.\" + type;\n-            var plan = planExtra(\"from test | eval new_\" + field + \" = \" + func + \"(\" + field + \")\");\n+            var plan = planExtra(\"from extra | eval new_\" + field + \" = \" + func + \"(\" + field + \")\");\n             var eval = as(plan, Eval.class);\n             var alias = as(eval.fields().get(0), Alias.class);\n             assertThat(func + \"(\" + field + \")\", alias.name(), equalTo(\"new_\" + field));\n@@ -5318,12 +5318,11 @@ private static boolean oneLeaveIsNull(Expression e) {\n \n     public void testEmptyMappingIndex() {\n         EsIndex empty = new EsIndex(\"empty_test\", emptyMap(), Map.of());\n-        IndexResolution getIndexResultAirports = IndexResolution.valid(empty);\n         var analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResultAirports,\n+                indexResolutions(empty),\n                 enrichResolution,\n                 emptyInferenceResolution()\n             ),\n@@ -8571,7 +8570,7 @@ public void testSampleMerged() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n         var query = \"\"\"\n-            FROM TEST\n+            FROM test\n             | SAMPLE .3\n             | EVAL irrelevant1 = 1\n             | SAMPLE .5\n@@ -8601,7 +8600,7 @@ public void testSamplePushDown() {\n             \"GROK first_name \\\"%{WORD:bar}\\\"\",\n             \"DISSECT first_name \\\"%{z}\\\"\"\n         )) {\n-            var query = \"FROM TEST | \" + command + \" | SAMPLE .5\";\n+            var query = \"FROM test | \" + command + \" | SAMPLE .5\";\n             var optimized = optimizedPlan(query);\n \n             var unary = as(optimized, UnaryPlan.class);\n@@ -8616,7 +8615,7 @@ public void testSamplePushDown() {\n     public void testSamplePushDown_sort() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n-        var query = \"FROM TEST | WHERE emp_no > 0 | SAMPLE 0.5 | LIMIT 100\";\n+        var query = \"FROM test | WHERE emp_no > 0 | SAMPLE 0.5 | LIMIT 100\";\n         var optimized = optimizedPlan(query);\n \n         var limit = as(optimized, Limit.class);\n@@ -8630,7 +8629,7 @@ public void testSamplePushDown_sort() {\n     public void testSamplePushDown_where() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n-        var query = \"FROM TEST | SORT emp_no | SAMPLE 0.5 | LIMIT 100\";\n+        var query = \"FROM test | SORT emp_no | SAMPLE 0.5 | LIMIT 100\";\n         var optimized = optimizedPlan(query);\n \n         var topN = as(optimized, TopN.class);\n@@ -8644,7 +8643,7 @@ public void testSampleNoPushDown() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n         for (var command : List.of(\"LIMIT 100\", \"MV_EXPAND languages\", \"STATS COUNT()\")) {\n-            var query = \"FROM TEST | \" + command + \" | SAMPLE .5\";\n+            var query = \"FROM test | \" + command + \" | SAMPLE .5\";\n             var optimized = optimizedPlan(query);\n \n             var limit = as(optimized, Limit.class);\n@@ -8668,7 +8667,7 @@ public void testSampleNoPushDownLookupJoin() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n         var query = \"\"\"\n-            FROM TEST\n+            FROM test\n             | EVAL language_code = emp_no\n             | LOOKUP JOIN languages_lookup ON language_code\n             | SAMPLE .5\n@@ -8696,7 +8695,7 @@ public void testSampleNoPushDownChangePoint() {\n         assumeTrue(\"sample must be enabled\", EsqlCapabilities.Cap.SAMPLE_V3.isEnabled());\n \n         var query = \"\"\"\n-            FROM TEST\n+            FROM test\n             | CHANGE_POINT emp_no ON hire_date\n             | SAMPLE .5\n             \"\"\";\n@@ -8712,7 +8711,7 @@ public void testSampleNoPushDownChangePoint() {\n \n     public void testPushDownConjunctionsToKnnPrefilter() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2]) and integer > 10\n             \"\"\";\n         var optimized = planTypes(query);\n@@ -8730,7 +8729,7 @@ public void testPushDownConjunctionsToKnnPrefilter() {\n \n     public void testPushDownMultipleFiltersToKnnPrefilter() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2])\n             | where integer > 10\n             | where keyword == \"test\"\n@@ -8751,7 +8750,7 @@ public void testPushDownMultipleFiltersToKnnPrefilter() {\n \n     public void testNotPushDownDisjunctionsToKnnPrefilter() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2]) or integer > 10\n             \"\"\";\n         var optimized = planTypes(query);\n@@ -8778,7 +8777,7 @@ public void testPushDownConjunctionsAndNotDisjunctionsToKnnPrefilter() {\n          */\n         // Both conjunctions are pushed down to knn prefilters, disjunctions are not\n         var query = \"\"\"\n-            from test\n+            from types\n             | where\n                  ((knn(dense_vector, [0, 1, 2]) or integer > 10) and keyword == \"test\") and ((short < 5) or (double > 5.0))\n             \"\"\";\n@@ -8811,7 +8810,7 @@ public void testMorePushDownConjunctionsAndNotDisjunctionsToKnnPrefilter() {\n          */\n         // Just the conjunction is pushed down to knn prefilters, disjunctions are not\n         var query = \"\"\"\n-            from test\n+            from types\n             | where\n                  ((knn(dense_vector, [0, 1, 2]) and integer > 10) or keyword == \"test\") or ((short < 5) and (double > 5.0))\n             \"\"\";\n@@ -8838,7 +8837,7 @@ public void testMultipleKnnQueriesInPrefilters() {\n                     knn(dense_vector, [4, 5, 6], 10)\n          */\n         var query = \"\"\"\n-            from test\n+            from types\n             | where ((knn(dense_vector, [0, 1, 2]) or integer > 10) and ((keyword == \"test\") or knn(dense_vector, [4, 5, 6])))\n             \"\"\";\n         var optimized = planTypes(query);\n@@ -8870,7 +8869,7 @@ public void testMultipleKnnQueriesInPrefilters() {\n \n     public void testKnnImplicitLimit() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2])\n             \"\"\";\n         var optimized = planTypes(query);\n@@ -8883,7 +8882,7 @@ public void testKnnImplicitLimit() {\n \n     public void testKnnWithLimit() {\n         var query = \"\"\"\n-            from test\n+            from types\n             | where knn(dense_vector, [0, 1, 2])\n             | limit 10\n             \"\"\";\n@@ -8897,7 +8896,7 @@ public void testKnnWithLimit() {\n \n     public void testKnnWithTopN() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | sort _score desc\n             | limit 10\n@@ -8912,7 +8911,7 @@ public void testKnnWithTopN() {\n \n     public void testKnnWithMultipleLimitsAfterTopN() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | limit 20\n             | sort _score desc\n@@ -8930,7 +8929,7 @@ public void testKnnWithMultipleLimitsAfterTopN() {\n \n     public void testKnnWithMultipleLimitsCombined() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | limit 20\n             | limit 10\n@@ -8946,7 +8945,7 @@ public void testKnnWithMultipleLimitsCombined() {\n \n     public void testKnnWithMultipleClauses() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2]) and match(keyword, \"test\")\n             | where knn(dense_vector, [1, 2, 3])\n             | sort _score\n@@ -8967,14 +8966,14 @@ public void testKnnWithMultipleClauses() {\n \n     public void testKnnWithStats() {\n         assertThat(\n-            typesError(\"from test | where knn(dense_vector, [0, 1, 2]) | stats c = count(*)\"),\n+            typesError(\"from types | where knn(dense_vector, [0, 1, 2]) | stats c = count(*)\"),\n             containsString(\"Knn function must be used with a LIMIT clause\")\n         );\n     }\n \n     public void testKnnWithRerankAmdTopN() {\n         assertThat(typesError(\"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | rerank \"some text\" on text with { \"inference_id\" : \"reranking-inference-id\" }\n             | sort _score desc\n@@ -8984,7 +8983,7 @@ public void testKnnWithRerankAmdTopN() {\n \n     public void testKnnWithRerankAmdLimit() {\n         var query = \"\"\"\n-            from test metadata _score\n+            from types metadata _score\n             | where knn(dense_vector, [0, 1, 2])\n             | rerank \"some text\" on text with { \"inference_id\" : \"reranking-inference-id\" }\n             | limit 100\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/PhysicalPlanOptimizerTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/PhysicalPlanOptimizerTests.java\nindex 40acba1df02af..250a77765a769 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/PhysicalPlanOptimizerTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/PhysicalPlanOptimizerTests.java\n@@ -189,6 +189,7 @@\n import static org.elasticsearch.xpack.esql.SerializationTestUtils.assertSerialization;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.analyze;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.expression.Expressions.name;\n import static org.elasticsearch.xpack.esql.core.expression.Expressions.names;\n import static org.elasticsearch.xpack.esql.core.expression.function.scalar.FunctionTestUtils.l;\n@@ -393,13 +394,23 @@ TestDataSource makeTestDataSource(\n         SearchStats stats\n     ) {\n         Map<String, EsField> mapping = loadMapping(mappingFileName);\n-        EsIndex index = new EsIndex(indexName, mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(index);\n+        EsIndex[] indexes = new EsIndex[1 + lookupResolution.size()];\n+        indexes[0] = new EsIndex(indexName, mapping, Map.of(indexName, IndexMode.STANDARD));\n+        for (int i = 0; i < lookupResolution.size(); i++) {\n+            indexes[i + 1] = lookupResolution.values().toArray(new IndexResolution[0])[i].get();\n+        }\n         Analyzer analyzer = new Analyzer(\n-            testAnalyzerContext(config, functionRegistry, getIndexResult, lookupResolution, enrichResolution, emptyInferenceResolution()),\n+            testAnalyzerContext(\n+                config,\n+                functionRegistry,\n+                indexResolutions(indexes),\n+                lookupResolution,\n+                enrichResolution,\n+                emptyInferenceResolution()\n+            ),\n             TEST_VERIFIER\n         );\n-        return new TestDataSource(mapping, index, analyzer, stats);\n+        return new TestDataSource(mapping, indexes[0], analyzer, stats);\n     }\n \n     TestDataSource makeTestDataSource(\n@@ -1440,7 +1451,7 @@ public void testPushMultipleBinaryLogicFilters() {\n      */\n     public void testPushMultipleFunctions() {\n         var plan = physicalPlan(\"\"\"\n-            from airports\n+            from test\n             | where starts_with(first_name, \"*Firs\") or ends_with(first_name, \"irst*\")\n             | where ends_with(last_name, \"ast\")\n             \"\"\");\n@@ -3700,7 +3711,7 @@ public void testSpatialTypesAndStatsCentroidUseDocValues() {\n             for (boolean withDocValues : new boolean[] { false, true }) {\n                 var testData = withDocValues ? airports : airportsNoDocValues;\n                 var fieldExtractPreference = withDocValues ? FieldExtractPreference.DOC_VALUES : FieldExtractPreference.NONE;\n-                var plan = physicalPlan(query, testData);\n+                var plan = physicalPlan(query.replace(\"airports\", testData.index.name()), testData);\n \n                 var limit = as(plan, LimitExec.class);\n                 var agg = as(limit.child(), AggregateExec.class);\n@@ -3763,7 +3774,7 @@ public void testSpatialTypesAndStatsExtentUseDocValues() {\n             for (boolean withDocValues : new boolean[] { false, true }) {\n                 var fieldExtractPreference = withDocValues ? FieldExtractPreference.DOC_VALUES : FieldExtractPreference.NONE;\n                 var testData = withDocValues ? airports : airportsNoDocValues;\n-                var plan = physicalPlan(query, testData);\n+                var plan = physicalPlan(query.replace(\"airports\", testData.index.name()), testData);\n \n                 var limit = as(plan, LimitExec.class);\n                 var agg = as(limit.child(), AggregateExec.class);\n@@ -3826,7 +3837,7 @@ public void testSpatialTypesAndStatsExtentAndCentroidUseDocValues() {\n             for (boolean withDocValues : new boolean[] { false, true }) {\n                 var fieldExtractPreference = withDocValues ? FieldExtractPreference.DOC_VALUES : FieldExtractPreference.NONE;\n                 var testData = withDocValues ? airports : airportsNoDocValues;\n-                var plan = physicalPlan(query, testData);\n+                var plan = physicalPlan(query.replace(\"airports\", testData.index.name()), testData);\n \n                 var limit = as(plan, LimitExec.class);\n                 var agg = as(limit.child(), AggregateExec.class);\n@@ -3875,7 +3886,7 @@ public void testSpatialTypesAndStatsExtentOfGeoShapeUsesBinaryExtraction() {\n         var query = \"FROM airports_city_boundaries | STATS extent = ST_EXTENT_AGG(city_boundary)\";\n         for (boolean useDocValues : new Boolean[] { true, false }) {\n             var testData = useDocValues ? airportsCityBoundaries : airportsCityBoundariesNoDocValues;\n-            var plan = physicalPlan(query, testData);\n+            var plan = physicalPlan(query.replace(\"airports_city_boundaries\", testData.index.name()), testData);\n \n             var limit = as(plan, LimitExec.class);\n             var agg = as(limit.child(), AggregateExec.class);\n@@ -3938,11 +3949,14 @@ public void testSpatialTypesAndStatsExtentOfShapesNegativeCases() {\n      */\n     public void testSpatialTypesAndStatsExtentOfCartesianShapesWithAndWithoutDocValues() {\n         for (boolean hasDocValues : new boolean[] { true, false }) {\n-            var query = \"\"\"\n-                FROM cartesian_multipolygons \\\n-                | STATS extent = ST_EXTENT_AGG(shape)\"\"\";\n-            var testData = hasDocValues ? cartesianMultipolygons : cartesianMultipolygonsNoDocValues;\n-            var fieldExtractPreference = hasDocValues ? FieldExtractPreference.EXTRACT_SPATIAL_BOUNDS : FieldExtractPreference.NONE;\n+            var query = \"FROM cartesian_multipolygons | STATS extent = ST_EXTENT_AGG(shape)\";\n+            var testData = cartesianMultipolygons;\n+            var fieldExtractPreference = FieldExtractPreference.EXTRACT_SPATIAL_BOUNDS;\n+            if (hasDocValues == false) {\n+                query = \"FROM cartesian_multipolygons_no_doc_values | STATS extent = ST_EXTENT_AGG(shape)\";\n+                testData = cartesianMultipolygonsNoDocValues;\n+                fieldExtractPreference = FieldExtractPreference.NONE;\n+            }\n             var plan = physicalPlan(query, testData);\n \n             var limit = as(plan, LimitExec.class);\n@@ -3990,7 +4004,7 @@ public void testSpatialTypesAndStatsExtentOfCartesianShapesWithAndWithoutDocValu\n      */\n     public void testMixedSpatialBoundsAndPointsExtracted() {\n         var query = \"\"\"\n-            FROM airports_city_boundaries \\\n+            FROM INDEX \\\n             | STATS extent = ST_EXTENT_AGG(city_boundary), centroid = ST_CENTROID_AGG(city_location)\"\"\";\n         for (boolean pointDocValues : new Boolean[] { true, false }) {\n             for (boolean shapeDocValues : new Boolean[] { true, false }) {\n@@ -3998,7 +4012,7 @@ public void testMixedSpatialBoundsAndPointsExtracted() {\n                     ? (shapeDocValues ? airportsCityBoundaries : airportsCityBoundariesNoShapeDocValues)\n                     : (shapeDocValues ? airportsCityBoundariesNoPointDocValues : airportsCityBoundariesNoDocValues);\n                 var msg = \"DocValues[point:\" + pointDocValues + \", shape:\" + shapeDocValues + \"]\";\n-                var plan = physicalPlan(query, testData);\n+                var plan = physicalPlan(query.replace(\"INDEX\", testData.index.name()), testData);\n \n                 var limit = as(plan, LimitExec.class);\n                 var agg = as(limit.child(), AggregateExec.class);\n@@ -4289,7 +4303,7 @@ public void testSpatialTypesAndStatsUseDocValuesMultiAggregationsGrouped() {\n             var plan = this.physicalPlan(\"\"\"\n                 FROM airports\n                 | STATS centroid=ST_CENTROID_AGG(location), count=COUNT() BY scalerank\n-                \"\"\", testData);\n+                \"\"\".replace(\"airports\", testData.index.name()), testData);\n \n             var limit = as(plan, LimitExec.class);\n             var agg = as(limit.child(), AggregateExec.class);\n@@ -4856,7 +4870,7 @@ public void testPushSpatialIntersectsStringToSourceAndUseDocValuesForCentroid()\n                     var testData = useDocValues\n                         ? (isIndexed ? airports : airportsNotIndexed)\n                         : (isIndexed ? airportsNoDocValues : airportsNotIndexedNorDocValues);\n-                    var plan = this.physicalPlan(query, testData);\n+                    var plan = this.physicalPlan(query.replace(\"airports\", testData.index.name()), testData);\n                     var limit = as(plan, LimitExec.class);\n                     var agg = as(limit.child(), AggregateExec.class);\n                     assertThat(\"No groupings in aggregation\", agg.groupings().size(), equalTo(0));\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/HoistRemoteEnrichTopNTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/HoistRemoteEnrichTopNTests.java\nindex 8032f3d469dc1..247fd80cf392b 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/HoistRemoteEnrichTopNTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/HoistRemoteEnrichTopNTests.java\n@@ -17,7 +17,6 @@\n import org.elasticsearch.xpack.esql.expression.Order;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.AbstractLogicalPlanOptimizerTests;\n import org.elasticsearch.xpack.esql.plan.logical.Enrich;\n import org.elasticsearch.xpack.esql.plan.logical.Eval;\n@@ -34,6 +33,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.is;\n import static org.hamcrest.Matchers.startsWith;\n@@ -127,12 +127,11 @@ private LogicalPlan planWithPolicyOverride(String query) {\n         );\n         var mapping = loadMapping(\"mapping-host_inventory.json\");\n         EsIndex inventory = new EsIndex(\"host_inventory\", mapping, Map.of(\"host_inventory\", IndexMode.STANDARD));\n-        IndexResolution resolution = IndexResolution.valid(inventory);\n         var analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                resolution,\n+                indexResolutions(inventory),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PropagateInlineEvalsTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PropagateInlineEvalsTests.java\nindex eedad20dcc42f..2f41ace68b8c3 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PropagateInlineEvalsTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PropagateInlineEvalsTests.java\n@@ -18,7 +18,6 @@\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.AbstractLogicalPlanOptimizerTests;\n import org.elasticsearch.xpack.esql.optimizer.LogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n@@ -42,6 +41,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultInferenceResolution;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.hamcrest.Matchers.contains;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.is;\n@@ -57,12 +57,11 @@ public static void init() {\n         parser = new EsqlParser();\n         mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 defaultLookupResolution(),\n                 new EnrichResolution(),\n                 defaultInferenceResolution()\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PushDownJoinPastProjectTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PushDownJoinPastProjectTests.java\nindex 260feb5e9b8b2..549ac3987c8b6 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PushDownJoinPastProjectTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/PushDownJoinPastProjectTests.java\n@@ -174,7 +174,7 @@ public void testShadowingAfterPushdown() {\n     // \\_EsRelation[test_lookup][LOOKUP][emp_no{f}#37, languages{f}#40, salary{f}#42]\n     public void testShadowingAfterPushdown2() {\n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | RENAME emp_no AS x, salary AS salary2\n             | EVAL y = x, gender = last_name\n             | RENAME y AS languages, gender AS ln\n@@ -247,7 +247,7 @@ public void testShadowingAfterPushdownExpressionJoin() {\n         );\n \n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | RENAME languages as lang2\n             | EVAL y = emp_no\n             | RENAME y AS lang\n@@ -295,7 +295,7 @@ public void testShadowingAfterPushdownExpressionJoinKeepOrig() {\n         );\n \n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | RENAME languages as lang2\n             | EVAL y = emp_no\n             | RENAME y AS lang\n@@ -347,7 +347,7 @@ public void testShadowingAfterPushdownRenameExpressionJoin() {\n         );\n \n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | RENAME languages AS lang\n             | LOOKUP JOIN test_lookup ON lang == languages\n             | KEEP languages, emp_no, salary\n@@ -393,7 +393,7 @@ public void testShadowingAfterPushdownEvalExpressionJoin() {\n         );\n \n         String query = \"\"\"\n-            FROM test_lookup\n+            FROM test\n             | EVAL lang = languages + 0\n             | DROP languages\n             | LOOKUP JOIN test_lookup ON lang == languages\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/local/IgnoreNullMetricsTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/local/IgnoreNullMetricsTests.java\nindex 6f927dae662d8..bbf18569ede0b 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/local/IgnoreNullMetricsTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/rules/logical/local/IgnoreNullMetricsTests.java\n@@ -24,7 +24,6 @@\n import org.elasticsearch.xpack.esql.expression.predicate.logical.Or;\n import org.elasticsearch.xpack.esql.expression.predicate.nulls.IsNotNull;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.LocalLogicalOptimizerContext;\n import org.elasticsearch.xpack.esql.optimizer.LocalLogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.optimizer.LogicalOptimizerContext;\n@@ -49,6 +48,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.unboundLogicalOptimizerContext;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.defaultLookupResolution;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.instanceOf;\n \n@@ -84,12 +84,11 @@ private static void init() {\n             new EsField(\"_tsid\", DataType.TSID_DATA_TYPE, Map.of(), true, EsField.TimeSeriesFieldType.NONE)\n         );\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.TIME_SERIES));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         analyzer = new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 defaultLookupResolution(),\n                 enrichResolution,\n                 emptyInferenceResolution()\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/parser/AbstractStatementParserTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/parser/AbstractStatementParserTests.java\nindex 86b594c027a4a..a14612a56fb85 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/parser/AbstractStatementParserTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/parser/AbstractStatementParserTests.java\n@@ -34,7 +34,7 @@\n import static org.elasticsearch.xpack.esql.expression.function.FunctionResolutionStrategy.DEFAULT;\n import static org.hamcrest.Matchers.containsString;\n \n-abstract class AbstractStatementParserTests extends ESTestCase {\n+public abstract class AbstractStatementParserTests extends ESTestCase {\n \n     EsqlParser parser = new EsqlParser();\n \n@@ -52,7 +52,7 @@ LogicalPlan statement(String query, String arg) {\n         return statement(LoggerMessageFormat.format(null, query, arg), new QueryParams());\n     }\n \n-    LogicalPlan statement(String e) {\n+    protected LogicalPlan statement(String e) {\n         return statement(e, new QueryParams());\n     }\n \ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/FilterTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/FilterTests.java\nindex 96507bf9615a1..9e1084ebe2d07 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/FilterTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/FilterTests.java\n@@ -28,7 +28,6 @@\n import org.elasticsearch.xpack.esql.core.util.Queries;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.io.stream.ExpressionQueryBuilder;\n import org.elasticsearch.xpack.esql.io.stream.PlanStreamInput;\n import org.elasticsearch.xpack.esql.io.stream.PlanStreamOutput;\n@@ -61,6 +60,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.unboundLogicalOptimizerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.SerializationTestUtils.assertSerialization;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.core.querydsl.query.Query.unscore;\n import static org.elasticsearch.xpack.esql.core.util.Queries.Clause.FILTER;\n import static org.elasticsearch.xpack.esql.core.util.Queries.Clause.MUST;\n@@ -86,7 +86,6 @@ public static void init() {\n \n         Map<String, EsField> mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         logicalOptimizer = new LogicalPlanOptimizer(unboundLogicalOptimizerContext());\n         TransportVersion minimumVersion = logicalOptimizer.context().minimumVersion();\n         physicalPlanOptimizer = new PhysicalPlanOptimizer(new PhysicalOptimizerContext(EsqlTestUtils.TEST_CFG, minimumVersion));\n@@ -96,7 +95,7 @@ public static void init() {\n             new AnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 Map.of(),\n                 EsqlTestUtils.emptyPolicyResolution(),\n                 emptyInferenceResolution(),\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/PlanConcurrencyCalculatorTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/PlanConcurrencyCalculatorTests.java\nindex 5212abf4270f7..027e7d8b7fc89 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/PlanConcurrencyCalculatorTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/PlanConcurrencyCalculatorTests.java\n@@ -36,32 +36,32 @@\n public class PlanConcurrencyCalculatorTests extends ESTestCase {\n     public void testSimpleLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             \"\"\", 9);\n     }\n \n     public void testLimitZero() {\n-        assertConcurrency(\"FROM x | LIMIT 0\", null);\n+        assertConcurrency(\"FROM test | LIMIT 0\", null);\n     }\n \n     public void testBiggestPragmaOverride() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             \"\"\", Integer.MAX_VALUE, Integer.MAX_VALUE);\n     }\n \n     public void testSmallestPragmaOverride() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             \"\"\", 1, 1);\n     }\n \n     public void testPragmaOverrideWithUnsupportedCommands() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | WHERE salary * 2 > 5\n             | LIMIT 512\n             \"\"\", 1, 1);\n@@ -69,20 +69,20 @@ public void testPragmaOverrideWithUnsupportedCommands() {\n \n     public void testImplicitLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             \"\"\", 9);\n     }\n \n     public void testStats() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | STATS COUNT(salary)\n             \"\"\", null);\n     }\n \n     public void testStatsWithLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             | STATS COUNT(salary)\n             \"\"\", 9);\n@@ -90,14 +90,14 @@ public void testStatsWithLimit() {\n \n     public void testSortBeforeLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | SORT salary\n             \"\"\", null);\n     }\n \n     public void testSortAfterLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             | SORT salary\n             \"\"\", 9);\n@@ -105,7 +105,7 @@ public void testSortAfterLimit() {\n \n     public void testStatsWithSortBeforeLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | SORT salary\n             | LIMIT 512\n             | STATS COUNT(salary)\n@@ -114,7 +114,7 @@ public void testStatsWithSortBeforeLimit() {\n \n     public void testStatsWithSortAfterLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | SORT salary\n             | LIMIT 512\n             | STATS COUNT(salary)\n@@ -123,7 +123,7 @@ public void testStatsWithSortAfterLimit() {\n \n     public void testWhereBeforeLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | WHERE salary * 2 > 5\n             | LIMIT 512\n             \"\"\", null);\n@@ -131,7 +131,7 @@ public void testWhereBeforeLimit() {\n \n     public void testWhereAfterLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             | WHERE salary * 2 > 5\n             \"\"\", 9);\n@@ -139,7 +139,7 @@ public void testWhereAfterLimit() {\n \n     public void testWherePushedToLuceneQueryBeforeLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | WHERE first_name LIKE \"A%\"\n             | LIMIT 512\n             \"\"\", null);\n@@ -147,7 +147,7 @@ public void testWherePushedToLuceneQueryBeforeLimit() {\n \n     public void testWherePushedToLuceneQueryAfterLimit() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 512\n             | WHERE first_name LIKE \"A%\"\n             \"\"\", 9);\n@@ -155,7 +155,7 @@ public void testWherePushedToLuceneQueryAfterLimit() {\n \n     public void testExpand() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | LIMIT 2048\n             | MV_EXPAND salary\n             | LIMIT 512\n@@ -164,7 +164,7 @@ public void testExpand() {\n \n     public void testEval() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | EVAL x=salary*2\n             | LIMIT 512\n             \"\"\", 9);\n@@ -172,7 +172,7 @@ public void testEval() {\n \n     public void testRename() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | RENAME salary as x\n             | LIMIT 512\n             \"\"\", 9);\n@@ -180,7 +180,7 @@ public void testRename() {\n \n     public void testKeep() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | KEEP salary\n             | LIMIT 512\n             \"\"\", 9);\n@@ -188,7 +188,7 @@ public void testKeep() {\n \n     public void testDrop() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | DROP salary\n             | LIMIT 512\n             \"\"\", 9);\n@@ -196,7 +196,7 @@ public void testDrop() {\n \n     public void testDissect() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | DISSECT first_name \"%{a} %{b}\"\n             | LIMIT 512\n             \"\"\", 9);\n@@ -204,7 +204,7 @@ public void testDissect() {\n \n     public void testGrok() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | GROK first_name \"%{EMAILADDRESS:email}\"\n             | LIMIT 512\n             \"\"\", 9);\n@@ -212,7 +212,7 @@ public void testGrok() {\n \n     public void testEnrich() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | ENRICH languages ON first_name\n             | LIMIT 512\n             \"\"\", 9);\n@@ -220,7 +220,7 @@ public void testEnrich() {\n \n     public void testLookup() {\n         assertConcurrency(\"\"\"\n-            FROM x\n+            FROM test\n             | RENAME salary as language_code\n             | LOOKUP JOIN languages_lookup on language_code\n             | LIMIT 512\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/QueryTranslatorTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/QueryTranslatorTests.java\nindex 4fd28e8897ee7..cca78dcc8b466 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/QueryTranslatorTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/planner/QueryTranslatorTests.java\n@@ -32,6 +32,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexWithDateDateNanosUnionType;\n import static org.hamcrest.Matchers.containsString;\n import static org.hamcrest.Matchers.matchesRegex;\n@@ -45,16 +46,15 @@ public class QueryTranslatorTests extends ESTestCase {\n \n     private static TestPlannerOptimizer plannerOptimizerDateDateNanosUnionTypes;\n \n-    private static Analyzer makeAnalyzer(String mappingFileName) {\n+    private static Analyzer makeAnalyzer(String indexName, String mappingFileName) {\n         var mapping = loadMapping(mappingFileName);\n-        EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n+        EsIndex test = new EsIndex(indexName, mapping, Map.of(indexName, IndexMode.STANDARD));\n \n         return new Analyzer(\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),\n@@ -67,7 +67,7 @@ public static Analyzer makeAnalyzer(IndexResolution indexResolution) {\n             testAnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                indexResolution,\n+                indexResolutions(indexResolution),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution()\n             ),\n@@ -77,8 +77,8 @@ public static Analyzer makeAnalyzer(IndexResolution indexResolution) {\n \n     @BeforeClass\n     public static void init() {\n-        plannerOptimizer = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(\"mapping-all-types.json\"));\n-        plannerOptimizerIPs = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(\"mapping-hosts.json\"));\n+        plannerOptimizer = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(\"test\", \"mapping-all-types.json\"));\n+        plannerOptimizerIPs = new TestPlannerOptimizer(EsqlTestUtils.TEST_CFG, makeAnalyzer(\"hosts\", \"mapping-hosts.json\"));\n     }\n \n     @Override\n@@ -331,27 +331,27 @@ public void testToDateNanos() {\n \n         // == term\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos == \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos == \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"term\":{\"date_and_date_nanos\":{\"value\":\"2025-01-01T00:00:00.000Z\",\"boost\":0.0}}}\"\"\"));\n \n         // != term\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"bool\":{\"must_not\":[{\"term\":{\"date_and_date_nanos\":{\"value\":\"2025-01-01T00:00:00.000Z\",\"boost\":0.0}}}],\\\n             \"boost\":0.0}}\"\"\"));\n \n         // > range\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos > \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos > \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"range\":{\"date_and_date_nanos\":{\"gt\":\"2025-01-01T00:00:00.000Z\",\"time_zone\":\"Z\",\\\n             \"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0}}}\"\"\"));\n \n         // >= range\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos >= \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos >= \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"range\":{\"date_and_date_nanos\":{\"gte\":\"2025-01-01T00:00:00.000Z\",\"time_zone\":\"Z\",\\\n             \"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0}}}\"\"\"));\n@@ -359,7 +359,7 @@ public void testToDateNanos() {\n         // < range\n         assertQueryTranslationDateDateNanosUnionTypes(\n             \"\"\"\n-                FROM test* | WHERE date_and_date_nanos < \"2025-01-01\" and date_and_date_nanos_and_long::date_nanos > \"2025-01-01\\\"\"\"\",\n+                FROM index* | WHERE date_and_date_nanos < \"2025-01-01\" and date_and_date_nanos_and_long::date_nanos > \"2025-01-01\\\"\"\"\",\n             stats,\n             containsString(\"\"\"\n                 \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n@@ -369,21 +369,21 @@ public void testToDateNanos() {\n \n         // <= range\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos <= \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos <= \"2025-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"range\":{\"date_and_date_nanos\":{\"lte\":\"2025-01-01T00:00:00.000Z\",\"time_zone\":\"Z\",\\\n             \"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0}}}\"\"\"));\n \n         // <= and >=\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos <= \"2025-01-01\" and date_and_date_nanos > \"2020-01-01\\\"\"\"\", stats, containsString(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos <= \"2025-01-01\" and date_and_date_nanos > \"2020-01-01\\\"\"\"\", stats, containsString(\"\"\"\n             \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\n             \"next\":{\"range\":{\"date_and_date_nanos\":{\"gt\":\"2020-01-01T00:00:00.000Z\",\"lte\":\"2025-01-01T00:00:00.000Z\",\"time_zone\":\"Z\",\\\n             \"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0}}}\"\"\"));\n \n         // >= or <\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos >= \"2025-01-01\" or date_and_date_nanos < \"2020-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos >= \"2025-01-01\" or date_and_date_nanos < \"2020-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"range\":\\\\{\"date_and_date_nanos\":\\\\{\"gte\":\"2025-01-01T00:00:00.000Z\",\\\n             \"time_zone\":\"Z\",\"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -392,7 +392,7 @@ public void testToDateNanos() {\n \n         // > or =\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos > \"2025-01-01\" or date_and_date_nanos == \"2020-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos > \"2025-01-01\" or date_and_date_nanos == \"2020-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"range\":\\\\{\"date_and_date_nanos\":\\\\{\"gt\":\"2025-01-01T00:00:00.000Z\",\\\n             \"time_zone\":\"Z\",\"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -401,7 +401,7 @@ public void testToDateNanos() {\n \n         // < or !=\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos < \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos < \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"range\":\\\\{\"date_and_date_nanos\":\\\\{\"lt\":\"2020-01-01T00:00:00.000Z\",\\\n             \"time_zone\":\"Z\",\"format\":\"strict_date_optional_time_nanos\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -410,7 +410,7 @@ public void testToDateNanos() {\n \n         // == or ==\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos == \"2020-01-01\" or date_and_date_nanos == \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos == \"2020-01-01\" or date_and_date_nanos == \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"term\":\\\\{\"date_and_date_nanos\":\\\\{\"value\":\"2020-01-01T00:00:00.000Z\",\\\n             \"boost\":0.0.*\"\"\" + \"\"\"\n@@ -419,7 +419,7 @@ public void testToDateNanos() {\n \n         // != or !=\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos != \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos != \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"must_not\".*\"term\":\\\\{\"date_and_date_nanos\":\\\\{\"value\":\\\n             \"2020-01-01T00:00:00.000Z\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -428,7 +428,7 @@ public void testToDateNanos() {\n \n         // = or !=\n         assertQueryTranslationDateDateNanosUnionTypes(\"\"\"\n-            FROM test* | WHERE date_and_date_nanos == \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n+            FROM index* | WHERE date_and_date_nanos == \"2020-01-01\" or date_and_date_nanos != \"2025-01-01\\\"\"\"\", stats, matchesRegex(\"\"\"\n             .*bool.*should.*\"\"\" + \"\"\"\n             esql_single_value\":\\\\{\"field\":\"date_and_date_nanos\".*\"term\":\\\\{\"date_and_date_nanos\":\\\\{\"value\":\\\n             \"2020-01-01T00:00:00.000Z\",\"boost\":0.0.*\"\"\" + \"\"\"\n@@ -438,7 +438,7 @@ public void testToDateNanos() {\n         // explicit casting\n         assertQueryTranslationDateDateNanosUnionTypes(\n             \"\"\"\n-                FROM test* | WHERE date_and_date_nanos::datetime < \"2025-12-31\" and date_and_date_nanos > \"2025-01-01\\\"\"\"\",\n+                FROM index* | WHERE date_and_date_nanos::datetime < \"2025-12-31\" and date_and_date_nanos > \"2025-01-01\\\"\"\"\",\n             stats,\n             containsString(\"\"\"\n                 \"esql_single_value\":{\"field\":\"date_and_date_nanos\",\\\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/ClusterRequestTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/ClusterRequestTests.java\nindex 544934f44e0b6..0371b6511fba6 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/ClusterRequestTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/ClusterRequestTests.java\n@@ -24,7 +24,6 @@\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.LogicalOptimizerContext;\n import org.elasticsearch.xpack.esql.optimizer.LogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n@@ -45,6 +44,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.unboundLogicalOptimizerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n \n public class ClusterRequestTests extends AbstractWireSerializingTestCase<ClusterComputeRequest> {\n \n@@ -171,7 +171,6 @@ private static String randomQuery() {\n     static Versioned<LogicalPlan> parse(String query) {\n         Map<String, EsField> mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         LogicalOptimizerContext context = unboundLogicalOptimizerContext();\n         TransportVersion minimumVersion = context.minimumVersion();\n         var logicalOptimizer = new LogicalPlanOptimizer(context);\n@@ -179,7 +178,7 @@ static Versioned<LogicalPlan> parse(String query) {\n             new AnalyzerContext(\n                 EsqlTestUtils.TEST_CFG,\n                 new EsqlFunctionRegistry(),\n-                getIndexResult,\n+                indexResolutions(test),\n                 Map.of(),\n                 emptyPolicyResolution(),\n                 emptyInferenceResolution(),\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/DataNodeRequestSerializationTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/DataNodeRequestSerializationTests.java\nindex dd4a0538988c6..4b6ede9da2ae2 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/DataNodeRequestSerializationTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/plugin/DataNodeRequestSerializationTests.java\n@@ -25,7 +25,6 @@\n import org.elasticsearch.xpack.esql.core.type.EsField;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.index.EsIndex;\n-import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.optimizer.LogicalOptimizerContext;\n import org.elasticsearch.xpack.esql.optimizer.LogicalPlanOptimizer;\n import org.elasticsearch.xpack.esql.optimizer.PhysicalOptimizerContext;\n@@ -50,6 +49,7 @@\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.testAnalyzerContext;\n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n \n public class DataNodeRequestSerializationTests extends AbstractWireSerializingTestCase<DataNodeRequest> {\n     @Override\n@@ -302,9 +302,14 @@ protected DataNodeRequest mutateInstance(DataNodeRequest in) throws IOException\n     static Versioned<LogicalPlan> parse(String query) {\n         Map<String, EsField> mapping = loadMapping(\"mapping-basic.json\");\n         EsIndex test = new EsIndex(\"test\", mapping, Map.of(\"test\", IndexMode.STANDARD));\n-        IndexResolution getIndexResult = IndexResolution.valid(test);\n         var analyzer = new Analyzer(\n-            testAnalyzerContext(TEST_CFG, new EsqlFunctionRegistry(), getIndexResult, emptyPolicyResolution(), emptyInferenceResolution()),\n+            testAnalyzerContext(\n+                TEST_CFG,\n+                new EsqlFunctionRegistry(),\n+                indexResolutions(test),\n+                emptyPolicyResolution(),\n+                emptyInferenceResolution()\n+            ),\n             TEST_VERIFIER\n         );\n         TransportVersion minimumVersion = analyzer.context().minimumVersion();\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtilsTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtilsTests.java\nindex 3a2eaa544c6ab..4504e2fdec96b 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtilsTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/session/EsqlCCSUtilsTests.java\n@@ -224,7 +224,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n \n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), Map.of());\n \n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -267,7 +267,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n             );\n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), Map.of());\n \n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -309,7 +309,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n             var failures = Map.of(REMOTE1_ALIAS, List.of(failure));\n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), failures);\n \n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -350,7 +350,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n             var failure = new FieldCapabilitiesFailure(new String[] { \"logs-a\" }, new NoSeedNodeLeftException(\"unable to connect\"));\n             var failures = Map.of(REMOTE1_ALIAS, List.of(failure));\n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), failures);\n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -399,7 +399,7 @@ public void testUpdateExecutionInfoWithClustersWithNoMatchingIndices() {\n             var failures = Map.of(REMOTE1_ALIAS, List.of(failure));\n             IndexResolution indexResolution = IndexResolution.valid(esIndex, esIndex.concreteIndices(), failures);\n \n-            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, indexResolution);\n+            EsqlCCSUtils.updateExecutionInfoWithClustersWithNoMatchingIndices(executionInfo, Set.of(indexResolution));\n \n             EsqlExecutionInfo.Cluster localCluster = executionInfo.getCluster(LOCAL_CLUSTER_ALIAS);\n             assertThat(localCluster.getIndexExpression(), equalTo(\"logs*\"));\n@@ -713,7 +713,7 @@ private void assertLicenseCheckPasses(\n         String... expectedRemotes\n     ) {\n         var executionInfo = new EsqlExecutionInfo(true);\n-        initCrossClusterState(indicesGrouper, createLicenseState(status), pattern, executionInfo);\n+        initCrossClusterState(indicesGrouper, createLicenseState(status), Set.of(pattern), executionInfo);\n         assertThat(executionInfo.clusterAliases(), containsInAnyOrder(expectedRemotes));\n     }\n \n@@ -728,7 +728,7 @@ private void assertLicenseCheckFails(\n             equalTo(\n                 \"A valid Enterprise license is required to run ES|QL cross-cluster searches. License found: \" + expectedErrorMessageSuffix\n             ),\n-            () -> initCrossClusterState(indicesGrouper, createLicenseState(licenseStatus), pattern, new EsqlExecutionInfo(true))\n+            () -> initCrossClusterState(indicesGrouper, createLicenseState(licenseStatus), Set.of(pattern), new EsqlExecutionInfo(true))\n         );\n         assertThat(e.status(), equalTo(RestStatus.BAD_REQUEST));\n     }\ndiff --git a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/telemetry/VerifierMetricsTests.java b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/telemetry/VerifierMetricsTests.java\nindex 7013cc6bc9ea0..94a1db9bcb676 100644\n--- a/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/telemetry/VerifierMetricsTests.java\n+++ b/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/telemetry/VerifierMetricsTests.java\n@@ -7,6 +7,7 @@\n \n package org.elasticsearch.xpack.esql.telemetry;\n \n+import org.elasticsearch.index.IndexMode;\n import org.elasticsearch.license.XPackLicenseState;\n import org.elasticsearch.test.ESTestCase;\n import org.elasticsearch.xpack.core.watcher.common.stats.Counters;\n@@ -14,6 +15,7 @@\n import org.elasticsearch.xpack.esql.analysis.Verifier;\n import org.elasticsearch.xpack.esql.expression.function.EsqlFunctionRegistry;\n import org.elasticsearch.xpack.esql.expression.function.FunctionDefinition;\n+import org.elasticsearch.xpack.esql.index.IndexResolution;\n import org.elasticsearch.xpack.esql.parser.EsqlParser;\n \n import java.util.HashMap;\n@@ -23,6 +25,8 @@\n \n import static org.elasticsearch.xpack.esql.EsqlTestUtils.withDefaultLimitWarning;\n import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.analyzer;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.indexResolutions;\n+import static org.elasticsearch.xpack.esql.analysis.AnalyzerTestUtils.loadMapping;\n import static org.elasticsearch.xpack.esql.telemetry.FeatureMetric.DISSECT;\n import static org.elasticsearch.xpack.esql.telemetry.FeatureMetric.DROP;\n import static org.elasticsearch.xpack.esql.telemetry.FeatureMetric.ENRICH;\n@@ -833,7 +837,9 @@ private Counters esql(String esql, Verifier v) {\n             metrics = new Metrics(new EsqlFunctionRegistry());\n             verifier = new Verifier(metrics, new XPackLicenseState(() -> 0L));\n         }\n-        analyzer(verifier).analyze(parser.createStatement(esql));\n+        IndexResolution metricsIndex = loadMapping(\"mapping-basic.json\", \"metrics\", IndexMode.TIME_SERIES);\n+        IndexResolution employees = loadMapping(\"mapping-basic.json\", \"employees\");\n+        analyzer(indexResolutions(metricsIndex, employees), verifier).analyze(parser.createStatement(esql));\n \n         return metrics == null ? null : metrics.stats();\n     }\n",
  "additions": 758,
  "deletions": 474,
  "changed_files": 35,
  "url": "https://github.com/elastic/elasticsearch/pull/136780",
  "mined_at": "2025-10-25T13:24:45.970468"
}