{
  "id": 137063,
  "repository": "elastic/elasticsearch",
  "title": "ESQL: Move doc values `BlockLoader` impls",
  "body": "We have a bunch of these as inner classes. Some of them are inner classes of the field types they support - which is fine and good. But a bunch of the shared ones were inner classes of `BlockDocValuesReader` which made the class like a billion lines long. And it made it harder to find the source code of the shared ones because they weren't in alphabetical order.\r\n\r\nThis moves these block loaders to top level classes. And lets our IDE put them in alphabetical order for us. Which is nice because we'll be adding a bunch more of them as we move further on #137002.\r\n",
  "state": "closed",
  "merged": true,
  "merged_at": "2025-10-23T22:43:30+00:00",
  "created_at": "2025-10-23T19:48:15+00:00",
  "updated_at": "2025-10-23T22:43:30+00:00",
  "author": "nik9000",
  "reviewers": [
    "dnhatn"
  ],
  "base_sha": "ea36c8a846cf83771377bd124ce214c1e423a724",
  "head_sha": "1a84d211af91bb2bc431244286205cc6ce6c7d4f",
  "review_comments": [
    {
      "user": "dnhatn",
      "state": "APPROVED",
      "body": "",
      "submitted_at": "2025-10-23T21:11:31+00:00"
    }
  ],
  "pr_comments": [
    {
      "user": "elasticsearchmachine",
      "body": "Pinging @elastic/es-analytical-engine (Team:Analytics)",
      "created_at": "2025-10-23T19:48:40+00:00"
    },
    {
      "user": "nik9000",
      "body": "Thanks @dnhatn !",
      "created_at": "2025-10-23T22:43:23+00:00"
    }
  ],
  "files_changed": [
    {
      "filename": "modules/mapper-extras/src/main/java/org/elasticsearch/index/mapper/extras/ScaledFloatFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "patch": "@@ -31,7 +31,6 @@\n import org.elasticsearch.index.fielddata.SourceValueFetcherSortedDoubleIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.LeafDoubleFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.BlockSourceReader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n@@ -51,6 +50,7 @@\n import org.elasticsearch.index.mapper.TextSearchInfo;\n import org.elasticsearch.index.mapper.TimeSeriesParams;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DoublesBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.field.DocValuesScriptFieldFactory;\n import org.elasticsearch.script.field.ScaledFloatDocValuesField;\n@@ -382,7 +382,7 @@ public BlockLoader blockLoader(BlockLoaderContext blContext) {\n                 return BlockLoader.CONSTANT_NULLS;\n             }\n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSource)) {\n-                return new BlockDocValuesReader.DoublesBlockLoader(name(), l -> l / scalingFactor);\n+                return new DoublesBlockLoader(name(), l -> l / scalingFactor);\n             }\n             // Multi fields don't have fallback synthetic source.\n             if (isSyntheticSource && blContext.parentField(name()) == null) {"
    },
    {
      "filename": "server/src/main/java/module-info.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -499,4 +499,5 @@\n     exports org.elasticsearch.index.codec.vectors.cluster to org.elasticsearch.test.knn;\n     exports org.elasticsearch.index.codec.vectors.es93 to org.elasticsearch.test.knn;\n     exports org.elasticsearch.search.crossproject;\n+    exports org.elasticsearch.index.mapper.blockloader.docvalues;\n }"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/codec/tsdb/es819/ES819TSDBDocValuesProducer.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "patch": "@@ -46,8 +46,8 @@\n import org.elasticsearch.core.Assertions;\n import org.elasticsearch.core.IOUtils;\n import org.elasticsearch.index.codec.tsdb.TSDBDocValuesEncoder;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n \n import java.io.IOException;\n "
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/AbstractShapeGeometryFieldMapper.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -12,6 +12,7 @@\n import org.apache.lucene.index.LeafReaderContext;\n import org.elasticsearch.common.Explicit;\n import org.elasticsearch.common.geo.Orientation;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.lucene.spatial.Extent;\n import org.elasticsearch.lucene.spatial.GeometryDocValueReader;\n "
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/BlockDocValuesReader.java",
      "status": "removed",
      "additions": 0,
      "deletions": 1302,
      "changes": 1302,
      "patch": "@@ -1,1302 +0,0 @@\n-/*\n- * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n- * or more contributor license agreements. Licensed under the \"Elastic License\n- * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n- * Public License v 1\"; you may not use this file except in compliance with, at\n- * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n- * License v3.0 only\", or the \"Server Side Public License, v 1\".\n- */\n-\n-package org.elasticsearch.index.mapper;\n-\n-import org.apache.lucene.index.BinaryDocValues;\n-import org.apache.lucene.index.ByteVectorValues;\n-import org.apache.lucene.index.DocValues;\n-import org.apache.lucene.index.FloatVectorValues;\n-import org.apache.lucene.index.KnnVectorValues;\n-import org.apache.lucene.index.LeafReaderContext;\n-import org.apache.lucene.index.NumericDocValues;\n-import org.apache.lucene.index.SortedDocValues;\n-import org.apache.lucene.index.SortedNumericDocValues;\n-import org.apache.lucene.index.SortedSetDocValues;\n-import org.apache.lucene.util.BytesRef;\n-import org.elasticsearch.common.io.stream.ByteArrayStreamInput;\n-import org.elasticsearch.index.IndexVersion;\n-import org.elasticsearch.index.mapper.BlockLoader.BlockFactory;\n-import org.elasticsearch.index.mapper.BlockLoader.BooleanBuilder;\n-import org.elasticsearch.index.mapper.BlockLoader.Builder;\n-import org.elasticsearch.index.mapper.BlockLoader.BytesRefBuilder;\n-import org.elasticsearch.index.mapper.BlockLoader.Docs;\n-import org.elasticsearch.index.mapper.BlockLoader.DoubleBuilder;\n-import org.elasticsearch.index.mapper.BlockLoader.IntBuilder;\n-import org.elasticsearch.index.mapper.BlockLoader.LongBuilder;\n-import org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper;\n-import org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper.ElementType;\n-import org.elasticsearch.index.mapper.vectors.VectorEncoderDecoder;\n-import org.elasticsearch.search.fetch.StoredFieldsSpec;\n-\n-import java.io.IOException;\n-\n-import static org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper.COSINE_MAGNITUDE_FIELD_SUFFIX;\n-\n-/**\n- * A reader that supports reading doc-values from a Lucene segment in Block fashion.\n- */\n-public abstract class BlockDocValuesReader implements BlockLoader.AllReader {\n-    private final Thread creationThread;\n-\n-    public BlockDocValuesReader() {\n-        this.creationThread = Thread.currentThread();\n-    }\n-\n-    protected abstract int docId();\n-\n-    /**\n-     * Checks if the reader can be used to read a range documents starting with the given docID by the current thread.\n-     */\n-    @Override\n-    public final boolean canReuse(int startingDocID) {\n-        return creationThread == Thread.currentThread() && docId() <= startingDocID;\n-    }\n-\n-    @Override\n-    public abstract String toString();\n-\n-    public abstract static class DocValuesBlockLoader implements BlockLoader {\n-        public abstract AllReader reader(LeafReaderContext context) throws IOException;\n-\n-        @Override\n-        public final ColumnAtATimeReader columnAtATimeReader(LeafReaderContext context) throws IOException {\n-            return reader(context);\n-        }\n-\n-        @Override\n-        public final RowStrideReader rowStrideReader(LeafReaderContext context) throws IOException {\n-            return reader(context);\n-        }\n-\n-        @Override\n-        public final StoredFieldsSpec rowStrideStoredFieldSpec() {\n-            return StoredFieldsSpec.NO_REQUIREMENTS;\n-        }\n-\n-        @Override\n-        public boolean supportsOrdinals() {\n-            return false;\n-        }\n-\n-        @Override\n-        public SortedSetDocValues ordinals(LeafReaderContext context) throws IOException {\n-            throw new UnsupportedOperationException();\n-        }\n-\n-    }\n-\n-    public static class LongsBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public LongsBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.longs(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n-            if (docValues != null) {\n-                NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonLongs(singleton);\n-                }\n-                return new Longs(docValues);\n-            }\n-            NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonLongs(singleton);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    // Used for testing.\n-    interface NumericDocValuesAccessor {\n-        NumericDocValues numericDocValues();\n-    }\n-\n-    static class SingletonLongs extends BlockDocValuesReader implements NumericDocValuesAccessor {\n-        final NumericDocValues numericDocValues;\n-\n-        SingletonLongs(NumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (numericDocValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n-                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, null, false);\n-                if (result != null) {\n-                    return result;\n-                }\n-            }\n-            try (BlockLoader.LongBuilder builder = factory.longsFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (numericDocValues.advanceExact(doc)) {\n-                        builder.appendLong(numericDocValues.longValue());\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            BlockLoader.LongBuilder blockBuilder = (BlockLoader.LongBuilder) builder;\n-            if (numericDocValues.advanceExact(docId)) {\n-                blockBuilder.appendLong(numericDocValues.longValue());\n-            } else {\n-                blockBuilder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonLongs\";\n-        }\n-\n-        @Override\n-        public NumericDocValues numericDocValues() {\n-            return numericDocValues;\n-        }\n-    }\n-\n-    static class Longs extends BlockDocValuesReader {\n-        private final SortedNumericDocValues numericDocValues;\n-\n-        Longs(SortedNumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.LongBuilder builder = factory.longsFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (LongBuilder) builder);\n-        }\n-\n-        private void read(int doc, LongBuilder builder) throws IOException {\n-            if (false == numericDocValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = numericDocValues.docValueCount();\n-            if (count == 1) {\n-                builder.appendLong(numericDocValues.nextValue());\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendLong(numericDocValues.nextValue());\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Longs\";\n-        }\n-    }\n-\n-    public static class IntsBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public IntsBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.ints(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n-            if (docValues != null) {\n-                NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonInts(singleton);\n-                }\n-                return new Ints(docValues);\n-            }\n-            NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonInts(singleton);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    static class SingletonInts extends BlockDocValuesReader implements NumericDocValuesAccessor {\n-        private final NumericDocValues numericDocValues;\n-\n-        SingletonInts(NumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (numericDocValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n-                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, null, true);\n-                if (result != null) {\n-                    return result;\n-                }\n-            }\n-            try (BlockLoader.IntBuilder builder = factory.intsFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (numericDocValues.advanceExact(doc)) {\n-                        builder.appendInt(Math.toIntExact(numericDocValues.longValue()));\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            IntBuilder blockBuilder = (IntBuilder) builder;\n-            if (numericDocValues.advanceExact(docId)) {\n-                blockBuilder.appendInt(Math.toIntExact(numericDocValues.longValue()));\n-            } else {\n-                blockBuilder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonInts\";\n-        }\n-\n-        @Override\n-        public NumericDocValues numericDocValues() {\n-            return numericDocValues;\n-        }\n-    }\n-\n-    static class Ints extends BlockDocValuesReader {\n-        private final SortedNumericDocValues numericDocValues;\n-\n-        Ints(SortedNumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.IntBuilder builder = factory.intsFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (IntBuilder) builder);\n-        }\n-\n-        private void read(int doc, IntBuilder builder) throws IOException {\n-            if (false == numericDocValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = numericDocValues.docValueCount();\n-            if (count == 1) {\n-                builder.appendInt(Math.toIntExact(numericDocValues.nextValue()));\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendInt(Math.toIntExact(numericDocValues.nextValue()));\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Ints\";\n-        }\n-    }\n-\n-    /**\n-     * Convert from the stored {@link long} into the {@link double} to load.\n-     * Sadly, this will go megamorphic pretty quickly and slow us down,\n-     * but it gets the job done for now.\n-     */\n-    public interface ToDouble {\n-        double convert(long v);\n-    }\n-\n-    public static class DoublesBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-        private final ToDouble toDouble;\n-\n-        public DoublesBlockLoader(String fieldName, ToDouble toDouble) {\n-            this.fieldName = fieldName;\n-            this.toDouble = toDouble;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.doubles(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n-            if (docValues != null) {\n-                NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonDoubles(singleton, toDouble);\n-                }\n-                return new Doubles(docValues, toDouble);\n-            }\n-            NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonDoubles(singleton, toDouble);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    static class SingletonDoubles extends BlockDocValuesReader implements NumericDocValuesAccessor {\n-        private final NumericDocValues docValues;\n-        private final ToDouble toDouble;\n-\n-        SingletonDoubles(NumericDocValues docValues, ToDouble toDouble) {\n-            this.docValues = docValues;\n-            this.toDouble = toDouble;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (docValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n-                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, toDouble, false);\n-                if (result != null) {\n-                    return result;\n-                }\n-            }\n-            try (BlockLoader.DoubleBuilder builder = factory.doublesFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (docValues.advanceExact(doc)) {\n-                        builder.appendDouble(toDouble.convert(docValues.longValue()));\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            DoubleBuilder blockBuilder = (DoubleBuilder) builder;\n-            if (docValues.advanceExact(docId)) {\n-                blockBuilder.appendDouble(toDouble.convert(docValues.longValue()));\n-            } else {\n-                blockBuilder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return docValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonDoubles\";\n-        }\n-\n-        @Override\n-        public NumericDocValues numericDocValues() {\n-            return docValues;\n-        }\n-    }\n-\n-    static class Doubles extends BlockDocValuesReader {\n-        private final SortedNumericDocValues docValues;\n-        private final ToDouble toDouble;\n-\n-        Doubles(SortedNumericDocValues docValues, ToDouble toDouble) {\n-            this.docValues = docValues;\n-            this.toDouble = toDouble;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.DoubleBuilder builder = factory.doublesFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (DoubleBuilder) builder);\n-        }\n-\n-        private void read(int doc, DoubleBuilder builder) throws IOException {\n-            if (false == docValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = docValues.docValueCount();\n-            if (count == 1) {\n-                builder.appendDouble(toDouble.convert(docValues.nextValue()));\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendDouble(toDouble.convert(docValues.nextValue()));\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return docValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Doubles\";\n-        }\n-    }\n-\n-    public static class DenseVectorBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-        private final int dimensions;\n-        private final DenseVectorFieldMapper.DenseVectorFieldType fieldType;\n-\n-        public DenseVectorBlockLoader(String fieldName, int dimensions, DenseVectorFieldMapper.DenseVectorFieldType fieldType) {\n-            this.fieldName = fieldName;\n-            this.dimensions = dimensions;\n-            this.fieldType = fieldType;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.denseVectors(expectedCount, dimensions);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            switch (fieldType.getElementType()) {\n-                case FLOAT -> {\n-                    FloatVectorValues floatVectorValues = context.reader().getFloatVectorValues(fieldName);\n-                    if (floatVectorValues != null) {\n-                        if (fieldType.isNormalized()) {\n-                            NumericDocValues magnitudeDocValues = context.reader()\n-                                .getNumericDocValues(fieldType.name() + COSINE_MAGNITUDE_FIELD_SUFFIX);\n-                            return new FloatDenseVectorNormalizedValuesBlockReader(floatVectorValues, dimensions, magnitudeDocValues);\n-                        }\n-                        return new FloatDenseVectorValuesBlockReader(floatVectorValues, dimensions);\n-                    }\n-                }\n-                case BYTE -> {\n-                    ByteVectorValues byteVectorValues = context.reader().getByteVectorValues(fieldName);\n-                    if (byteVectorValues != null) {\n-                        return new ByteDenseVectorValuesBlockReader(byteVectorValues, dimensions);\n-                    }\n-                }\n-                case BIT -> {\n-                    ByteVectorValues byteVectorValues = context.reader().getByteVectorValues(fieldName);\n-                    if (byteVectorValues != null) {\n-                        return new BitDenseVectorValuesBlockReader(byteVectorValues, dimensions);\n-                    }\n-                }\n-            }\n-\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    private abstract static class DenseVectorValuesBlockReader<T extends KnnVectorValues> extends BlockDocValuesReader {\n-\n-        protected final T vectorValues;\n-        protected final KnnVectorValues.DocIndexIterator iterator;\n-        protected final int dimensions;\n-\n-        DenseVectorValuesBlockReader(T vectorValues, int dimensions) {\n-            this.vectorValues = vectorValues;\n-            iterator = vectorValues.iterator();\n-            this.dimensions = dimensions;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            // Doubles from doc values ensures that the values are in order\n-            try (BlockLoader.FloatBuilder builder = factory.denseVectors(docs.count() - offset, dimensions)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    read(docs.get(i), builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BlockLoader.FloatBuilder) builder);\n-        }\n-\n-        private void read(int doc, BlockLoader.FloatBuilder builder) throws IOException {\n-            assertDimensions();\n-\n-            if (iterator.docID() > doc) {\n-                builder.appendNull();\n-            } else if (iterator.docID() == doc || iterator.advance(doc) == doc) {\n-                builder.beginPositionEntry();\n-                appendDoc(builder);\n-                builder.endPositionEntry();\n-            } else {\n-                builder.appendNull();\n-            }\n-        }\n-\n-        protected abstract void appendDoc(BlockLoader.FloatBuilder builder) throws IOException;\n-\n-        @Override\n-        public int docId() {\n-            return iterator.docID();\n-        }\n-\n-        protected void assertDimensions() {\n-            assert vectorValues.dimension() == dimensions\n-                : \"unexpected dimensions for vector value; expected \" + dimensions + \" but got \" + vectorValues.dimension();\n-        }\n-    }\n-\n-    private static class FloatDenseVectorValuesBlockReader extends DenseVectorValuesBlockReader<FloatVectorValues> {\n-\n-        FloatDenseVectorValuesBlockReader(FloatVectorValues floatVectorValues, int dimensions) {\n-            super(floatVectorValues, dimensions);\n-        }\n-\n-        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n-            float[] floats = vectorValues.vectorValue(iterator.index());\n-            for (float aFloat : floats) {\n-                builder.appendFloat(aFloat);\n-            }\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.FloatDenseVectorValuesBlockReader\";\n-        }\n-    }\n-\n-    private static class FloatDenseVectorNormalizedValuesBlockReader extends DenseVectorValuesBlockReader<FloatVectorValues> {\n-        private final NumericDocValues magnitudeDocValues;\n-\n-        FloatDenseVectorNormalizedValuesBlockReader(\n-            FloatVectorValues floatVectorValues,\n-            int dimensions,\n-            NumericDocValues magnitudeDocValues\n-        ) {\n-            super(floatVectorValues, dimensions);\n-            this.magnitudeDocValues = magnitudeDocValues;\n-        }\n-\n-        @Override\n-        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n-            float magnitude = 1.0f;\n-            // If all vectors are normalized, no doc values will be present. The vector may be normalized already, so we may not have a\n-            // stored magnitude for all docs\n-            if ((magnitudeDocValues != null) && magnitudeDocValues.advanceExact(iterator.docID())) {\n-                magnitude = Float.intBitsToFloat((int) magnitudeDocValues.longValue());\n-            }\n-            float[] floats = vectorValues.vectorValue(iterator.index());\n-            for (float aFloat : floats) {\n-                builder.appendFloat(aFloat * magnitude);\n-            }\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.FloatDenseVectorNormalizedValuesBlockReader\";\n-        }\n-    }\n-\n-    private static class ByteDenseVectorValuesBlockReader extends DenseVectorValuesBlockReader<ByteVectorValues> {\n-        ByteDenseVectorValuesBlockReader(ByteVectorValues floatVectorValues, int dimensions) {\n-            super(floatVectorValues, dimensions);\n-        }\n-\n-        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n-            byte[] bytes = vectorValues.vectorValue(iterator.index());\n-            for (byte aFloat : bytes) {\n-                builder.appendFloat(aFloat);\n-            }\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.ByteDenseVectorValuesBlockReader\";\n-        }\n-    }\n-\n-    private static class BitDenseVectorValuesBlockReader extends ByteDenseVectorValuesBlockReader {\n-\n-        BitDenseVectorValuesBlockReader(ByteVectorValues floatVectorValues, int dimensions) {\n-            super(floatVectorValues, dimensions);\n-        }\n-\n-        @Override\n-        protected void assertDimensions() {\n-            assert vectorValues.dimension() * Byte.SIZE == dimensions\n-                : \"unexpected dimensions for vector value; expected \" + dimensions + \" but got \" + vectorValues.dimension() * Byte.SIZE;\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.BitDenseVectorValuesBlockReader\";\n-        }\n-    }\n-\n-    public static class BytesRefsFromOrdsBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public BytesRefsFromOrdsBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public BytesRefBuilder builder(BlockFactory factory, int expectedCount) {\n-            return factory.bytesRefs(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedSetDocValues docValues = context.reader().getSortedSetDocValues(fieldName);\n-            if (docValues != null) {\n-                SortedDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonOrdinals(singleton);\n-                }\n-                return new Ordinals(docValues);\n-            }\n-            SortedDocValues singleton = context.reader().getSortedDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonOrdinals(singleton);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-\n-        @Override\n-        public boolean supportsOrdinals() {\n-            return true;\n-        }\n-\n-        @Override\n-        public SortedSetDocValues ordinals(LeafReaderContext context) throws IOException {\n-            return DocValues.getSortedSet(context.reader(), fieldName);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BytesRefsFromOrds[\" + fieldName + \"]\";\n-        }\n-    }\n-\n-    private static class SingletonOrdinals extends BlockDocValuesReader {\n-        private final SortedDocValues ordinals;\n-\n-        SingletonOrdinals(SortedDocValues ordinals) {\n-            this.ordinals = ordinals;\n-        }\n-\n-        private BlockLoader.Block readSingleDoc(BlockFactory factory, int docId) throws IOException {\n-            if (ordinals.advanceExact(docId)) {\n-                BytesRef v = ordinals.lookupOrd(ordinals.ordValue());\n-                // the returned BytesRef can be reused\n-                return factory.constantBytes(BytesRef.deepCopyOf(v), 1);\n-            } else {\n-                return factory.constantNulls(1);\n-            }\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (docs.count() - offset == 1) {\n-                return readSingleDoc(factory, docs.get(offset));\n-            }\n-            if (ordinals instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n-                BlockLoader.Block block = direct.tryRead(factory, docs, offset, nullsFiltered, null, false);\n-                if (block != null) {\n-                    return block;\n-                }\n-            }\n-            try (var builder = factory.singletonOrdinalsBuilder(ordinals, docs.count() - offset, false)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (ordinals.advanceExact(doc)) {\n-                        builder.appendOrd(ordinals.ordValue());\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            if (ordinals.advanceExact(docId)) {\n-                ((BytesRefBuilder) builder).appendBytesRef(ordinals.lookupOrd(ordinals.ordValue()));\n-            } else {\n-                builder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return ordinals.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonOrdinals\";\n-        }\n-    }\n-\n-    private static class Ordinals extends BlockDocValuesReader {\n-        private final SortedSetDocValues ordinals;\n-\n-        Ordinals(SortedSetDocValues ordinals) {\n-            this.ordinals = ordinals;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (docs.count() - offset == 1) {\n-                return readSingleDoc(factory, docs.get(offset));\n-            }\n-            try (var builder = factory.sortedSetOrdinalsBuilder(ordinals, docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (doc < ordinals.docID()) {\n-                        throw new IllegalStateException(\"docs within same block must be in order\");\n-                    }\n-                    if (ordinals.advanceExact(doc) == false) {\n-                        builder.appendNull();\n-                        continue;\n-                    }\n-                    int count = ordinals.docValueCount();\n-                    if (count == 1) {\n-                        builder.appendOrd(Math.toIntExact(ordinals.nextOrd()));\n-                    } else {\n-                        builder.beginPositionEntry();\n-                        for (int c = 0; c < count; c++) {\n-                            builder.appendOrd(Math.toIntExact(ordinals.nextOrd()));\n-                        }\n-                        builder.endPositionEntry();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BytesRefBuilder) builder);\n-        }\n-\n-        private BlockLoader.Block readSingleDoc(BlockFactory factory, int docId) throws IOException {\n-            if (ordinals.advanceExact(docId) == false) {\n-                return factory.constantNulls(1);\n-            }\n-            int count = ordinals.docValueCount();\n-            if (count == 1) {\n-                BytesRef v = ordinals.lookupOrd(ordinals.nextOrd());\n-                return factory.constantBytes(BytesRef.deepCopyOf(v), 1);\n-            }\n-            try (var builder = factory.bytesRefsFromDocValues(count)) {\n-                builder.beginPositionEntry();\n-                for (int c = 0; c < count; c++) {\n-                    BytesRef v = ordinals.lookupOrd(ordinals.nextOrd());\n-                    builder.appendBytesRef(v);\n-                }\n-                builder.endPositionEntry();\n-                return builder.build();\n-            }\n-        }\n-\n-        private void read(int docId, BytesRefBuilder builder) throws IOException {\n-            if (false == ordinals.advanceExact(docId)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = ordinals.docValueCount();\n-            if (count == 1) {\n-                builder.appendBytesRef(ordinals.lookupOrd(ordinals.nextOrd()));\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendBytesRef(ordinals.lookupOrd(ordinals.nextOrd()));\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return ordinals.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Ordinals\";\n-        }\n-    }\n-\n-    public static class BytesRefsFromCustomBinaryBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public BytesRefsFromCustomBinaryBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.bytesRefs(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            BinaryDocValues docValues = context.reader().getBinaryDocValues(fieldName);\n-            if (docValues == null) {\n-                return new ConstantNullsReader();\n-            }\n-            return new BytesRefsFromCustomBinary(docValues);\n-        }\n-    }\n-\n-    abstract static class AbstractBytesRefsFromBinary extends BlockDocValuesReader {\n-        protected final BinaryDocValues docValues;\n-\n-        AbstractBytesRefsFromBinary(BinaryDocValues docValues) {\n-            this.docValues = docValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.BytesRefBuilder builder = factory.bytesRefs(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BytesRefBuilder) builder);\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return docValues.docID();\n-        }\n-\n-        abstract void read(int docId, BytesRefBuilder builder) throws IOException;\n-    }\n-\n-    /**\n-     * Read BinaryDocValues encoded by {@link BinaryFieldMapper.CustomBinaryDocValuesField}\n-     */\n-    static class BytesRefsFromCustomBinary extends AbstractBytesRefsFromBinary {\n-        private final ByteArrayStreamInput in = new ByteArrayStreamInput();\n-        private final BytesRef scratch = new BytesRef();\n-\n-        BytesRefsFromCustomBinary(BinaryDocValues docValues) {\n-            super(docValues);\n-        }\n-\n-        @Override\n-        void read(int doc, BytesRefBuilder builder) throws IOException {\n-            if (false == docValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            BytesRef bytes = docValues.binaryValue();\n-            assert bytes.length > 0;\n-            in.reset(bytes.bytes, bytes.offset, bytes.length);\n-            int count = in.readVInt();\n-            scratch.bytes = bytes.bytes;\n-\n-            if (count == 1) {\n-                scratch.length = in.readVInt();\n-                scratch.offset = in.getPosition();\n-                builder.appendBytesRef(scratch);\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                scratch.length = in.readVInt();\n-                scratch.offset = in.getPosition();\n-                in.setPosition(scratch.offset + scratch.length);\n-                builder.appendBytesRef(scratch);\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.BytesCustom\";\n-        }\n-    }\n-\n-    /**\n-     * Read BinaryDocValues with no additional structure in the BytesRefs.\n-     * Each BytesRef from the doc values maps directly to a value in the block loader.\n-     */\n-    public static class BytesRefsFromBinary extends AbstractBytesRefsFromBinary {\n-        public BytesRefsFromBinary(BinaryDocValues docValues) {\n-            super(docValues);\n-        }\n-\n-        @Override\n-        void read(int doc, BytesRefBuilder builder) throws IOException {\n-            if (false == docValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            BytesRef bytes = docValues.binaryValue();\n-            builder.appendBytesRef(bytes);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Bytes\";\n-        }\n-    }\n-\n-    public static class DenseVectorFromBinaryBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-        private final int dims;\n-        private final IndexVersion indexVersion;\n-        private final ElementType elementType;\n-\n-        public DenseVectorFromBinaryBlockLoader(String fieldName, int dims, IndexVersion indexVersion, ElementType elementType) {\n-            this.fieldName = fieldName;\n-            this.dims = dims;\n-            this.indexVersion = indexVersion;\n-            this.elementType = elementType;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.denseVectors(expectedCount, dims);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            BinaryDocValues docValues = context.reader().getBinaryDocValues(fieldName);\n-            if (docValues == null) {\n-                return new ConstantNullsReader();\n-            }\n-            return switch (elementType) {\n-                case FLOAT -> new FloatDenseVectorFromBinary(docValues, dims, indexVersion);\n-                case BYTE -> new ByteDenseVectorFromBinary(docValues, dims, indexVersion);\n-                case BIT -> new BitDenseVectorFromBinary(docValues, dims, indexVersion);\n-            };\n-        }\n-    }\n-\n-    // Abstract base for dense vector readers\n-    private abstract static class AbstractDenseVectorFromBinary<T> extends BlockDocValuesReader {\n-        protected final BinaryDocValues docValues;\n-        protected final IndexVersion indexVersion;\n-        protected final int dimensions;\n-        protected final T scratch;\n-\n-        AbstractDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion, T scratch) {\n-            this.docValues = docValues;\n-            this.indexVersion = indexVersion;\n-            this.dimensions = dims;\n-            this.scratch = scratch;\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return docValues.docID();\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BlockLoader.FloatBuilder) builder);\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.FloatBuilder builder = factory.denseVectors(docs.count() - offset, dimensions)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        private void read(int doc, BlockLoader.FloatBuilder builder) throws IOException {\n-            if (docValues.advanceExact(doc) == false) {\n-                builder.appendNull();\n-                return;\n-            }\n-            BytesRef bytesRef = docValues.binaryValue();\n-            assert bytesRef.length > 0;\n-            decodeDenseVector(bytesRef, scratch);\n-\n-            builder.beginPositionEntry();\n-            writeScratchToBuilder(scratch, builder);\n-            builder.endPositionEntry();\n-        }\n-\n-        protected abstract void decodeDenseVector(BytesRef bytesRef, T scratch);\n-\n-        protected abstract void writeScratchToBuilder(T scratch, BlockLoader.FloatBuilder builder);\n-    }\n-\n-    private static class FloatDenseVectorFromBinary extends AbstractDenseVectorFromBinary<float[]> {\n-        FloatDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n-            super(docValues, dims, indexVersion, new float[dims]);\n-        }\n-\n-        @Override\n-        protected void writeScratchToBuilder(float[] scratch, BlockLoader.FloatBuilder builder) {\n-            for (float value : scratch) {\n-                builder.appendFloat(value);\n-            }\n-        }\n-\n-        @Override\n-        protected void decodeDenseVector(BytesRef bytesRef, float[] scratch) {\n-            VectorEncoderDecoder.decodeDenseVector(indexVersion, bytesRef, scratch);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"FloatDenseVectorFromBinary.Bytes\";\n-        }\n-    }\n-\n-    private static class ByteDenseVectorFromBinary extends AbstractDenseVectorFromBinary<byte[]> {\n-        ByteDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n-            this(docValues, dims, indexVersion, dims);\n-        }\n-\n-        protected ByteDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion, int readScratchSize) {\n-            super(docValues, dims, indexVersion, new byte[readScratchSize]);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"ByteDenseVectorFromBinary.Bytes\";\n-        }\n-\n-        protected void writeScratchToBuilder(byte[] scratch, BlockLoader.FloatBuilder builder) {\n-            for (byte value : scratch) {\n-                builder.appendFloat(value);\n-            }\n-        }\n-\n-        protected void decodeDenseVector(BytesRef bytesRef, byte[] scratch) {\n-            VectorEncoderDecoder.decodeDenseVector(indexVersion, bytesRef, scratch);\n-        }\n-    }\n-\n-    private static class BitDenseVectorFromBinary extends ByteDenseVectorFromBinary {\n-        BitDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n-            super(docValues, dims, indexVersion, dims / Byte.SIZE);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BitDenseVectorFromBinary.Bytes\";\n-        }\n-    }\n-\n-    public static class BooleansBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public BooleansBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public BooleanBuilder builder(BlockFactory factory, int expectedCount) {\n-            return factory.booleans(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n-            if (docValues != null) {\n-                NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonBooleans(singleton);\n-                }\n-                return new Booleans(docValues);\n-            }\n-            NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonBooleans(singleton);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    private static class SingletonBooleans extends BlockDocValuesReader {\n-        private final NumericDocValues numericDocValues;\n-\n-        SingletonBooleans(NumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.BooleanBuilder builder = factory.booleansFromDocValues(docs.count() - offset)) {\n-                int lastDoc = -1;\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (doc < lastDoc) {\n-                        throw new IllegalStateException(\"docs within same block must be in order\");\n-                    }\n-                    if (numericDocValues.advanceExact(doc)) {\n-                        builder.appendBoolean(numericDocValues.longValue() != 0);\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                    lastDoc = doc;\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            BooleanBuilder blockBuilder = (BooleanBuilder) builder;\n-            if (numericDocValues.advanceExact(docId)) {\n-                blockBuilder.appendBoolean(numericDocValues.longValue() != 0);\n-            } else {\n-                blockBuilder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonBooleans\";\n-        }\n-    }\n-\n-    private static class Booleans extends BlockDocValuesReader {\n-        private final SortedNumericDocValues numericDocValues;\n-\n-        Booleans(SortedNumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.BooleanBuilder builder = factory.booleansFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BooleanBuilder) builder);\n-        }\n-\n-        private void read(int doc, BooleanBuilder builder) throws IOException {\n-            if (false == numericDocValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = numericDocValues.docValueCount();\n-            if (count == 1) {\n-                builder.appendBoolean(numericDocValues.nextValue() != 0);\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendBoolean(numericDocValues.nextValue() != 0);\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Booleans\";\n-        }\n-    }\n-}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/BlockLoader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -15,6 +15,7 @@\n import org.apache.lucene.util.BytesRef;\n import org.elasticsearch.core.Nullable;\n import org.elasticsearch.core.Releasable;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.search.fetch.StoredFieldsSpec;\n import org.elasticsearch.search.lookup.Source;\n "
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/BlockStoredFieldsReader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -14,6 +14,7 @@\n import org.apache.lucene.index.SortedSetDocValues;\n import org.apache.lucene.util.BytesRef;\n import org.elasticsearch.index.mapper.BlockLoader.BytesRefBuilder;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.search.fetch.StoredFieldsSpec;\n \n import java.io.IOException;"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/BooleanFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "patch": "@@ -35,6 +35,7 @@\n import org.elasticsearch.index.fielddata.IndexNumericFieldData.NumericType;\n import org.elasticsearch.index.fielddata.SourceValueFetcherSortedBooleanIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BooleansBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.BooleanFieldScript;\n import org.elasticsearch.script.Script;\n@@ -351,7 +352,7 @@ public Boolean valueForDisplay(Object value) {\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues()) {\n-                return new BlockDocValuesReader.BooleansBlockLoader(name());\n+                return new BooleansBlockLoader(name());\n             }\n \n             // Multi fields don't have fallback synthetic source."
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/BooleanScriptBlockDocValuesReader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.BooleanFieldScript;\n \n import java.io.IOException;"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/DateFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "patch": "@@ -46,6 +46,7 @@\n import org.elasticsearch.index.fielddata.SortedNumericLongValues;\n import org.elasticsearch.index.fielddata.SourceValueFetcherSortedNumericIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.DateRangeIncludingNowQuery;\n import org.elasticsearch.index.query.QueryRewriteContext;\n import org.elasticsearch.index.query.SearchExecutionContext;\n@@ -927,7 +928,7 @@ public Function<byte[], Number> pointReaderIfPossible() {\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues()) {\n-                return new BlockDocValuesReader.LongsBlockLoader(name());\n+                return new LongsBlockLoader(name());\n             }\n \n             // Multi fields don't have fallback synthetic source."
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/DateScriptBlockDocValuesReader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.DateFieldScript;\n \n import java.io.IOException;"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/DoubleScriptBlockDocValuesReader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.DoubleFieldScript;\n \n import java.io.IOException;"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/GeoPointFieldMapper.java",
      "status": "modified",
      "additions": 3,
      "deletions": 1,
      "changes": 4,
      "patch": "@@ -42,6 +42,8 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.SourceValueFetcherMultiGeoPointIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.LatLonPointIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.GeoPointFieldScript;\n import org.elasticsearch.script.Script;\n@@ -553,7 +555,7 @@ public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             // load from doc values\n             if (hasDocValues()) {\n                 if (blContext.fieldExtractPreference() == DOC_VALUES) {\n-                    return new BlockDocValuesReader.LongsBlockLoader(name());\n+                    return new LongsBlockLoader(name());\n                 } else if (blContext.fieldExtractPreference() == NONE && isSyntheticSource) {\n                     // when the preference is not explicitly set to DOC_VALUES, we expect a BytesRef -> see PlannerUtils.toElementType()\n                     return new BytesRefFromLongsBlockLoader(name());"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/IgnoredFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "patch": "@@ -22,6 +22,7 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.field.KeywordDocValuesField;\n import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n@@ -97,7 +98,7 @@ public String typeName() {\n \n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n-            return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(NAME);\n+            return new BytesRefsFromOrdsBlockLoader(NAME);\n         }\n \n         @Override"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/IpFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "patch": "@@ -33,6 +33,7 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.IpFieldScript;\n import org.elasticsearch.script.Script;\n@@ -469,7 +470,7 @@ public static Query rangeQuery(\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSource)) {\n-                return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(name());\n+                return new BytesRefsFromOrdsBlockLoader(name());\n             }\n \n             if (isStored()) {"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/IpScriptBlockDocValuesReader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.IpFieldScript;\n \n import java.io.IOException;"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/KeywordFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "patch": "@@ -55,6 +55,7 @@\n import org.elasticsearch.index.fielddata.SourceValueFetcherSortedBinaryIndexFieldData;\n import org.elasticsearch.index.fielddata.StoredFieldSortedBinaryIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.AutomatonQueryWithDescription;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.index.similarity.SimilarityProvider;\n@@ -812,7 +813,7 @@ NamedAnalyzer normalizer() {\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSourceEnabled())) {\n-                return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(name());\n+                return new BytesRefsFromOrdsBlockLoader(name());\n             }\n             if (isStored()) {\n                 return new BlockStoredFieldsReader.BytesFromBytesRefsBlockLoader(name());"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/KeywordScriptBlockDocValuesReader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -11,6 +11,7 @@\n \n import org.apache.lucene.index.LeafReaderContext;\n import org.apache.lucene.util.BytesRefBuilder;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.StringFieldScript;\n \n import java.io.IOException;"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/LongScriptBlockDocValuesReader.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.LongFieldScript;\n \n import java.io.IOException;"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/NumberFieldMapper.java",
      "status": "modified",
      "additions": 10,
      "deletions": 7,
      "changes": 17,
      "patch": "@@ -47,6 +47,9 @@\n import org.elasticsearch.index.fielddata.plain.SortedDoublesIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n import org.elasticsearch.index.mapper.TimeSeriesParams.MetricType;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DoublesBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.IntsBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.DoubleFieldScript;\n import org.elasticsearch.script.LongFieldScript;\n@@ -491,7 +494,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.DoublesBlockLoader(fieldName, l -> HalfFloatPoint.sortableShortToHalfFloat((short) l));\n+                return new DoublesBlockLoader(fieldName, l -> HalfFloatPoint.sortableShortToHalfFloat((short) l));\n             }\n \n             @Override\n@@ -685,7 +688,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.DoublesBlockLoader(fieldName, l -> NumericUtils.sortableIntToFloat((int) l));\n+                return new DoublesBlockLoader(fieldName, l -> NumericUtils.sortableIntToFloat((int) l));\n             }\n \n             @Override\n@@ -845,7 +848,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.DoublesBlockLoader(fieldName, NumericUtils::sortableLongToDouble);\n+                return new DoublesBlockLoader(fieldName, NumericUtils::sortableLongToDouble);\n             }\n \n             @Override\n@@ -973,7 +976,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.IntsBlockLoader(fieldName);\n+                return new IntsBlockLoader(fieldName);\n             }\n \n             @Override\n@@ -1101,7 +1104,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.IntsBlockLoader(fieldName);\n+                return new IntsBlockLoader(fieldName);\n             }\n \n             @Override\n@@ -1303,7 +1306,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.IntsBlockLoader(fieldName);\n+                return new IntsBlockLoader(fieldName);\n             }\n \n             @Override\n@@ -1465,7 +1468,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.LongsBlockLoader(fieldName);\n+                return new LongsBlockLoader(fieldName);\n             }\n \n             @Override"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/TimeSeriesIdFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "patch": "@@ -27,6 +27,7 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.ScriptDocValues;\n import org.elasticsearch.index.fielddata.plain.SortedOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.field.DelegateDocValuesField;\n import org.elasticsearch.search.DocValueFormat;\n@@ -150,7 +151,7 @@ public Object valueForDisplay(Object value) {\n \n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n-            return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(name());\n+            return new BytesRefsFromOrdsBlockLoader(name());\n         }\n     }\n "
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/VersionFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "patch": "@@ -16,6 +16,7 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.IndexNumericFieldData.NumericType;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.QueryShardException;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.field.VersionDocValuesField;\n@@ -66,7 +67,7 @@ public ValueFetcher valueFetcher(SearchExecutionContext context, String format)\n \n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n-            return new BlockDocValuesReader.LongsBlockLoader(name());\n+            return new LongsBlockLoader(name());\n         }\n \n         @Override"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BlockDocValuesReader.java",
      "status": "added",
      "additions": 86,
      "deletions": 0,
      "changes": 86,
      "patch": "@@ -0,0 +1,86 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.search.fetch.StoredFieldsSpec;\n+\n+import java.io.IOException;\n+\n+/**\n+ * A reader that supports reading doc-values from a Lucene segment in Block fashion.\n+ */\n+public abstract class BlockDocValuesReader implements BlockLoader.AllReader {\n+    private final Thread creationThread;\n+\n+    public BlockDocValuesReader() {\n+        this.creationThread = Thread.currentThread();\n+    }\n+\n+    protected abstract int docId();\n+\n+    /**\n+     * Checks if the reader can be used to read a range documents starting with the given docID by the current thread.\n+     */\n+    @Override\n+    public final boolean canReuse(int startingDocID) {\n+        return creationThread == Thread.currentThread() && docId() <= startingDocID;\n+    }\n+\n+    @Override\n+    public abstract String toString();\n+\n+    public abstract static class DocValuesBlockLoader implements BlockLoader {\n+        public abstract AllReader reader(LeafReaderContext context) throws IOException;\n+\n+        @Override\n+        public final ColumnAtATimeReader columnAtATimeReader(LeafReaderContext context) throws IOException {\n+            return reader(context);\n+        }\n+\n+        @Override\n+        public final RowStrideReader rowStrideReader(LeafReaderContext context) throws IOException {\n+            return reader(context);\n+        }\n+\n+        @Override\n+        public final StoredFieldsSpec rowStrideStoredFieldSpec() {\n+            return StoredFieldsSpec.NO_REQUIREMENTS;\n+        }\n+\n+        @Override\n+        public boolean supportsOrdinals() {\n+            return false;\n+        }\n+\n+        @Override\n+        public SortedSetDocValues ordinals(LeafReaderContext context) throws IOException {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+    }\n+\n+    // Used for testing.\n+    public interface NumericDocValuesAccessor {\n+        NumericDocValues numericDocValues();\n+    }\n+\n+    /**\n+     * Convert from the stored {@link long} into the {@link double} to load.\n+     * Sadly, this will go megamorphic pretty quickly and slow us down,\n+     * but it gets the job done for now.\n+     */\n+    public interface ToDouble {\n+        double convert(long v);\n+    }\n+}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BooleansBlockLoader.java",
      "status": "added",
      "additions": 147,
      "deletions": 0,
      "changes": 147,
      "patch": "@@ -0,0 +1,147 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedNumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class BooleansBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public BooleansBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public BooleanBuilder builder(BlockFactory factory, int expectedCount) {\n+        return factory.booleans(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n+        if (docValues != null) {\n+            NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonBooleans(singleton);\n+            }\n+            return new Booleans(docValues);\n+        }\n+        NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonBooleans(singleton);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    private static class SingletonBooleans extends BlockDocValuesReader {\n+        private final NumericDocValues numericDocValues;\n+\n+        SingletonBooleans(NumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.BooleanBuilder builder = factory.booleansFromDocValues(docs.count() - offset)) {\n+                int lastDoc = -1;\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (doc < lastDoc) {\n+                        throw new IllegalStateException(\"docs within same block must be in order\");\n+                    }\n+                    if (numericDocValues.advanceExact(doc)) {\n+                        builder.appendBoolean(numericDocValues.longValue() != 0);\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                    lastDoc = doc;\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            BooleanBuilder blockBuilder = (BooleanBuilder) builder;\n+            if (numericDocValues.advanceExact(docId)) {\n+                blockBuilder.appendBoolean(numericDocValues.longValue() != 0);\n+            } else {\n+                blockBuilder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonBooleans\";\n+        }\n+    }\n+\n+    private static class Booleans extends BlockDocValuesReader {\n+        private final SortedNumericDocValues numericDocValues;\n+\n+        Booleans(SortedNumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.BooleanBuilder builder = factory.booleansFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BooleanBuilder) builder);\n+        }\n+\n+        private void read(int doc, BooleanBuilder builder) throws IOException {\n+            if (false == numericDocValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = numericDocValues.docValueCount();\n+            if (count == 1) {\n+                builder.appendBoolean(numericDocValues.nextValue() != 0);\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendBoolean(numericDocValues.nextValue() != 0);\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Booleans\";\n+        }\n+    }\n+}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BytesRefsFromCustomBinaryBlockLoader.java",
      "status": "added",
      "additions": 117,
      "deletions": 0,
      "changes": 117,
      "patch": "@@ -0,0 +1,117 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.BinaryDocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.common.io.stream.ByteArrayStreamInput;\n+import org.elasticsearch.index.mapper.BinaryFieldMapper;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class BytesRefsFromCustomBinaryBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public BytesRefsFromCustomBinaryBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.bytesRefs(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        BinaryDocValues docValues = context.reader().getBinaryDocValues(fieldName);\n+        if (docValues == null) {\n+            return new ConstantNullsReader();\n+        }\n+        return new BytesRefsFromCustomBinary(docValues);\n+    }\n+\n+    public abstract static class AbstractBytesRefsFromBinary extends BlockDocValuesReader {\n+        protected final BinaryDocValues docValues;\n+\n+        public AbstractBytesRefsFromBinary(BinaryDocValues docValues) {\n+            this.docValues = docValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.BytesRefBuilder builder = factory.bytesRefs(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BytesRefBuilder) builder);\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return docValues.docID();\n+        }\n+\n+        public abstract void read(int docId, BytesRefBuilder builder) throws IOException;\n+    }\n+\n+    /**\n+     * Read BinaryDocValues encoded by {@link BinaryFieldMapper.CustomBinaryDocValuesField}\n+     */\n+    static class BytesRefsFromCustomBinary extends AbstractBytesRefsFromBinary {\n+        private final ByteArrayStreamInput in = new ByteArrayStreamInput();\n+        private final BytesRef scratch = new BytesRef();\n+\n+        BytesRefsFromCustomBinary(BinaryDocValues docValues) {\n+            super(docValues);\n+        }\n+\n+        @Override\n+        public void read(int doc, BytesRefBuilder builder) throws IOException {\n+            if (false == docValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            BytesRef bytes = docValues.binaryValue();\n+            assert bytes.length > 0;\n+            in.reset(bytes.bytes, bytes.offset, bytes.length);\n+            int count = in.readVInt();\n+            scratch.bytes = bytes.bytes;\n+\n+            if (count == 1) {\n+                scratch.length = in.readVInt();\n+                scratch.offset = in.getPosition();\n+                builder.appendBytesRef(scratch);\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                scratch.length = in.readVInt();\n+                scratch.offset = in.getPosition();\n+                in.setPosition(scratch.offset + scratch.length);\n+                builder.appendBytesRef(scratch);\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.BytesCustom\";\n+        }\n+    }\n+}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BytesRefsFromOrdsBlockLoader.java",
      "status": "added",
      "additions": 218,
      "deletions": 0,
      "changes": 218,
      "patch": "@@ -0,0 +1,218 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedDocValues;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Loads {@code keyword} style fields that are stored as a lookup table and ordinals.\n+ */\n+public class BytesRefsFromOrdsBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public BytesRefsFromOrdsBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public BytesRefBuilder builder(BlockFactory factory, int expectedCount) {\n+        return factory.bytesRefs(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedSetDocValues docValues = context.reader().getSortedSetDocValues(fieldName);\n+        if (docValues != null) {\n+            SortedDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonOrdinals(singleton);\n+            }\n+            return new Ordinals(docValues);\n+        }\n+        SortedDocValues singleton = context.reader().getSortedDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonOrdinals(singleton);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    @Override\n+    public boolean supportsOrdinals() {\n+        return true;\n+    }\n+\n+    @Override\n+    public SortedSetDocValues ordinals(LeafReaderContext context) throws IOException {\n+        return DocValues.getSortedSet(context.reader(), fieldName);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"BytesRefsFromOrds[\" + fieldName + \"]\";\n+    }\n+\n+    private static class SingletonOrdinals extends BlockDocValuesReader {\n+        private final SortedDocValues ordinals;\n+\n+        SingletonOrdinals(SortedDocValues ordinals) {\n+            this.ordinals = ordinals;\n+        }\n+\n+        private BlockLoader.Block readSingleDoc(BlockFactory factory, int docId) throws IOException {\n+            if (ordinals.advanceExact(docId)) {\n+                BytesRef v = ordinals.lookupOrd(ordinals.ordValue());\n+                // the returned BytesRef can be reused\n+                return factory.constantBytes(BytesRef.deepCopyOf(v), 1);\n+            } else {\n+                return factory.constantNulls(1);\n+            }\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (docs.count() - offset == 1) {\n+                return readSingleDoc(factory, docs.get(offset));\n+            }\n+            if (ordinals instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n+                BlockLoader.Block block = direct.tryRead(factory, docs, offset, nullsFiltered, null, false);\n+                if (block != null) {\n+                    return block;\n+                }\n+            }\n+            try (var builder = factory.singletonOrdinalsBuilder(ordinals, docs.count() - offset, false)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (ordinals.advanceExact(doc)) {\n+                        builder.appendOrd(ordinals.ordValue());\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            if (ordinals.advanceExact(docId)) {\n+                ((BytesRefBuilder) builder).appendBytesRef(ordinals.lookupOrd(ordinals.ordValue()));\n+            } else {\n+                builder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return ordinals.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonOrdinals\";\n+        }\n+    }\n+\n+    private static class Ordinals extends BlockDocValuesReader {\n+        private final SortedSetDocValues ordinals;\n+\n+        Ordinals(SortedSetDocValues ordinals) {\n+            this.ordinals = ordinals;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (docs.count() - offset == 1) {\n+                return readSingleDoc(factory, docs.get(offset));\n+            }\n+            try (var builder = factory.sortedSetOrdinalsBuilder(ordinals, docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (doc < ordinals.docID()) {\n+                        throw new IllegalStateException(\"docs within same block must be in order\");\n+                    }\n+                    if (ordinals.advanceExact(doc) == false) {\n+                        builder.appendNull();\n+                        continue;\n+                    }\n+                    int count = ordinals.docValueCount();\n+                    if (count == 1) {\n+                        builder.appendOrd(Math.toIntExact(ordinals.nextOrd()));\n+                    } else {\n+                        builder.beginPositionEntry();\n+                        for (int c = 0; c < count; c++) {\n+                            builder.appendOrd(Math.toIntExact(ordinals.nextOrd()));\n+                        }\n+                        builder.endPositionEntry();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BytesRefBuilder) builder);\n+        }\n+\n+        private BlockLoader.Block readSingleDoc(BlockFactory factory, int docId) throws IOException {\n+            if (ordinals.advanceExact(docId) == false) {\n+                return factory.constantNulls(1);\n+            }\n+            int count = ordinals.docValueCount();\n+            if (count == 1) {\n+                BytesRef v = ordinals.lookupOrd(ordinals.nextOrd());\n+                return factory.constantBytes(BytesRef.deepCopyOf(v), 1);\n+            }\n+            try (var builder = factory.bytesRefsFromDocValues(count)) {\n+                builder.beginPositionEntry();\n+                for (int c = 0; c < count; c++) {\n+                    BytesRef v = ordinals.lookupOrd(ordinals.nextOrd());\n+                    builder.appendBytesRef(v);\n+                }\n+                builder.endPositionEntry();\n+                return builder.build();\n+            }\n+        }\n+\n+        private void read(int docId, BytesRefBuilder builder) throws IOException {\n+            if (false == ordinals.advanceExact(docId)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = ordinals.docValueCount();\n+            if (count == 1) {\n+                builder.appendBytesRef(ordinals.lookupOrd(ordinals.nextOrd()));\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendBytesRef(ordinals.lookupOrd(ordinals.nextOrd()));\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return ordinals.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Ordinals\";\n+        }\n+    }\n+}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DenseVectorBlockLoader.java",
      "status": "added",
      "additions": 211,
      "deletions": 0,
      "changes": 211,
      "patch": "@@ -0,0 +1,211 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.ByteVectorValues;\n+import org.apache.lucene.index.FloatVectorValues;\n+import org.apache.lucene.index.KnnVectorValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper;\n+\n+import java.io.IOException;\n+\n+import static org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper.COSINE_MAGNITUDE_FIELD_SUFFIX;\n+\n+public class DenseVectorBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+    private final int dimensions;\n+    private final DenseVectorFieldMapper.DenseVectorFieldType fieldType;\n+\n+    public DenseVectorBlockLoader(String fieldName, int dimensions, DenseVectorFieldMapper.DenseVectorFieldType fieldType) {\n+        this.fieldName = fieldName;\n+        this.dimensions = dimensions;\n+        this.fieldType = fieldType;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.denseVectors(expectedCount, dimensions);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        switch (fieldType.getElementType()) {\n+            case FLOAT -> {\n+                FloatVectorValues floatVectorValues = context.reader().getFloatVectorValues(fieldName);\n+                if (floatVectorValues != null) {\n+                    if (fieldType.isNormalized()) {\n+                        NumericDocValues magnitudeDocValues = context.reader()\n+                            .getNumericDocValues(fieldType.name() + COSINE_MAGNITUDE_FIELD_SUFFIX);\n+                        return new FloatDenseVectorNormalizedValuesBlockReader(floatVectorValues, dimensions, magnitudeDocValues);\n+                    }\n+                    return new FloatDenseVectorValuesBlockReader(floatVectorValues, dimensions);\n+                }\n+            }\n+            case BYTE -> {\n+                ByteVectorValues byteVectorValues = context.reader().getByteVectorValues(fieldName);\n+                if (byteVectorValues != null) {\n+                    return new ByteDenseVectorValuesBlockReader(byteVectorValues, dimensions);\n+                }\n+            }\n+            case BIT -> {\n+                ByteVectorValues byteVectorValues = context.reader().getByteVectorValues(fieldName);\n+                if (byteVectorValues != null) {\n+                    return new BitDenseVectorValuesBlockReader(byteVectorValues, dimensions);\n+                }\n+            }\n+        }\n+\n+        return new ConstantNullsReader();\n+    }\n+\n+    private abstract static class DenseVectorValuesBlockReader<T extends KnnVectorValues> extends BlockDocValuesReader {\n+        protected final T vectorValues;\n+        protected final KnnVectorValues.DocIndexIterator iterator;\n+        protected final int dimensions;\n+\n+        DenseVectorValuesBlockReader(T vectorValues, int dimensions) {\n+            this.vectorValues = vectorValues;\n+            iterator = vectorValues.iterator();\n+            this.dimensions = dimensions;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            // Doubles from doc values ensures that the values are in order\n+            try (BlockLoader.FloatBuilder builder = factory.denseVectors(docs.count() - offset, dimensions)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    read(docs.get(i), builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BlockLoader.FloatBuilder) builder);\n+        }\n+\n+        private void read(int doc, BlockLoader.FloatBuilder builder) throws IOException {\n+            assertDimensions();\n+\n+            if (iterator.docID() > doc) {\n+                builder.appendNull();\n+            } else if (iterator.docID() == doc || iterator.advance(doc) == doc) {\n+                builder.beginPositionEntry();\n+                appendDoc(builder);\n+                builder.endPositionEntry();\n+            } else {\n+                builder.appendNull();\n+            }\n+        }\n+\n+        protected abstract void appendDoc(BlockLoader.FloatBuilder builder) throws IOException;\n+\n+        @Override\n+        public int docId() {\n+            return iterator.docID();\n+        }\n+\n+        protected void assertDimensions() {\n+            assert vectorValues.dimension() == dimensions\n+                : \"unexpected dimensions for vector value; expected \" + dimensions + \" but got \" + vectorValues.dimension();\n+        }\n+    }\n+\n+    private static class FloatDenseVectorValuesBlockReader extends DenseVectorValuesBlockReader<FloatVectorValues> {\n+\n+        FloatDenseVectorValuesBlockReader(FloatVectorValues floatVectorValues, int dimensions) {\n+            super(floatVectorValues, dimensions);\n+        }\n+\n+        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n+            float[] floats = vectorValues.vectorValue(iterator.index());\n+            for (float aFloat : floats) {\n+                builder.appendFloat(aFloat);\n+            }\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.FloatDenseVectorValuesBlockReader\";\n+        }\n+    }\n+\n+    private static class FloatDenseVectorNormalizedValuesBlockReader extends DenseVectorValuesBlockReader<FloatVectorValues> {\n+        private final NumericDocValues magnitudeDocValues;\n+\n+        FloatDenseVectorNormalizedValuesBlockReader(\n+            FloatVectorValues floatVectorValues,\n+            int dimensions,\n+            NumericDocValues magnitudeDocValues\n+        ) {\n+            super(floatVectorValues, dimensions);\n+            this.magnitudeDocValues = magnitudeDocValues;\n+        }\n+\n+        @Override\n+        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n+            float magnitude = 1.0f;\n+            // If all vectors are normalized, no doc values will be present. The vector may be normalized already, so we may not have a\n+            // stored magnitude for all docs\n+            if ((magnitudeDocValues != null) && magnitudeDocValues.advanceExact(iterator.docID())) {\n+                magnitude = Float.intBitsToFloat((int) magnitudeDocValues.longValue());\n+            }\n+            float[] floats = vectorValues.vectorValue(iterator.index());\n+            for (float aFloat : floats) {\n+                builder.appendFloat(aFloat * magnitude);\n+            }\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.FloatDenseVectorNormalizedValuesBlockReader\";\n+        }\n+    }\n+\n+    private static class ByteDenseVectorValuesBlockReader extends DenseVectorValuesBlockReader<ByteVectorValues> {\n+        ByteDenseVectorValuesBlockReader(ByteVectorValues floatVectorValues, int dimensions) {\n+            super(floatVectorValues, dimensions);\n+        }\n+\n+        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n+            byte[] bytes = vectorValues.vectorValue(iterator.index());\n+            for (byte aFloat : bytes) {\n+                builder.appendFloat(aFloat);\n+            }\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.ByteDenseVectorValuesBlockReader\";\n+        }\n+    }\n+\n+    private static class BitDenseVectorValuesBlockReader extends ByteDenseVectorValuesBlockReader {\n+\n+        BitDenseVectorValuesBlockReader(ByteVectorValues floatVectorValues, int dimensions) {\n+            super(floatVectorValues, dimensions);\n+        }\n+\n+        @Override\n+        protected void assertDimensions() {\n+            assert vectorValues.dimension() * Byte.SIZE == dimensions\n+                : \"unexpected dimensions for vector value; expected \" + dimensions + \" but got \" + vectorValues.dimension() * Byte.SIZE;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.BitDenseVectorValuesBlockReader\";\n+        }\n+    }\n+}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DenseVectorFromBinaryBlockLoader.java",
      "status": "added",
      "additions": 170,
      "deletions": 0,
      "changes": 170,
      "patch": "@@ -0,0 +1,170 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.BinaryDocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.index.IndexVersion;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper;\n+import org.elasticsearch.index.mapper.vectors.VectorEncoderDecoder;\n+\n+import java.io.IOException;\n+\n+public class DenseVectorFromBinaryBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+    private final int dims;\n+    private final IndexVersion indexVersion;\n+    private final DenseVectorFieldMapper.ElementType elementType;\n+\n+    public DenseVectorFromBinaryBlockLoader(\n+        String fieldName,\n+        int dims,\n+        IndexVersion indexVersion,\n+        DenseVectorFieldMapper.ElementType elementType\n+    ) {\n+        this.fieldName = fieldName;\n+        this.dims = dims;\n+        this.indexVersion = indexVersion;\n+        this.elementType = elementType;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.denseVectors(expectedCount, dims);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        BinaryDocValues docValues = context.reader().getBinaryDocValues(fieldName);\n+        if (docValues == null) {\n+            return new ConstantNullsReader();\n+        }\n+        return switch (elementType) {\n+            case FLOAT -> new FloatDenseVectorFromBinary(docValues, dims, indexVersion);\n+            case BYTE -> new ByteDenseVectorFromBinary(docValues, dims, indexVersion);\n+            case BIT -> new BitDenseVectorFromBinary(docValues, dims, indexVersion);\n+        };\n+    }\n+\n+    // Abstract base for dense vector readers\n+    private abstract static class AbstractDenseVectorFromBinary<T> extends BlockDocValuesReader {\n+        protected final BinaryDocValues docValues;\n+        protected final IndexVersion indexVersion;\n+        protected final int dimensions;\n+        protected final T scratch;\n+\n+        AbstractDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion, T scratch) {\n+            this.docValues = docValues;\n+            this.indexVersion = indexVersion;\n+            this.dimensions = dims;\n+            this.scratch = scratch;\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return docValues.docID();\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BlockLoader.FloatBuilder) builder);\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.FloatBuilder builder = factory.denseVectors(docs.count() - offset, dimensions)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        private void read(int doc, BlockLoader.FloatBuilder builder) throws IOException {\n+            if (docValues.advanceExact(doc) == false) {\n+                builder.appendNull();\n+                return;\n+            }\n+            BytesRef bytesRef = docValues.binaryValue();\n+            assert bytesRef.length > 0;\n+            decodeDenseVector(bytesRef, scratch);\n+\n+            builder.beginPositionEntry();\n+            writeScratchToBuilder(scratch, builder);\n+            builder.endPositionEntry();\n+        }\n+\n+        protected abstract void decodeDenseVector(BytesRef bytesRef, T scratch);\n+\n+        protected abstract void writeScratchToBuilder(T scratch, BlockLoader.FloatBuilder builder);\n+    }\n+\n+    private static class FloatDenseVectorFromBinary extends AbstractDenseVectorFromBinary<float[]> {\n+        FloatDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n+            super(docValues, dims, indexVersion, new float[dims]);\n+        }\n+\n+        @Override\n+        protected void writeScratchToBuilder(float[] scratch, BlockLoader.FloatBuilder builder) {\n+            for (float value : scratch) {\n+                builder.appendFloat(value);\n+            }\n+        }\n+\n+        @Override\n+        protected void decodeDenseVector(BytesRef bytesRef, float[] scratch) {\n+            VectorEncoderDecoder.decodeDenseVector(indexVersion, bytesRef, scratch);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"FloatDenseVectorFromBinary.Bytes\";\n+        }\n+    }\n+\n+    private static class ByteDenseVectorFromBinary extends AbstractDenseVectorFromBinary<byte[]> {\n+        ByteDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n+            this(docValues, dims, indexVersion, dims);\n+        }\n+\n+        protected ByteDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion, int readScratchSize) {\n+            super(docValues, dims, indexVersion, new byte[readScratchSize]);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"ByteDenseVectorFromBinary.Bytes\";\n+        }\n+\n+        protected void writeScratchToBuilder(byte[] scratch, BlockLoader.FloatBuilder builder) {\n+            for (byte value : scratch) {\n+                builder.appendFloat(value);\n+            }\n+        }\n+\n+        protected void decodeDenseVector(BytesRef bytesRef, byte[] scratch) {\n+            VectorEncoderDecoder.decodeDenseVector(indexVersion, bytesRef, scratch);\n+        }\n+    }\n+\n+    private static class BitDenseVectorFromBinary extends ByteDenseVectorFromBinary {\n+        BitDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n+            super(docValues, dims, indexVersion, dims / Byte.SIZE);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BitDenseVectorFromBinary.Bytes\";\n+        }\n+    }\n+}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DoublesBlockLoader.java",
      "status": "added",
      "additions": 159,
      "deletions": 0,
      "changes": 159,
      "patch": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedNumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class DoublesBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+    private final BlockDocValuesReader.ToDouble toDouble;\n+\n+    public DoublesBlockLoader(String fieldName, BlockDocValuesReader.ToDouble toDouble) {\n+        this.fieldName = fieldName;\n+        this.toDouble = toDouble;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.doubles(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n+        if (docValues != null) {\n+            NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonDoubles(singleton, toDouble);\n+            }\n+            return new Doubles(docValues, toDouble);\n+        }\n+        NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonDoubles(singleton, toDouble);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    public static class SingletonDoubles extends BlockDocValuesReader implements BlockDocValuesReader.NumericDocValuesAccessor {\n+        private final NumericDocValues docValues;\n+        private final ToDouble toDouble;\n+\n+        SingletonDoubles(NumericDocValues docValues, ToDouble toDouble) {\n+            this.docValues = docValues;\n+            this.toDouble = toDouble;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (docValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n+                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, toDouble, false);\n+                if (result != null) {\n+                    return result;\n+                }\n+            }\n+            try (BlockLoader.DoubleBuilder builder = factory.doublesFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (docValues.advanceExact(doc)) {\n+                        builder.appendDouble(toDouble.convert(docValues.longValue()));\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            DoubleBuilder blockBuilder = (DoubleBuilder) builder;\n+            if (docValues.advanceExact(docId)) {\n+                blockBuilder.appendDouble(toDouble.convert(docValues.longValue()));\n+            } else {\n+                blockBuilder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return docValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonDoubles\";\n+        }\n+\n+        @Override\n+        public NumericDocValues numericDocValues() {\n+            return docValues;\n+        }\n+    }\n+\n+    public static class Doubles extends BlockDocValuesReader {\n+        private final SortedNumericDocValues docValues;\n+        private final ToDouble toDouble;\n+\n+        Doubles(SortedNumericDocValues docValues, ToDouble toDouble) {\n+            this.docValues = docValues;\n+            this.toDouble = toDouble;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.DoubleBuilder builder = factory.doublesFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (DoubleBuilder) builder);\n+        }\n+\n+        private void read(int doc, DoubleBuilder builder) throws IOException {\n+            if (false == docValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = docValues.docValueCount();\n+            if (count == 1) {\n+                builder.appendDouble(toDouble.convert(docValues.nextValue()));\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendDouble(toDouble.convert(docValues.nextValue()));\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return docValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Doubles\";\n+        }\n+    }\n+}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/IntsBlockLoader.java",
      "status": "added",
      "additions": 153,
      "deletions": 0,
      "changes": 153,
      "patch": "@@ -0,0 +1,153 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedNumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class IntsBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public IntsBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.ints(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n+        if (docValues != null) {\n+            NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonInts(singleton);\n+            }\n+            return new Ints(docValues);\n+        }\n+        NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonInts(singleton);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    public static class SingletonInts extends BlockDocValuesReader implements BlockDocValuesReader.NumericDocValuesAccessor {\n+        private final NumericDocValues numericDocValues;\n+\n+        SingletonInts(NumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (numericDocValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n+                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, null, true);\n+                if (result != null) {\n+                    return result;\n+                }\n+            }\n+            try (BlockLoader.IntBuilder builder = factory.intsFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (numericDocValues.advanceExact(doc)) {\n+                        builder.appendInt(Math.toIntExact(numericDocValues.longValue()));\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            IntBuilder blockBuilder = (IntBuilder) builder;\n+            if (numericDocValues.advanceExact(docId)) {\n+                blockBuilder.appendInt(Math.toIntExact(numericDocValues.longValue()));\n+            } else {\n+                blockBuilder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonInts\";\n+        }\n+\n+        @Override\n+        public NumericDocValues numericDocValues() {\n+            return numericDocValues;\n+        }\n+    }\n+\n+    public static class Ints extends BlockDocValuesReader {\n+        private final SortedNumericDocValues numericDocValues;\n+\n+        Ints(SortedNumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.IntBuilder builder = factory.intsFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (IntBuilder) builder);\n+        }\n+\n+        private void read(int doc, IntBuilder builder) throws IOException {\n+            if (false == numericDocValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = numericDocValues.docValueCount();\n+            if (count == 1) {\n+                builder.appendInt(Math.toIntExact(numericDocValues.nextValue()));\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendInt(Math.toIntExact(numericDocValues.nextValue()));\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Ints\";\n+        }\n+    }\n+}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/LongsBlockLoader.java",
      "status": "added",
      "additions": 153,
      "deletions": 0,
      "changes": 153,
      "patch": "@@ -0,0 +1,153 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedNumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class LongsBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public LongsBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.longs(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n+        if (docValues != null) {\n+            NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonLongs(singleton);\n+            }\n+            return new Longs(docValues);\n+        }\n+        NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonLongs(singleton);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    public static class SingletonLongs extends BlockDocValuesReader implements BlockDocValuesReader.NumericDocValuesAccessor {\n+        final NumericDocValues numericDocValues;\n+\n+        SingletonLongs(NumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (numericDocValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n+                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, null, false);\n+                if (result != null) {\n+                    return result;\n+                }\n+            }\n+            try (BlockLoader.LongBuilder builder = factory.longsFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (numericDocValues.advanceExact(doc)) {\n+                        builder.appendLong(numericDocValues.longValue());\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            BlockLoader.LongBuilder blockBuilder = (BlockLoader.LongBuilder) builder;\n+            if (numericDocValues.advanceExact(docId)) {\n+                blockBuilder.appendLong(numericDocValues.longValue());\n+            } else {\n+                blockBuilder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonLongs\";\n+        }\n+\n+        @Override\n+        public NumericDocValues numericDocValues() {\n+            return numericDocValues;\n+        }\n+    }\n+\n+    public static class Longs extends BlockDocValuesReader {\n+        private final SortedNumericDocValues numericDocValues;\n+\n+        Longs(SortedNumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.LongBuilder builder = factory.longsFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (LongBuilder) builder);\n+        }\n+\n+        private void read(int doc, LongBuilder builder) throws IOException {\n+            if (false == numericDocValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = numericDocValues.docValueCount();\n+            if (count == 1) {\n+                builder.appendLong(numericDocValues.nextValue());\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendLong(numericDocValues.nextValue());\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Longs\";\n+        }\n+    }\n+}"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/mapper/vectors/DenseVectorFieldMapper.java",
      "status": "modified",
      "additions": 4,
      "deletions": 3,
      "changes": 7,
      "patch": "@@ -58,7 +58,6 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.mapper.ArraySourceValueFetcher;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.BlockSourceReader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n@@ -74,6 +73,8 @@\n import org.elasticsearch.index.mapper.SourceLoader;\n import org.elasticsearch.index.mapper.SourceValueFetcher;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DenseVectorBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DenseVectorFromBinaryBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.search.DocValueFormat;\n import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n@@ -2689,11 +2690,11 @@ public BlockLoader blockLoader(MappedFieldType.BlockLoaderContext blContext) {\n             }\n \n             if (indexed) {\n-                return new BlockDocValuesReader.DenseVectorBlockLoader(name(), dims, this);\n+                return new DenseVectorBlockLoader(name(), dims, this);\n             }\n \n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSource)) {\n-                return new BlockDocValuesReader.DenseVectorFromBinaryBlockLoader(name(), dims, indexVersionCreated, element.elementType());\n+                return new DenseVectorFromBinaryBlockLoader(name(), dims, indexVersionCreated, element.elementType());\n             }\n             BlockSourceReader.LeafIteratorLookup lookup = BlockSourceReader.lookupMatchingAll();\n             return new BlockSourceReader.DenseVectorBlockLoader("
    },
    {
      "filename": "server/src/test/java/org/elasticsearch/index/mapper/DateFieldMapperTests.java",
      "status": "modified",
      "additions": 9,
      "deletions": 8,
      "changes": 17,
      "patch": "@@ -33,6 +33,7 @@\n import org.elasticsearch.index.IndexVersions;\n import org.elasticsearch.index.codec.tsdb.es819.ES819TSDBDocValuesFormat;\n import org.elasticsearch.index.mapper.DateFieldMapper.DateFieldType;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.script.DateFieldScript;\n import org.elasticsearch.script.ScriptService;\n import org.elasticsearch.search.DocValueFormat;\n@@ -854,8 +855,8 @@ public void testSingletonLongBulkBlockReadingManyValues() throws Exception {\n                 LeafReaderContext context = reader.leaves().get(0);\n                 {\n                     // One big doc block\n-                    var columnReader = (BlockDocValuesReader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n-                    assertThat(columnReader.numericDocValues, instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n+                    var columnReader = (LongsBlockLoader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n+                    assertThat(columnReader.numericDocValues(), instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n                     var docBlock = TestBlock.docs(IntStream.range(from, to).toArray());\n                     var block = (TestBlock) columnReader.read(TestBlock.factory(), docBlock, 0, false);\n                     assertThat(block.size(), equalTo(to - from));\n@@ -866,8 +867,8 @@ public void testSingletonLongBulkBlockReadingManyValues() throws Exception {\n                 {\n                     // Smaller doc blocks\n                     int docBlockSize = 1000;\n-                    var columnReader = (BlockDocValuesReader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n-                    assertThat(columnReader.numericDocValues, instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n+                    var columnReader = (LongsBlockLoader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n+                    assertThat(columnReader.numericDocValues(), instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n                     for (int i = from; i < to; i += docBlockSize) {\n                         var docBlock = TestBlock.docs(IntStream.range(i, i + docBlockSize).toArray());\n                         var block = (TestBlock) columnReader.read(TestBlock.factory(), docBlock, 0, false);\n@@ -880,8 +881,8 @@ public void testSingletonLongBulkBlockReadingManyValues() throws Exception {\n                 }\n                 {\n                     // One smaller doc block:\n-                    var columnReader = (BlockDocValuesReader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n-                    assertThat(columnReader.numericDocValues, instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n+                    var columnReader = (LongsBlockLoader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n+                    assertThat(columnReader.numericDocValues(), instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n                     var docBlock = TestBlock.docs(IntStream.range(1010, 2020).toArray());\n                     var block = (TestBlock) columnReader.read(TestBlock.factory(), docBlock, 0, false);\n                     assertThat(block.size(), equalTo(1010));\n@@ -892,8 +893,8 @@ public void testSingletonLongBulkBlockReadingManyValues() throws Exception {\n                 }\n                 {\n                     // Read two tiny blocks:\n-                    var columnReader = (BlockDocValuesReader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n-                    assertThat(columnReader.numericDocValues, instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n+                    var columnReader = (LongsBlockLoader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n+                    assertThat(columnReader.numericDocValues(), instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n                     var docBlock = TestBlock.docs(IntStream.range(32, 64).toArray());\n                     var block = (TestBlock) columnReader.read(TestBlock.factory(), docBlock, 0, false);\n                     assertThat(block.size(), equalTo(32));"
    },
    {
      "filename": "server/src/test/java/org/elasticsearch/index/mapper/GeoPointFieldTypeTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 1,
      "changes": 3,
      "patch": "@@ -19,6 +19,7 @@\n import org.elasticsearch.index.IndexMode;\n import org.elasticsearch.index.IndexSettings;\n import org.elasticsearch.index.IndexVersion;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.script.ScriptCompiler;\n \n import java.io.IOException;\n@@ -166,7 +167,7 @@ public void testBlockLoaderWhenDocValuesAreEnabledAndThePreferenceIsToUseDocValu\n \n         // then\n         // verify that we use the correct block value reader\n-        assertThat(loader, instanceOf(BlockDocValuesReader.LongsBlockLoader.class));\n+        assertThat(loader, instanceOf(LongsBlockLoader.class));\n     }\n \n     public void testBlockLoaderWhenDocValuesAreEnabledAndThereIsNoPreference() {"
    },
    {
      "filename": "test/framework/src/main/java/org/elasticsearch/index/mapper/MapperTestCase.java",
      "status": "modified",
      "additions": 10,
      "deletions": 6,
      "changes": 16,
      "patch": "@@ -51,6 +51,10 @@\n import org.elasticsearch.index.fielddata.LeafFieldData;\n import org.elasticsearch.index.fieldvisitor.LeafStoredFieldLoader;\n import org.elasticsearch.index.fieldvisitor.StoredFieldLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DoublesBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.IntsBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.index.termvectors.TermVectorsService;\n import org.elasticsearch.index.translog.Translog;\n@@ -1523,17 +1527,17 @@ protected Object[] getThreeEncodedSampleValues() {\n \n     public void testSingletonIntBulkBlockReading() throws IOException {\n         assumeTrue(\"field type supports bulk singleton int reading\", supportsBulkIntBlockReading());\n-        testSingletonBulkBlockReading(columnAtATimeReader -> (BlockDocValuesReader.SingletonInts) columnAtATimeReader);\n+        testSingletonBulkBlockReading(columnAtATimeReader -> (IntsBlockLoader.SingletonInts) columnAtATimeReader);\n     }\n \n     public void testSingletonLongBulkBlockReading() throws IOException {\n         assumeTrue(\"field type supports bulk singleton long reading\", supportsBulkLongBlockReading());\n-        testSingletonBulkBlockReading(columnAtATimeReader -> (BlockDocValuesReader.SingletonLongs) columnAtATimeReader);\n+        testSingletonBulkBlockReading(columnAtATimeReader -> (LongsBlockLoader.SingletonLongs) columnAtATimeReader);\n     }\n \n     public void testSingletonDoubleBulkBlockReading() throws IOException {\n         assumeTrue(\"field type supports bulk singleton double reading\", supportsBulkDoubleBlockReading());\n-        testSingletonBulkBlockReading(columnAtATimeReader -> (BlockDocValuesReader.SingletonDoubles) columnAtATimeReader);\n+        testSingletonBulkBlockReading(columnAtATimeReader -> (DoublesBlockLoader.SingletonDoubles) columnAtATimeReader);\n     }\n \n     private void testSingletonBulkBlockReading(Function<BlockLoader.ColumnAtATimeReader, BlockDocValuesReader> readerCast)\n@@ -1637,9 +1641,9 @@ private void testSingletonBulkBlockReading(Function<BlockLoader.ColumnAtATimeRea\n                 assertThat(\n                     columnReader,\n                     anyOf(\n-                        instanceOf(BlockDocValuesReader.Longs.class),\n-                        instanceOf(BlockDocValuesReader.Doubles.class),\n-                        instanceOf(BlockDocValuesReader.Ints.class)\n+                        instanceOf(LongsBlockLoader.Longs.class),\n+                        instanceOf(DoublesBlockLoader.Doubles.class),\n+                        instanceOf(IntsBlockLoader.Ints.class)\n                     )\n                 );\n                 var docBlock = TestBlock.docs(IntStream.range(0, 3).toArray());"
    },
    {
      "filename": "test/framework/src/main/java/org/elasticsearch/index/mapper/TestBlock.java",
      "status": "modified",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "patch": "@@ -13,6 +13,7 @@\n import org.apache.lucene.index.SortedDocValues;\n import org.apache.lucene.index.SortedSetDocValues;\n import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.hamcrest.Matcher;\n \n import java.io.IOException;"
    },
    {
      "filename": "x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/lucene/read/SingletonDoubleBuilder.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "patch": "@@ -10,8 +10,8 @@\n import org.elasticsearch.compute.data.Block;\n import org.elasticsearch.compute.data.BlockFactory;\n import org.elasticsearch.core.Releasable;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n \n /**\n  * Like {@link org.elasticsearch.compute.data.DoubleBlockBuilder} but optimized for collecting dense single valued values."
    },
    {
      "filename": "x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/OperatorTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 9,
      "changes": 11,
      "patch": "@@ -66,12 +66,12 @@\n import org.elasticsearch.core.CheckedConsumer;\n import org.elasticsearch.core.Releasables;\n import org.elasticsearch.index.IndexSettings;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.FieldNamesFieldMapper;\n import org.elasticsearch.index.mapper.KeywordFieldMapper;\n import org.elasticsearch.index.mapper.MappedFieldType;\n import org.elasticsearch.index.mapper.MapperServiceTestCase;\n import org.elasticsearch.index.mapper.Uid;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;\n import org.elasticsearch.search.lookup.SearchLookup;\n \n@@ -183,14 +183,7 @@ public void testPushRoundToToQuery() throws IOException {\n             );\n             ValuesSourceReaderOperator.Factory load = new ValuesSourceReaderOperator.Factory(\n                 ByteSizeValue.ofGb(1),\n-                List.of(\n-                    new ValuesSourceReaderOperator.FieldInfo(\n-                        \"v\",\n-                        ElementType.LONG,\n-                        false,\n-                        f -> new BlockDocValuesReader.LongsBlockLoader(\"v\")\n-                    )\n-                ),\n+                List.of(new ValuesSourceReaderOperator.FieldInfo(\"v\", ElementType.LONG, false, f -> new LongsBlockLoader(\"v\"))),\n                 new IndexedByShardIdFromSingleton<>(new ValuesSourceReaderOperator.ShardContext(reader, (sourcePaths) -> {\n                     throw new UnsupportedOperationException();\n                 }, 0.8)),"
    },
    {
      "filename": "x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/lucene/LuceneQueryEvaluatorTests.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "patch": "@@ -42,7 +42,7 @@\n import org.elasticsearch.compute.test.TestDriverFactory;\n import org.elasticsearch.compute.test.TestResultPageSinkOperator;\n import org.elasticsearch.core.CheckedFunction;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n \n import java.io.IOException;\n import java.util.ArrayList;\n@@ -207,7 +207,7 @@ private List<Page> runQuery(Set<String> values, Query query, boolean shuffleDocs\n                             FIELD,\n                             ElementType.BYTES_REF,\n                             false,\n-                            unused -> new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(FIELD)\n+                            unused -> new BytesRefsFromOrdsBlockLoader(FIELD)\n                         )\n                     ),\n                     new IndexedByShardIdFromSingleton<>(new ValuesSourceReaderOperator.ShardContext(reader, (sourcePaths) -> {"
    },
    {
      "filename": "x-pack/plugin/logsdb/src/main/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextBlockLoader.java",
      "status": "modified",
      "additions": 30,
      "deletions": 2,
      "changes": 32,
      "patch": "@@ -7,8 +7,11 @@\n \n package org.elasticsearch.xpack.logsdb.patterntext;\n \n+import org.apache.lucene.index.BinaryDocValues;\n import org.apache.lucene.index.LeafReaderContext;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromCustomBinaryBlockLoader;\n \n import java.io.IOException;\n \n@@ -31,6 +34,31 @@ public AllReader reader(LeafReaderContext context) throws IOException {\n         if (docValues == null) {\n             return new ConstantNullsReader();\n         }\n-        return new BlockDocValuesReader.BytesRefsFromBinary(docValues);\n+        return new BytesRefsFromBinary(docValues);\n+    }\n+\n+    /**\n+     * Read BinaryDocValues with no additional structure in the BytesRefs.\n+     * Each BytesRef from the doc values maps directly to a value in the block loader.\n+     */\n+    public static class BytesRefsFromBinary extends BytesRefsFromCustomBinaryBlockLoader.AbstractBytesRefsFromBinary {\n+        public BytesRefsFromBinary(BinaryDocValues docValues) {\n+            super(docValues);\n+        }\n+\n+        @Override\n+        public void read(int doc, BytesRefBuilder builder) throws IOException {\n+            if (false == docValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            BytesRef bytes = docValues.binaryValue();\n+            builder.appendBytesRef(bytes);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Bytes\";\n+        }\n     }\n }"
    },
    {
      "filename": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateMetricDoubleFieldMapper.java",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "changes": 2,
      "patch": "@@ -28,7 +28,6 @@\n import org.elasticsearch.index.fielddata.ScriptDocValues.DoublesSupplier;\n import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n@@ -46,6 +45,7 @@\n import org.elasticsearch.index.mapper.TimeSeriesParams;\n import org.elasticsearch.index.mapper.TimeSeriesParams.MetricType;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.index.query.QueryRewriteContext;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.ScriptCompiler;"
    },
    {
      "filename": "x-pack/plugin/mapper-unsigned-long/src/main/java/org/elasticsearch/xpack/unsignedlong/UnsignedLongFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "patch": "@@ -27,7 +27,6 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.IndexNumericFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.BlockSourceReader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n@@ -50,6 +49,7 @@\n import org.elasticsearch.index.mapper.TimeSeriesParams;\n import org.elasticsearch.index.mapper.TimeSeriesParams.MetricType;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.search.DocValueFormat;\n import org.elasticsearch.search.aggregations.support.TimeSeriesValuesSourceType;\n@@ -383,7 +383,7 @@ public BlockLoader blockLoader(BlockLoaderContext blContext) {\n                 return BlockLoader.CONSTANT_NULLS;\n             }\n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSource)) {\n-                return new BlockDocValuesReader.LongsBlockLoader(name());\n+                return new LongsBlockLoader(name());\n             }\n             // Multi fields don't have fallback synthetic source.\n             if (isSyntheticSource && blContext.parentField(name()) == null) {"
    },
    {
      "filename": "x-pack/plugin/mapper-version/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "patch": "@@ -39,7 +39,6 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n@@ -53,6 +52,7 @@\n import org.elasticsearch.index.mapper.TermBasedFieldType;\n import org.elasticsearch.index.mapper.TextSearchInfo;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.search.DocValueFormat;\n import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n@@ -305,7 +305,7 @@ protected BytesRef indexedValueForSearch(Object value) {\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             failIfNoDocValues();\n-            return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(name());\n+            return new BytesRefsFromOrdsBlockLoader(name());\n         }\n \n         @Override"
    },
    {
      "filename": "x-pack/plugin/spatial/src/main/java/org/elasticsearch/xpack/spatial/index/mapper/PointFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "patch": "@@ -26,13 +26,13 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.mapper.AbstractPointGeometryFieldMapper;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n import org.elasticsearch.index.mapper.FieldMapper;\n import org.elasticsearch.index.mapper.IndexType;\n import org.elasticsearch.index.mapper.MappedFieldType;\n import org.elasticsearch.index.mapper.MapperBuilderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.lucene.spatial.XYQueriesUtils;\n import org.elasticsearch.xcontent.XContentBuilder;\n@@ -243,7 +243,7 @@ protected Function<List<CartesianPoint>, List<Object>> getFormatter(String forma\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (blContext.fieldExtractPreference() == DOC_VALUES && hasDocValues()) {\n-                return new BlockDocValuesReader.LongsBlockLoader(name());\n+                return new LongsBlockLoader(name());\n             }\n \n             // Multi fields don't have fallback synthetic source.s"
    },
    {
      "filename": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "changes": 4,
      "patch": "@@ -59,7 +59,6 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.plain.StringBinaryIndexFieldData;\n import org.elasticsearch.index.mapper.BinaryFieldMapper.CustomBinaryDocValuesField;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n@@ -73,6 +72,7 @@\n import org.elasticsearch.index.mapper.SourceValueFetcher;\n import org.elasticsearch.index.mapper.TextSearchInfo;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromCustomBinaryBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n import org.elasticsearch.xcontent.XContentBuilder;\n@@ -958,7 +958,7 @@ public Query prefixQuery(\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues()) {\n-                return new BlockDocValuesReader.BytesRefsFromCustomBinaryBlockLoader(name());\n+                return new BytesRefsFromCustomBinaryBlockLoader(name());\n             }\n             return null;\n         }"
    }
  ],
  "diff": "diff --git a/modules/mapper-extras/src/main/java/org/elasticsearch/index/mapper/extras/ScaledFloatFieldMapper.java b/modules/mapper-extras/src/main/java/org/elasticsearch/index/mapper/extras/ScaledFloatFieldMapper.java\nindex 826ca3bb89811..40fd851b98793 100644\n--- a/modules/mapper-extras/src/main/java/org/elasticsearch/index/mapper/extras/ScaledFloatFieldMapper.java\n+++ b/modules/mapper-extras/src/main/java/org/elasticsearch/index/mapper/extras/ScaledFloatFieldMapper.java\n@@ -31,7 +31,6 @@\n import org.elasticsearch.index.fielddata.SourceValueFetcherSortedDoubleIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.LeafDoubleFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.BlockSourceReader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n@@ -51,6 +50,7 @@\n import org.elasticsearch.index.mapper.TextSearchInfo;\n import org.elasticsearch.index.mapper.TimeSeriesParams;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DoublesBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.field.DocValuesScriptFieldFactory;\n import org.elasticsearch.script.field.ScaledFloatDocValuesField;\n@@ -382,7 +382,7 @@ public BlockLoader blockLoader(BlockLoaderContext blContext) {\n                 return BlockLoader.CONSTANT_NULLS;\n             }\n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSource)) {\n-                return new BlockDocValuesReader.DoublesBlockLoader(name(), l -> l / scalingFactor);\n+                return new DoublesBlockLoader(name(), l -> l / scalingFactor);\n             }\n             // Multi fields don't have fallback synthetic source.\n             if (isSyntheticSource && blContext.parentField(name()) == null) {\ndiff --git a/server/src/main/java/module-info.java b/server/src/main/java/module-info.java\nindex fd50628539ebd..e7bf0c83a1123 100644\n--- a/server/src/main/java/module-info.java\n+++ b/server/src/main/java/module-info.java\n@@ -499,4 +499,5 @@\n     exports org.elasticsearch.index.codec.vectors.cluster to org.elasticsearch.test.knn;\n     exports org.elasticsearch.index.codec.vectors.es93 to org.elasticsearch.test.knn;\n     exports org.elasticsearch.search.crossproject;\n+    exports org.elasticsearch.index.mapper.blockloader.docvalues;\n }\ndiff --git a/server/src/main/java/org/elasticsearch/index/codec/tsdb/es819/ES819TSDBDocValuesProducer.java b/server/src/main/java/org/elasticsearch/index/codec/tsdb/es819/ES819TSDBDocValuesProducer.java\nindex 5d90f2814853d..df83845a69370 100644\n--- a/server/src/main/java/org/elasticsearch/index/codec/tsdb/es819/ES819TSDBDocValuesProducer.java\n+++ b/server/src/main/java/org/elasticsearch/index/codec/tsdb/es819/ES819TSDBDocValuesProducer.java\n@@ -46,8 +46,8 @@\n import org.elasticsearch.core.Assertions;\n import org.elasticsearch.core.IOUtils;\n import org.elasticsearch.index.codec.tsdb.TSDBDocValuesEncoder;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n \n import java.io.IOException;\n \ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/AbstractShapeGeometryFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/AbstractShapeGeometryFieldMapper.java\nindex d6ed620fde016..ae7c888490d61 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/AbstractShapeGeometryFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/AbstractShapeGeometryFieldMapper.java\n@@ -12,6 +12,7 @@\n import org.apache.lucene.index.LeafReaderContext;\n import org.elasticsearch.common.Explicit;\n import org.elasticsearch.common.geo.Orientation;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.lucene.spatial.Extent;\n import org.elasticsearch.lucene.spatial.GeometryDocValueReader;\n \ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/BlockDocValuesReader.java b/server/src/main/java/org/elasticsearch/index/mapper/BlockDocValuesReader.java\ndeleted file mode 100644\nindex 457c90383b5d2..0000000000000\n--- a/server/src/main/java/org/elasticsearch/index/mapper/BlockDocValuesReader.java\n+++ /dev/null\n@@ -1,1302 +0,0 @@\n-/*\n- * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n- * or more contributor license agreements. Licensed under the \"Elastic License\n- * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n- * Public License v 1\"; you may not use this file except in compliance with, at\n- * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n- * License v3.0 only\", or the \"Server Side Public License, v 1\".\n- */\n-\n-package org.elasticsearch.index.mapper;\n-\n-import org.apache.lucene.index.BinaryDocValues;\n-import org.apache.lucene.index.ByteVectorValues;\n-import org.apache.lucene.index.DocValues;\n-import org.apache.lucene.index.FloatVectorValues;\n-import org.apache.lucene.index.KnnVectorValues;\n-import org.apache.lucene.index.LeafReaderContext;\n-import org.apache.lucene.index.NumericDocValues;\n-import org.apache.lucene.index.SortedDocValues;\n-import org.apache.lucene.index.SortedNumericDocValues;\n-import org.apache.lucene.index.SortedSetDocValues;\n-import org.apache.lucene.util.BytesRef;\n-import org.elasticsearch.common.io.stream.ByteArrayStreamInput;\n-import org.elasticsearch.index.IndexVersion;\n-import org.elasticsearch.index.mapper.BlockLoader.BlockFactory;\n-import org.elasticsearch.index.mapper.BlockLoader.BooleanBuilder;\n-import org.elasticsearch.index.mapper.BlockLoader.Builder;\n-import org.elasticsearch.index.mapper.BlockLoader.BytesRefBuilder;\n-import org.elasticsearch.index.mapper.BlockLoader.Docs;\n-import org.elasticsearch.index.mapper.BlockLoader.DoubleBuilder;\n-import org.elasticsearch.index.mapper.BlockLoader.IntBuilder;\n-import org.elasticsearch.index.mapper.BlockLoader.LongBuilder;\n-import org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper;\n-import org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper.ElementType;\n-import org.elasticsearch.index.mapper.vectors.VectorEncoderDecoder;\n-import org.elasticsearch.search.fetch.StoredFieldsSpec;\n-\n-import java.io.IOException;\n-\n-import static org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper.COSINE_MAGNITUDE_FIELD_SUFFIX;\n-\n-/**\n- * A reader that supports reading doc-values from a Lucene segment in Block fashion.\n- */\n-public abstract class BlockDocValuesReader implements BlockLoader.AllReader {\n-    private final Thread creationThread;\n-\n-    public BlockDocValuesReader() {\n-        this.creationThread = Thread.currentThread();\n-    }\n-\n-    protected abstract int docId();\n-\n-    /**\n-     * Checks if the reader can be used to read a range documents starting with the given docID by the current thread.\n-     */\n-    @Override\n-    public final boolean canReuse(int startingDocID) {\n-        return creationThread == Thread.currentThread() && docId() <= startingDocID;\n-    }\n-\n-    @Override\n-    public abstract String toString();\n-\n-    public abstract static class DocValuesBlockLoader implements BlockLoader {\n-        public abstract AllReader reader(LeafReaderContext context) throws IOException;\n-\n-        @Override\n-        public final ColumnAtATimeReader columnAtATimeReader(LeafReaderContext context) throws IOException {\n-            return reader(context);\n-        }\n-\n-        @Override\n-        public final RowStrideReader rowStrideReader(LeafReaderContext context) throws IOException {\n-            return reader(context);\n-        }\n-\n-        @Override\n-        public final StoredFieldsSpec rowStrideStoredFieldSpec() {\n-            return StoredFieldsSpec.NO_REQUIREMENTS;\n-        }\n-\n-        @Override\n-        public boolean supportsOrdinals() {\n-            return false;\n-        }\n-\n-        @Override\n-        public SortedSetDocValues ordinals(LeafReaderContext context) throws IOException {\n-            throw new UnsupportedOperationException();\n-        }\n-\n-    }\n-\n-    public static class LongsBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public LongsBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.longs(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n-            if (docValues != null) {\n-                NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonLongs(singleton);\n-                }\n-                return new Longs(docValues);\n-            }\n-            NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonLongs(singleton);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    // Used for testing.\n-    interface NumericDocValuesAccessor {\n-        NumericDocValues numericDocValues();\n-    }\n-\n-    static class SingletonLongs extends BlockDocValuesReader implements NumericDocValuesAccessor {\n-        final NumericDocValues numericDocValues;\n-\n-        SingletonLongs(NumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (numericDocValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n-                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, null, false);\n-                if (result != null) {\n-                    return result;\n-                }\n-            }\n-            try (BlockLoader.LongBuilder builder = factory.longsFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (numericDocValues.advanceExact(doc)) {\n-                        builder.appendLong(numericDocValues.longValue());\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            BlockLoader.LongBuilder blockBuilder = (BlockLoader.LongBuilder) builder;\n-            if (numericDocValues.advanceExact(docId)) {\n-                blockBuilder.appendLong(numericDocValues.longValue());\n-            } else {\n-                blockBuilder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonLongs\";\n-        }\n-\n-        @Override\n-        public NumericDocValues numericDocValues() {\n-            return numericDocValues;\n-        }\n-    }\n-\n-    static class Longs extends BlockDocValuesReader {\n-        private final SortedNumericDocValues numericDocValues;\n-\n-        Longs(SortedNumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.LongBuilder builder = factory.longsFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (LongBuilder) builder);\n-        }\n-\n-        private void read(int doc, LongBuilder builder) throws IOException {\n-            if (false == numericDocValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = numericDocValues.docValueCount();\n-            if (count == 1) {\n-                builder.appendLong(numericDocValues.nextValue());\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendLong(numericDocValues.nextValue());\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Longs\";\n-        }\n-    }\n-\n-    public static class IntsBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public IntsBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.ints(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n-            if (docValues != null) {\n-                NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonInts(singleton);\n-                }\n-                return new Ints(docValues);\n-            }\n-            NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonInts(singleton);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    static class SingletonInts extends BlockDocValuesReader implements NumericDocValuesAccessor {\n-        private final NumericDocValues numericDocValues;\n-\n-        SingletonInts(NumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (numericDocValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n-                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, null, true);\n-                if (result != null) {\n-                    return result;\n-                }\n-            }\n-            try (BlockLoader.IntBuilder builder = factory.intsFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (numericDocValues.advanceExact(doc)) {\n-                        builder.appendInt(Math.toIntExact(numericDocValues.longValue()));\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            IntBuilder blockBuilder = (IntBuilder) builder;\n-            if (numericDocValues.advanceExact(docId)) {\n-                blockBuilder.appendInt(Math.toIntExact(numericDocValues.longValue()));\n-            } else {\n-                blockBuilder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonInts\";\n-        }\n-\n-        @Override\n-        public NumericDocValues numericDocValues() {\n-            return numericDocValues;\n-        }\n-    }\n-\n-    static class Ints extends BlockDocValuesReader {\n-        private final SortedNumericDocValues numericDocValues;\n-\n-        Ints(SortedNumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.IntBuilder builder = factory.intsFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (IntBuilder) builder);\n-        }\n-\n-        private void read(int doc, IntBuilder builder) throws IOException {\n-            if (false == numericDocValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = numericDocValues.docValueCount();\n-            if (count == 1) {\n-                builder.appendInt(Math.toIntExact(numericDocValues.nextValue()));\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendInt(Math.toIntExact(numericDocValues.nextValue()));\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Ints\";\n-        }\n-    }\n-\n-    /**\n-     * Convert from the stored {@link long} into the {@link double} to load.\n-     * Sadly, this will go megamorphic pretty quickly and slow us down,\n-     * but it gets the job done for now.\n-     */\n-    public interface ToDouble {\n-        double convert(long v);\n-    }\n-\n-    public static class DoublesBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-        private final ToDouble toDouble;\n-\n-        public DoublesBlockLoader(String fieldName, ToDouble toDouble) {\n-            this.fieldName = fieldName;\n-            this.toDouble = toDouble;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.doubles(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n-            if (docValues != null) {\n-                NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonDoubles(singleton, toDouble);\n-                }\n-                return new Doubles(docValues, toDouble);\n-            }\n-            NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonDoubles(singleton, toDouble);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    static class SingletonDoubles extends BlockDocValuesReader implements NumericDocValuesAccessor {\n-        private final NumericDocValues docValues;\n-        private final ToDouble toDouble;\n-\n-        SingletonDoubles(NumericDocValues docValues, ToDouble toDouble) {\n-            this.docValues = docValues;\n-            this.toDouble = toDouble;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (docValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n-                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, toDouble, false);\n-                if (result != null) {\n-                    return result;\n-                }\n-            }\n-            try (BlockLoader.DoubleBuilder builder = factory.doublesFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (docValues.advanceExact(doc)) {\n-                        builder.appendDouble(toDouble.convert(docValues.longValue()));\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            DoubleBuilder blockBuilder = (DoubleBuilder) builder;\n-            if (docValues.advanceExact(docId)) {\n-                blockBuilder.appendDouble(toDouble.convert(docValues.longValue()));\n-            } else {\n-                blockBuilder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return docValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonDoubles\";\n-        }\n-\n-        @Override\n-        public NumericDocValues numericDocValues() {\n-            return docValues;\n-        }\n-    }\n-\n-    static class Doubles extends BlockDocValuesReader {\n-        private final SortedNumericDocValues docValues;\n-        private final ToDouble toDouble;\n-\n-        Doubles(SortedNumericDocValues docValues, ToDouble toDouble) {\n-            this.docValues = docValues;\n-            this.toDouble = toDouble;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.DoubleBuilder builder = factory.doublesFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (DoubleBuilder) builder);\n-        }\n-\n-        private void read(int doc, DoubleBuilder builder) throws IOException {\n-            if (false == docValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = docValues.docValueCount();\n-            if (count == 1) {\n-                builder.appendDouble(toDouble.convert(docValues.nextValue()));\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendDouble(toDouble.convert(docValues.nextValue()));\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return docValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Doubles\";\n-        }\n-    }\n-\n-    public static class DenseVectorBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-        private final int dimensions;\n-        private final DenseVectorFieldMapper.DenseVectorFieldType fieldType;\n-\n-        public DenseVectorBlockLoader(String fieldName, int dimensions, DenseVectorFieldMapper.DenseVectorFieldType fieldType) {\n-            this.fieldName = fieldName;\n-            this.dimensions = dimensions;\n-            this.fieldType = fieldType;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.denseVectors(expectedCount, dimensions);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            switch (fieldType.getElementType()) {\n-                case FLOAT -> {\n-                    FloatVectorValues floatVectorValues = context.reader().getFloatVectorValues(fieldName);\n-                    if (floatVectorValues != null) {\n-                        if (fieldType.isNormalized()) {\n-                            NumericDocValues magnitudeDocValues = context.reader()\n-                                .getNumericDocValues(fieldType.name() + COSINE_MAGNITUDE_FIELD_SUFFIX);\n-                            return new FloatDenseVectorNormalizedValuesBlockReader(floatVectorValues, dimensions, magnitudeDocValues);\n-                        }\n-                        return new FloatDenseVectorValuesBlockReader(floatVectorValues, dimensions);\n-                    }\n-                }\n-                case BYTE -> {\n-                    ByteVectorValues byteVectorValues = context.reader().getByteVectorValues(fieldName);\n-                    if (byteVectorValues != null) {\n-                        return new ByteDenseVectorValuesBlockReader(byteVectorValues, dimensions);\n-                    }\n-                }\n-                case BIT -> {\n-                    ByteVectorValues byteVectorValues = context.reader().getByteVectorValues(fieldName);\n-                    if (byteVectorValues != null) {\n-                        return new BitDenseVectorValuesBlockReader(byteVectorValues, dimensions);\n-                    }\n-                }\n-            }\n-\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    private abstract static class DenseVectorValuesBlockReader<T extends KnnVectorValues> extends BlockDocValuesReader {\n-\n-        protected final T vectorValues;\n-        protected final KnnVectorValues.DocIndexIterator iterator;\n-        protected final int dimensions;\n-\n-        DenseVectorValuesBlockReader(T vectorValues, int dimensions) {\n-            this.vectorValues = vectorValues;\n-            iterator = vectorValues.iterator();\n-            this.dimensions = dimensions;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            // Doubles from doc values ensures that the values are in order\n-            try (BlockLoader.FloatBuilder builder = factory.denseVectors(docs.count() - offset, dimensions)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    read(docs.get(i), builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BlockLoader.FloatBuilder) builder);\n-        }\n-\n-        private void read(int doc, BlockLoader.FloatBuilder builder) throws IOException {\n-            assertDimensions();\n-\n-            if (iterator.docID() > doc) {\n-                builder.appendNull();\n-            } else if (iterator.docID() == doc || iterator.advance(doc) == doc) {\n-                builder.beginPositionEntry();\n-                appendDoc(builder);\n-                builder.endPositionEntry();\n-            } else {\n-                builder.appendNull();\n-            }\n-        }\n-\n-        protected abstract void appendDoc(BlockLoader.FloatBuilder builder) throws IOException;\n-\n-        @Override\n-        public int docId() {\n-            return iterator.docID();\n-        }\n-\n-        protected void assertDimensions() {\n-            assert vectorValues.dimension() == dimensions\n-                : \"unexpected dimensions for vector value; expected \" + dimensions + \" but got \" + vectorValues.dimension();\n-        }\n-    }\n-\n-    private static class FloatDenseVectorValuesBlockReader extends DenseVectorValuesBlockReader<FloatVectorValues> {\n-\n-        FloatDenseVectorValuesBlockReader(FloatVectorValues floatVectorValues, int dimensions) {\n-            super(floatVectorValues, dimensions);\n-        }\n-\n-        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n-            float[] floats = vectorValues.vectorValue(iterator.index());\n-            for (float aFloat : floats) {\n-                builder.appendFloat(aFloat);\n-            }\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.FloatDenseVectorValuesBlockReader\";\n-        }\n-    }\n-\n-    private static class FloatDenseVectorNormalizedValuesBlockReader extends DenseVectorValuesBlockReader<FloatVectorValues> {\n-        private final NumericDocValues magnitudeDocValues;\n-\n-        FloatDenseVectorNormalizedValuesBlockReader(\n-            FloatVectorValues floatVectorValues,\n-            int dimensions,\n-            NumericDocValues magnitudeDocValues\n-        ) {\n-            super(floatVectorValues, dimensions);\n-            this.magnitudeDocValues = magnitudeDocValues;\n-        }\n-\n-        @Override\n-        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n-            float magnitude = 1.0f;\n-            // If all vectors are normalized, no doc values will be present. The vector may be normalized already, so we may not have a\n-            // stored magnitude for all docs\n-            if ((magnitudeDocValues != null) && magnitudeDocValues.advanceExact(iterator.docID())) {\n-                magnitude = Float.intBitsToFloat((int) magnitudeDocValues.longValue());\n-            }\n-            float[] floats = vectorValues.vectorValue(iterator.index());\n-            for (float aFloat : floats) {\n-                builder.appendFloat(aFloat * magnitude);\n-            }\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.FloatDenseVectorNormalizedValuesBlockReader\";\n-        }\n-    }\n-\n-    private static class ByteDenseVectorValuesBlockReader extends DenseVectorValuesBlockReader<ByteVectorValues> {\n-        ByteDenseVectorValuesBlockReader(ByteVectorValues floatVectorValues, int dimensions) {\n-            super(floatVectorValues, dimensions);\n-        }\n-\n-        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n-            byte[] bytes = vectorValues.vectorValue(iterator.index());\n-            for (byte aFloat : bytes) {\n-                builder.appendFloat(aFloat);\n-            }\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.ByteDenseVectorValuesBlockReader\";\n-        }\n-    }\n-\n-    private static class BitDenseVectorValuesBlockReader extends ByteDenseVectorValuesBlockReader {\n-\n-        BitDenseVectorValuesBlockReader(ByteVectorValues floatVectorValues, int dimensions) {\n-            super(floatVectorValues, dimensions);\n-        }\n-\n-        @Override\n-        protected void assertDimensions() {\n-            assert vectorValues.dimension() * Byte.SIZE == dimensions\n-                : \"unexpected dimensions for vector value; expected \" + dimensions + \" but got \" + vectorValues.dimension() * Byte.SIZE;\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.BitDenseVectorValuesBlockReader\";\n-        }\n-    }\n-\n-    public static class BytesRefsFromOrdsBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public BytesRefsFromOrdsBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public BytesRefBuilder builder(BlockFactory factory, int expectedCount) {\n-            return factory.bytesRefs(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedSetDocValues docValues = context.reader().getSortedSetDocValues(fieldName);\n-            if (docValues != null) {\n-                SortedDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonOrdinals(singleton);\n-                }\n-                return new Ordinals(docValues);\n-            }\n-            SortedDocValues singleton = context.reader().getSortedDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonOrdinals(singleton);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-\n-        @Override\n-        public boolean supportsOrdinals() {\n-            return true;\n-        }\n-\n-        @Override\n-        public SortedSetDocValues ordinals(LeafReaderContext context) throws IOException {\n-            return DocValues.getSortedSet(context.reader(), fieldName);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BytesRefsFromOrds[\" + fieldName + \"]\";\n-        }\n-    }\n-\n-    private static class SingletonOrdinals extends BlockDocValuesReader {\n-        private final SortedDocValues ordinals;\n-\n-        SingletonOrdinals(SortedDocValues ordinals) {\n-            this.ordinals = ordinals;\n-        }\n-\n-        private BlockLoader.Block readSingleDoc(BlockFactory factory, int docId) throws IOException {\n-            if (ordinals.advanceExact(docId)) {\n-                BytesRef v = ordinals.lookupOrd(ordinals.ordValue());\n-                // the returned BytesRef can be reused\n-                return factory.constantBytes(BytesRef.deepCopyOf(v), 1);\n-            } else {\n-                return factory.constantNulls(1);\n-            }\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (docs.count() - offset == 1) {\n-                return readSingleDoc(factory, docs.get(offset));\n-            }\n-            if (ordinals instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n-                BlockLoader.Block block = direct.tryRead(factory, docs, offset, nullsFiltered, null, false);\n-                if (block != null) {\n-                    return block;\n-                }\n-            }\n-            try (var builder = factory.singletonOrdinalsBuilder(ordinals, docs.count() - offset, false)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (ordinals.advanceExact(doc)) {\n-                        builder.appendOrd(ordinals.ordValue());\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            if (ordinals.advanceExact(docId)) {\n-                ((BytesRefBuilder) builder).appendBytesRef(ordinals.lookupOrd(ordinals.ordValue()));\n-            } else {\n-                builder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return ordinals.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonOrdinals\";\n-        }\n-    }\n-\n-    private static class Ordinals extends BlockDocValuesReader {\n-        private final SortedSetDocValues ordinals;\n-\n-        Ordinals(SortedSetDocValues ordinals) {\n-            this.ordinals = ordinals;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            if (docs.count() - offset == 1) {\n-                return readSingleDoc(factory, docs.get(offset));\n-            }\n-            try (var builder = factory.sortedSetOrdinalsBuilder(ordinals, docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (doc < ordinals.docID()) {\n-                        throw new IllegalStateException(\"docs within same block must be in order\");\n-                    }\n-                    if (ordinals.advanceExact(doc) == false) {\n-                        builder.appendNull();\n-                        continue;\n-                    }\n-                    int count = ordinals.docValueCount();\n-                    if (count == 1) {\n-                        builder.appendOrd(Math.toIntExact(ordinals.nextOrd()));\n-                    } else {\n-                        builder.beginPositionEntry();\n-                        for (int c = 0; c < count; c++) {\n-                            builder.appendOrd(Math.toIntExact(ordinals.nextOrd()));\n-                        }\n-                        builder.endPositionEntry();\n-                    }\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BytesRefBuilder) builder);\n-        }\n-\n-        private BlockLoader.Block readSingleDoc(BlockFactory factory, int docId) throws IOException {\n-            if (ordinals.advanceExact(docId) == false) {\n-                return factory.constantNulls(1);\n-            }\n-            int count = ordinals.docValueCount();\n-            if (count == 1) {\n-                BytesRef v = ordinals.lookupOrd(ordinals.nextOrd());\n-                return factory.constantBytes(BytesRef.deepCopyOf(v), 1);\n-            }\n-            try (var builder = factory.bytesRefsFromDocValues(count)) {\n-                builder.beginPositionEntry();\n-                for (int c = 0; c < count; c++) {\n-                    BytesRef v = ordinals.lookupOrd(ordinals.nextOrd());\n-                    builder.appendBytesRef(v);\n-                }\n-                builder.endPositionEntry();\n-                return builder.build();\n-            }\n-        }\n-\n-        private void read(int docId, BytesRefBuilder builder) throws IOException {\n-            if (false == ordinals.advanceExact(docId)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = ordinals.docValueCount();\n-            if (count == 1) {\n-                builder.appendBytesRef(ordinals.lookupOrd(ordinals.nextOrd()));\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendBytesRef(ordinals.lookupOrd(ordinals.nextOrd()));\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return ordinals.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Ordinals\";\n-        }\n-    }\n-\n-    public static class BytesRefsFromCustomBinaryBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public BytesRefsFromCustomBinaryBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.bytesRefs(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            BinaryDocValues docValues = context.reader().getBinaryDocValues(fieldName);\n-            if (docValues == null) {\n-                return new ConstantNullsReader();\n-            }\n-            return new BytesRefsFromCustomBinary(docValues);\n-        }\n-    }\n-\n-    abstract static class AbstractBytesRefsFromBinary extends BlockDocValuesReader {\n-        protected final BinaryDocValues docValues;\n-\n-        AbstractBytesRefsFromBinary(BinaryDocValues docValues) {\n-            this.docValues = docValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.BytesRefBuilder builder = factory.bytesRefs(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BytesRefBuilder) builder);\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return docValues.docID();\n-        }\n-\n-        abstract void read(int docId, BytesRefBuilder builder) throws IOException;\n-    }\n-\n-    /**\n-     * Read BinaryDocValues encoded by {@link BinaryFieldMapper.CustomBinaryDocValuesField}\n-     */\n-    static class BytesRefsFromCustomBinary extends AbstractBytesRefsFromBinary {\n-        private final ByteArrayStreamInput in = new ByteArrayStreamInput();\n-        private final BytesRef scratch = new BytesRef();\n-\n-        BytesRefsFromCustomBinary(BinaryDocValues docValues) {\n-            super(docValues);\n-        }\n-\n-        @Override\n-        void read(int doc, BytesRefBuilder builder) throws IOException {\n-            if (false == docValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            BytesRef bytes = docValues.binaryValue();\n-            assert bytes.length > 0;\n-            in.reset(bytes.bytes, bytes.offset, bytes.length);\n-            int count = in.readVInt();\n-            scratch.bytes = bytes.bytes;\n-\n-            if (count == 1) {\n-                scratch.length = in.readVInt();\n-                scratch.offset = in.getPosition();\n-                builder.appendBytesRef(scratch);\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                scratch.length = in.readVInt();\n-                scratch.offset = in.getPosition();\n-                in.setPosition(scratch.offset + scratch.length);\n-                builder.appendBytesRef(scratch);\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.BytesCustom\";\n-        }\n-    }\n-\n-    /**\n-     * Read BinaryDocValues with no additional structure in the BytesRefs.\n-     * Each BytesRef from the doc values maps directly to a value in the block loader.\n-     */\n-    public static class BytesRefsFromBinary extends AbstractBytesRefsFromBinary {\n-        public BytesRefsFromBinary(BinaryDocValues docValues) {\n-            super(docValues);\n-        }\n-\n-        @Override\n-        void read(int doc, BytesRefBuilder builder) throws IOException {\n-            if (false == docValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            BytesRef bytes = docValues.binaryValue();\n-            builder.appendBytesRef(bytes);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Bytes\";\n-        }\n-    }\n-\n-    public static class DenseVectorFromBinaryBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-        private final int dims;\n-        private final IndexVersion indexVersion;\n-        private final ElementType elementType;\n-\n-        public DenseVectorFromBinaryBlockLoader(String fieldName, int dims, IndexVersion indexVersion, ElementType elementType) {\n-            this.fieldName = fieldName;\n-            this.dims = dims;\n-            this.indexVersion = indexVersion;\n-            this.elementType = elementType;\n-        }\n-\n-        @Override\n-        public Builder builder(BlockFactory factory, int expectedCount) {\n-            return factory.denseVectors(expectedCount, dims);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            BinaryDocValues docValues = context.reader().getBinaryDocValues(fieldName);\n-            if (docValues == null) {\n-                return new ConstantNullsReader();\n-            }\n-            return switch (elementType) {\n-                case FLOAT -> new FloatDenseVectorFromBinary(docValues, dims, indexVersion);\n-                case BYTE -> new ByteDenseVectorFromBinary(docValues, dims, indexVersion);\n-                case BIT -> new BitDenseVectorFromBinary(docValues, dims, indexVersion);\n-            };\n-        }\n-    }\n-\n-    // Abstract base for dense vector readers\n-    private abstract static class AbstractDenseVectorFromBinary<T> extends BlockDocValuesReader {\n-        protected final BinaryDocValues docValues;\n-        protected final IndexVersion indexVersion;\n-        protected final int dimensions;\n-        protected final T scratch;\n-\n-        AbstractDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion, T scratch) {\n-            this.docValues = docValues;\n-            this.indexVersion = indexVersion;\n-            this.dimensions = dims;\n-            this.scratch = scratch;\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return docValues.docID();\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BlockLoader.FloatBuilder) builder);\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.FloatBuilder builder = factory.denseVectors(docs.count() - offset, dimensions)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        private void read(int doc, BlockLoader.FloatBuilder builder) throws IOException {\n-            if (docValues.advanceExact(doc) == false) {\n-                builder.appendNull();\n-                return;\n-            }\n-            BytesRef bytesRef = docValues.binaryValue();\n-            assert bytesRef.length > 0;\n-            decodeDenseVector(bytesRef, scratch);\n-\n-            builder.beginPositionEntry();\n-            writeScratchToBuilder(scratch, builder);\n-            builder.endPositionEntry();\n-        }\n-\n-        protected abstract void decodeDenseVector(BytesRef bytesRef, T scratch);\n-\n-        protected abstract void writeScratchToBuilder(T scratch, BlockLoader.FloatBuilder builder);\n-    }\n-\n-    private static class FloatDenseVectorFromBinary extends AbstractDenseVectorFromBinary<float[]> {\n-        FloatDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n-            super(docValues, dims, indexVersion, new float[dims]);\n-        }\n-\n-        @Override\n-        protected void writeScratchToBuilder(float[] scratch, BlockLoader.FloatBuilder builder) {\n-            for (float value : scratch) {\n-                builder.appendFloat(value);\n-            }\n-        }\n-\n-        @Override\n-        protected void decodeDenseVector(BytesRef bytesRef, float[] scratch) {\n-            VectorEncoderDecoder.decodeDenseVector(indexVersion, bytesRef, scratch);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"FloatDenseVectorFromBinary.Bytes\";\n-        }\n-    }\n-\n-    private static class ByteDenseVectorFromBinary extends AbstractDenseVectorFromBinary<byte[]> {\n-        ByteDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n-            this(docValues, dims, indexVersion, dims);\n-        }\n-\n-        protected ByteDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion, int readScratchSize) {\n-            super(docValues, dims, indexVersion, new byte[readScratchSize]);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"ByteDenseVectorFromBinary.Bytes\";\n-        }\n-\n-        protected void writeScratchToBuilder(byte[] scratch, BlockLoader.FloatBuilder builder) {\n-            for (byte value : scratch) {\n-                builder.appendFloat(value);\n-            }\n-        }\n-\n-        protected void decodeDenseVector(BytesRef bytesRef, byte[] scratch) {\n-            VectorEncoderDecoder.decodeDenseVector(indexVersion, bytesRef, scratch);\n-        }\n-    }\n-\n-    private static class BitDenseVectorFromBinary extends ByteDenseVectorFromBinary {\n-        BitDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n-            super(docValues, dims, indexVersion, dims / Byte.SIZE);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BitDenseVectorFromBinary.Bytes\";\n-        }\n-    }\n-\n-    public static class BooleansBlockLoader extends DocValuesBlockLoader {\n-        private final String fieldName;\n-\n-        public BooleansBlockLoader(String fieldName) {\n-            this.fieldName = fieldName;\n-        }\n-\n-        @Override\n-        public BooleanBuilder builder(BlockFactory factory, int expectedCount) {\n-            return factory.booleans(expectedCount);\n-        }\n-\n-        @Override\n-        public AllReader reader(LeafReaderContext context) throws IOException {\n-            SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n-            if (docValues != null) {\n-                NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n-                if (singleton != null) {\n-                    return new SingletonBooleans(singleton);\n-                }\n-                return new Booleans(docValues);\n-            }\n-            NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n-            if (singleton != null) {\n-                return new SingletonBooleans(singleton);\n-            }\n-            return new ConstantNullsReader();\n-        }\n-    }\n-\n-    private static class SingletonBooleans extends BlockDocValuesReader {\n-        private final NumericDocValues numericDocValues;\n-\n-        SingletonBooleans(NumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.BooleanBuilder builder = factory.booleansFromDocValues(docs.count() - offset)) {\n-                int lastDoc = -1;\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    if (doc < lastDoc) {\n-                        throw new IllegalStateException(\"docs within same block must be in order\");\n-                    }\n-                    if (numericDocValues.advanceExact(doc)) {\n-                        builder.appendBoolean(numericDocValues.longValue() != 0);\n-                    } else {\n-                        builder.appendNull();\n-                    }\n-                    lastDoc = doc;\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            BooleanBuilder blockBuilder = (BooleanBuilder) builder;\n-            if (numericDocValues.advanceExact(docId)) {\n-                blockBuilder.appendBoolean(numericDocValues.longValue() != 0);\n-            } else {\n-                blockBuilder.appendNull();\n-            }\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.SingletonBooleans\";\n-        }\n-    }\n-\n-    private static class Booleans extends BlockDocValuesReader {\n-        private final SortedNumericDocValues numericDocValues;\n-\n-        Booleans(SortedNumericDocValues numericDocValues) {\n-            this.numericDocValues = numericDocValues;\n-        }\n-\n-        @Override\n-        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n-            try (BlockLoader.BooleanBuilder builder = factory.booleansFromDocValues(docs.count() - offset)) {\n-                for (int i = offset; i < docs.count(); i++) {\n-                    int doc = docs.get(i);\n-                    read(doc, builder);\n-                }\n-                return builder.build();\n-            }\n-        }\n-\n-        @Override\n-        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n-            read(docId, (BooleanBuilder) builder);\n-        }\n-\n-        private void read(int doc, BooleanBuilder builder) throws IOException {\n-            if (false == numericDocValues.advanceExact(doc)) {\n-                builder.appendNull();\n-                return;\n-            }\n-            int count = numericDocValues.docValueCount();\n-            if (count == 1) {\n-                builder.appendBoolean(numericDocValues.nextValue() != 0);\n-                return;\n-            }\n-            builder.beginPositionEntry();\n-            for (int v = 0; v < count; v++) {\n-                builder.appendBoolean(numericDocValues.nextValue() != 0);\n-            }\n-            builder.endPositionEntry();\n-        }\n-\n-        @Override\n-        public int docId() {\n-            return numericDocValues.docID();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"BlockDocValuesReader.Booleans\";\n-        }\n-    }\n-}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/BlockLoader.java b/server/src/main/java/org/elasticsearch/index/mapper/BlockLoader.java\nindex 5f2bd15abaa34..1186b481b2208 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/BlockLoader.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/BlockLoader.java\n@@ -15,6 +15,7 @@\n import org.apache.lucene.util.BytesRef;\n import org.elasticsearch.core.Nullable;\n import org.elasticsearch.core.Releasable;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.search.fetch.StoredFieldsSpec;\n import org.elasticsearch.search.lookup.Source;\n \ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/BlockStoredFieldsReader.java b/server/src/main/java/org/elasticsearch/index/mapper/BlockStoredFieldsReader.java\nindex a1f5dc4381f50..12584577b561a 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/BlockStoredFieldsReader.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/BlockStoredFieldsReader.java\n@@ -14,6 +14,7 @@\n import org.apache.lucene.index.SortedSetDocValues;\n import org.apache.lucene.util.BytesRef;\n import org.elasticsearch.index.mapper.BlockLoader.BytesRefBuilder;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.search.fetch.StoredFieldsSpec;\n \n import java.io.IOException;\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/BooleanFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/BooleanFieldMapper.java\nindex 804c5157bd9ce..e9fdf24133ecf 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/BooleanFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/BooleanFieldMapper.java\n@@ -35,6 +35,7 @@\n import org.elasticsearch.index.fielddata.IndexNumericFieldData.NumericType;\n import org.elasticsearch.index.fielddata.SourceValueFetcherSortedBooleanIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BooleansBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.BooleanFieldScript;\n import org.elasticsearch.script.Script;\n@@ -351,7 +352,7 @@ public Boolean valueForDisplay(Object value) {\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues()) {\n-                return new BlockDocValuesReader.BooleansBlockLoader(name());\n+                return new BooleansBlockLoader(name());\n             }\n \n             // Multi fields don't have fallback synthetic source.\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/BooleanScriptBlockDocValuesReader.java b/server/src/main/java/org/elasticsearch/index/mapper/BooleanScriptBlockDocValuesReader.java\nindex aff36af3948a9..3ce6bdcf9bea6 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/BooleanScriptBlockDocValuesReader.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/BooleanScriptBlockDocValuesReader.java\n@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.BooleanFieldScript;\n \n import java.io.IOException;\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/DateFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/DateFieldMapper.java\nindex d16045e709d15..20f1c0dadd592 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/DateFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/DateFieldMapper.java\n@@ -46,6 +46,7 @@\n import org.elasticsearch.index.fielddata.SortedNumericLongValues;\n import org.elasticsearch.index.fielddata.SourceValueFetcherSortedNumericIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.DateRangeIncludingNowQuery;\n import org.elasticsearch.index.query.QueryRewriteContext;\n import org.elasticsearch.index.query.SearchExecutionContext;\n@@ -927,7 +928,7 @@ public Function<byte[], Number> pointReaderIfPossible() {\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues()) {\n-                return new BlockDocValuesReader.LongsBlockLoader(name());\n+                return new LongsBlockLoader(name());\n             }\n \n             // Multi fields don't have fallback synthetic source.\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/DateScriptBlockDocValuesReader.java b/server/src/main/java/org/elasticsearch/index/mapper/DateScriptBlockDocValuesReader.java\nindex 6f56c90fa67e0..b14fd65714425 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/DateScriptBlockDocValuesReader.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/DateScriptBlockDocValuesReader.java\n@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.DateFieldScript;\n \n import java.io.IOException;\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/DoubleScriptBlockDocValuesReader.java b/server/src/main/java/org/elasticsearch/index/mapper/DoubleScriptBlockDocValuesReader.java\nindex aeb9f8856527f..8f40f6f1b580b 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/DoubleScriptBlockDocValuesReader.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/DoubleScriptBlockDocValuesReader.java\n@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.DoubleFieldScript;\n \n import java.io.IOException;\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/GeoPointFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/GeoPointFieldMapper.java\nindex 958439bddd329..9557d5fbf2936 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/GeoPointFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/GeoPointFieldMapper.java\n@@ -42,6 +42,8 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.SourceValueFetcherMultiGeoPointIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.LatLonPointIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.GeoPointFieldScript;\n import org.elasticsearch.script.Script;\n@@ -553,7 +555,7 @@ public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             // load from doc values\n             if (hasDocValues()) {\n                 if (blContext.fieldExtractPreference() == DOC_VALUES) {\n-                    return new BlockDocValuesReader.LongsBlockLoader(name());\n+                    return new LongsBlockLoader(name());\n                 } else if (blContext.fieldExtractPreference() == NONE && isSyntheticSource) {\n                     // when the preference is not explicitly set to DOC_VALUES, we expect a BytesRef -> see PlannerUtils.toElementType()\n                     return new BytesRefFromLongsBlockLoader(name());\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/IgnoredFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/IgnoredFieldMapper.java\nindex d82c76e4d37a3..70b43d202b3d6 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/IgnoredFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/IgnoredFieldMapper.java\n@@ -22,6 +22,7 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.field.KeywordDocValuesField;\n import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n@@ -97,7 +98,7 @@ public String typeName() {\n \n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n-            return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(NAME);\n+            return new BytesRefsFromOrdsBlockLoader(NAME);\n         }\n \n         @Override\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/IpFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/IpFieldMapper.java\nindex 644ab73a0217b..b47928d48e83a 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/IpFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/IpFieldMapper.java\n@@ -33,6 +33,7 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.IpFieldScript;\n import org.elasticsearch.script.Script;\n@@ -469,7 +470,7 @@ public static Query rangeQuery(\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSource)) {\n-                return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(name());\n+                return new BytesRefsFromOrdsBlockLoader(name());\n             }\n \n             if (isStored()) {\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/IpScriptBlockDocValuesReader.java b/server/src/main/java/org/elasticsearch/index/mapper/IpScriptBlockDocValuesReader.java\nindex 75dbb3e2ce223..36595d0805b3d 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/IpScriptBlockDocValuesReader.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/IpScriptBlockDocValuesReader.java\n@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.IpFieldScript;\n \n import java.io.IOException;\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/KeywordFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/KeywordFieldMapper.java\nindex 13b5bf71ebe61..57c0de6c82983 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/KeywordFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/KeywordFieldMapper.java\n@@ -55,6 +55,7 @@\n import org.elasticsearch.index.fielddata.SourceValueFetcherSortedBinaryIndexFieldData;\n import org.elasticsearch.index.fielddata.StoredFieldSortedBinaryIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.AutomatonQueryWithDescription;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.index.similarity.SimilarityProvider;\n@@ -812,7 +813,7 @@ NamedAnalyzer normalizer() {\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSourceEnabled())) {\n-                return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(name());\n+                return new BytesRefsFromOrdsBlockLoader(name());\n             }\n             if (isStored()) {\n                 return new BlockStoredFieldsReader.BytesFromBytesRefsBlockLoader(name());\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/KeywordScriptBlockDocValuesReader.java b/server/src/main/java/org/elasticsearch/index/mapper/KeywordScriptBlockDocValuesReader.java\nindex bb6e7c22bd8b2..7f98da1a6b6d4 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/KeywordScriptBlockDocValuesReader.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/KeywordScriptBlockDocValuesReader.java\n@@ -11,6 +11,7 @@\n \n import org.apache.lucene.index.LeafReaderContext;\n import org.apache.lucene.util.BytesRefBuilder;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.StringFieldScript;\n \n import java.io.IOException;\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/LongScriptBlockDocValuesReader.java b/server/src/main/java/org/elasticsearch/index/mapper/LongScriptBlockDocValuesReader.java\nindex 950bb4e8388e6..e2b94083f0c9c 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/LongScriptBlockDocValuesReader.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/LongScriptBlockDocValuesReader.java\n@@ -10,6 +10,7 @@\n package org.elasticsearch.index.mapper;\n \n import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.script.LongFieldScript;\n \n import java.io.IOException;\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/NumberFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/NumberFieldMapper.java\nindex 46098f22bfc7a..3c6d1c68553e4 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/NumberFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/NumberFieldMapper.java\n@@ -47,6 +47,9 @@\n import org.elasticsearch.index.fielddata.plain.SortedDoublesIndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n import org.elasticsearch.index.mapper.TimeSeriesParams.MetricType;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DoublesBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.IntsBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.DoubleFieldScript;\n import org.elasticsearch.script.LongFieldScript;\n@@ -491,7 +494,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.DoublesBlockLoader(fieldName, l -> HalfFloatPoint.sortableShortToHalfFloat((short) l));\n+                return new DoublesBlockLoader(fieldName, l -> HalfFloatPoint.sortableShortToHalfFloat((short) l));\n             }\n \n             @Override\n@@ -685,7 +688,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.DoublesBlockLoader(fieldName, l -> NumericUtils.sortableIntToFloat((int) l));\n+                return new DoublesBlockLoader(fieldName, l -> NumericUtils.sortableIntToFloat((int) l));\n             }\n \n             @Override\n@@ -845,7 +848,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.DoublesBlockLoader(fieldName, NumericUtils::sortableLongToDouble);\n+                return new DoublesBlockLoader(fieldName, NumericUtils::sortableLongToDouble);\n             }\n \n             @Override\n@@ -973,7 +976,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.IntsBlockLoader(fieldName);\n+                return new IntsBlockLoader(fieldName);\n             }\n \n             @Override\n@@ -1101,7 +1104,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.IntsBlockLoader(fieldName);\n+                return new IntsBlockLoader(fieldName);\n             }\n \n             @Override\n@@ -1303,7 +1306,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.IntsBlockLoader(fieldName);\n+                return new IntsBlockLoader(fieldName);\n             }\n \n             @Override\n@@ -1465,7 +1468,7 @@ public void writeValue(XContentBuilder b, long value) throws IOException {\n \n             @Override\n             BlockLoader blockLoaderFromDocValues(String fieldName) {\n-                return new BlockDocValuesReader.LongsBlockLoader(fieldName);\n+                return new LongsBlockLoader(fieldName);\n             }\n \n             @Override\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/TimeSeriesIdFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/TimeSeriesIdFieldMapper.java\nindex 79a3342d1e4a4..953d94b2624e3 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/TimeSeriesIdFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/TimeSeriesIdFieldMapper.java\n@@ -27,6 +27,7 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.ScriptDocValues;\n import org.elasticsearch.index.fielddata.plain.SortedOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.field.DelegateDocValuesField;\n import org.elasticsearch.search.DocValueFormat;\n@@ -150,7 +151,7 @@ public Object valueForDisplay(Object value) {\n \n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n-            return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(name());\n+            return new BytesRefsFromOrdsBlockLoader(name());\n         }\n     }\n \ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/VersionFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/VersionFieldMapper.java\nindex 072e845a155ec..e05f21f2fbea0 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/VersionFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/VersionFieldMapper.java\n@@ -16,6 +16,7 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.IndexNumericFieldData.NumericType;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.QueryShardException;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.field.VersionDocValuesField;\n@@ -66,7 +67,7 @@ public ValueFetcher valueFetcher(SearchExecutionContext context, String format)\n \n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n-            return new BlockDocValuesReader.LongsBlockLoader(name());\n+            return new LongsBlockLoader(name());\n         }\n \n         @Override\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BlockDocValuesReader.java b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BlockDocValuesReader.java\nnew file mode 100644\nindex 0000000000000..735cf598b502e\n--- /dev/null\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BlockDocValuesReader.java\n@@ -0,0 +1,86 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.search.fetch.StoredFieldsSpec;\n+\n+import java.io.IOException;\n+\n+/**\n+ * A reader that supports reading doc-values from a Lucene segment in Block fashion.\n+ */\n+public abstract class BlockDocValuesReader implements BlockLoader.AllReader {\n+    private final Thread creationThread;\n+\n+    public BlockDocValuesReader() {\n+        this.creationThread = Thread.currentThread();\n+    }\n+\n+    protected abstract int docId();\n+\n+    /**\n+     * Checks if the reader can be used to read a range documents starting with the given docID by the current thread.\n+     */\n+    @Override\n+    public final boolean canReuse(int startingDocID) {\n+        return creationThread == Thread.currentThread() && docId() <= startingDocID;\n+    }\n+\n+    @Override\n+    public abstract String toString();\n+\n+    public abstract static class DocValuesBlockLoader implements BlockLoader {\n+        public abstract AllReader reader(LeafReaderContext context) throws IOException;\n+\n+        @Override\n+        public final ColumnAtATimeReader columnAtATimeReader(LeafReaderContext context) throws IOException {\n+            return reader(context);\n+        }\n+\n+        @Override\n+        public final RowStrideReader rowStrideReader(LeafReaderContext context) throws IOException {\n+            return reader(context);\n+        }\n+\n+        @Override\n+        public final StoredFieldsSpec rowStrideStoredFieldSpec() {\n+            return StoredFieldsSpec.NO_REQUIREMENTS;\n+        }\n+\n+        @Override\n+        public boolean supportsOrdinals() {\n+            return false;\n+        }\n+\n+        @Override\n+        public SortedSetDocValues ordinals(LeafReaderContext context) throws IOException {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+    }\n+\n+    // Used for testing.\n+    public interface NumericDocValuesAccessor {\n+        NumericDocValues numericDocValues();\n+    }\n+\n+    /**\n+     * Convert from the stored {@link long} into the {@link double} to load.\n+     * Sadly, this will go megamorphic pretty quickly and slow us down,\n+     * but it gets the job done for now.\n+     */\n+    public interface ToDouble {\n+        double convert(long v);\n+    }\n+}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BooleansBlockLoader.java b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BooleansBlockLoader.java\nnew file mode 100644\nindex 0000000000000..c82a91ccb9dd7\n--- /dev/null\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BooleansBlockLoader.java\n@@ -0,0 +1,147 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedNumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class BooleansBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public BooleansBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public BooleanBuilder builder(BlockFactory factory, int expectedCount) {\n+        return factory.booleans(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n+        if (docValues != null) {\n+            NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonBooleans(singleton);\n+            }\n+            return new Booleans(docValues);\n+        }\n+        NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonBooleans(singleton);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    private static class SingletonBooleans extends BlockDocValuesReader {\n+        private final NumericDocValues numericDocValues;\n+\n+        SingletonBooleans(NumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.BooleanBuilder builder = factory.booleansFromDocValues(docs.count() - offset)) {\n+                int lastDoc = -1;\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (doc < lastDoc) {\n+                        throw new IllegalStateException(\"docs within same block must be in order\");\n+                    }\n+                    if (numericDocValues.advanceExact(doc)) {\n+                        builder.appendBoolean(numericDocValues.longValue() != 0);\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                    lastDoc = doc;\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            BooleanBuilder blockBuilder = (BooleanBuilder) builder;\n+            if (numericDocValues.advanceExact(docId)) {\n+                blockBuilder.appendBoolean(numericDocValues.longValue() != 0);\n+            } else {\n+                blockBuilder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonBooleans\";\n+        }\n+    }\n+\n+    private static class Booleans extends BlockDocValuesReader {\n+        private final SortedNumericDocValues numericDocValues;\n+\n+        Booleans(SortedNumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.BooleanBuilder builder = factory.booleansFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BooleanBuilder) builder);\n+        }\n+\n+        private void read(int doc, BooleanBuilder builder) throws IOException {\n+            if (false == numericDocValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = numericDocValues.docValueCount();\n+            if (count == 1) {\n+                builder.appendBoolean(numericDocValues.nextValue() != 0);\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendBoolean(numericDocValues.nextValue() != 0);\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Booleans\";\n+        }\n+    }\n+}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BytesRefsFromCustomBinaryBlockLoader.java b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BytesRefsFromCustomBinaryBlockLoader.java\nnew file mode 100644\nindex 0000000000000..86ce0dba56f8a\n--- /dev/null\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BytesRefsFromCustomBinaryBlockLoader.java\n@@ -0,0 +1,117 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.BinaryDocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.common.io.stream.ByteArrayStreamInput;\n+import org.elasticsearch.index.mapper.BinaryFieldMapper;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class BytesRefsFromCustomBinaryBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public BytesRefsFromCustomBinaryBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.bytesRefs(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        BinaryDocValues docValues = context.reader().getBinaryDocValues(fieldName);\n+        if (docValues == null) {\n+            return new ConstantNullsReader();\n+        }\n+        return new BytesRefsFromCustomBinary(docValues);\n+    }\n+\n+    public abstract static class AbstractBytesRefsFromBinary extends BlockDocValuesReader {\n+        protected final BinaryDocValues docValues;\n+\n+        public AbstractBytesRefsFromBinary(BinaryDocValues docValues) {\n+            this.docValues = docValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.BytesRefBuilder builder = factory.bytesRefs(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BytesRefBuilder) builder);\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return docValues.docID();\n+        }\n+\n+        public abstract void read(int docId, BytesRefBuilder builder) throws IOException;\n+    }\n+\n+    /**\n+     * Read BinaryDocValues encoded by {@link BinaryFieldMapper.CustomBinaryDocValuesField}\n+     */\n+    static class BytesRefsFromCustomBinary extends AbstractBytesRefsFromBinary {\n+        private final ByteArrayStreamInput in = new ByteArrayStreamInput();\n+        private final BytesRef scratch = new BytesRef();\n+\n+        BytesRefsFromCustomBinary(BinaryDocValues docValues) {\n+            super(docValues);\n+        }\n+\n+        @Override\n+        public void read(int doc, BytesRefBuilder builder) throws IOException {\n+            if (false == docValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            BytesRef bytes = docValues.binaryValue();\n+            assert bytes.length > 0;\n+            in.reset(bytes.bytes, bytes.offset, bytes.length);\n+            int count = in.readVInt();\n+            scratch.bytes = bytes.bytes;\n+\n+            if (count == 1) {\n+                scratch.length = in.readVInt();\n+                scratch.offset = in.getPosition();\n+                builder.appendBytesRef(scratch);\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                scratch.length = in.readVInt();\n+                scratch.offset = in.getPosition();\n+                in.setPosition(scratch.offset + scratch.length);\n+                builder.appendBytesRef(scratch);\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.BytesCustom\";\n+        }\n+    }\n+}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BytesRefsFromOrdsBlockLoader.java b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BytesRefsFromOrdsBlockLoader.java\nnew file mode 100644\nindex 0000000000000..f6b3daf536d8d\n--- /dev/null\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/BytesRefsFromOrdsBlockLoader.java\n@@ -0,0 +1,218 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedDocValues;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Loads {@code keyword} style fields that are stored as a lookup table and ordinals.\n+ */\n+public class BytesRefsFromOrdsBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public BytesRefsFromOrdsBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public BytesRefBuilder builder(BlockFactory factory, int expectedCount) {\n+        return factory.bytesRefs(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedSetDocValues docValues = context.reader().getSortedSetDocValues(fieldName);\n+        if (docValues != null) {\n+            SortedDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonOrdinals(singleton);\n+            }\n+            return new Ordinals(docValues);\n+        }\n+        SortedDocValues singleton = context.reader().getSortedDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonOrdinals(singleton);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    @Override\n+    public boolean supportsOrdinals() {\n+        return true;\n+    }\n+\n+    @Override\n+    public SortedSetDocValues ordinals(LeafReaderContext context) throws IOException {\n+        return DocValues.getSortedSet(context.reader(), fieldName);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"BytesRefsFromOrds[\" + fieldName + \"]\";\n+    }\n+\n+    private static class SingletonOrdinals extends BlockDocValuesReader {\n+        private final SortedDocValues ordinals;\n+\n+        SingletonOrdinals(SortedDocValues ordinals) {\n+            this.ordinals = ordinals;\n+        }\n+\n+        private BlockLoader.Block readSingleDoc(BlockFactory factory, int docId) throws IOException {\n+            if (ordinals.advanceExact(docId)) {\n+                BytesRef v = ordinals.lookupOrd(ordinals.ordValue());\n+                // the returned BytesRef can be reused\n+                return factory.constantBytes(BytesRef.deepCopyOf(v), 1);\n+            } else {\n+                return factory.constantNulls(1);\n+            }\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (docs.count() - offset == 1) {\n+                return readSingleDoc(factory, docs.get(offset));\n+            }\n+            if (ordinals instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n+                BlockLoader.Block block = direct.tryRead(factory, docs, offset, nullsFiltered, null, false);\n+                if (block != null) {\n+                    return block;\n+                }\n+            }\n+            try (var builder = factory.singletonOrdinalsBuilder(ordinals, docs.count() - offset, false)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (ordinals.advanceExact(doc)) {\n+                        builder.appendOrd(ordinals.ordValue());\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            if (ordinals.advanceExact(docId)) {\n+                ((BytesRefBuilder) builder).appendBytesRef(ordinals.lookupOrd(ordinals.ordValue()));\n+            } else {\n+                builder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return ordinals.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonOrdinals\";\n+        }\n+    }\n+\n+    private static class Ordinals extends BlockDocValuesReader {\n+        private final SortedSetDocValues ordinals;\n+\n+        Ordinals(SortedSetDocValues ordinals) {\n+            this.ordinals = ordinals;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (docs.count() - offset == 1) {\n+                return readSingleDoc(factory, docs.get(offset));\n+            }\n+            try (var builder = factory.sortedSetOrdinalsBuilder(ordinals, docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (doc < ordinals.docID()) {\n+                        throw new IllegalStateException(\"docs within same block must be in order\");\n+                    }\n+                    if (ordinals.advanceExact(doc) == false) {\n+                        builder.appendNull();\n+                        continue;\n+                    }\n+                    int count = ordinals.docValueCount();\n+                    if (count == 1) {\n+                        builder.appendOrd(Math.toIntExact(ordinals.nextOrd()));\n+                    } else {\n+                        builder.beginPositionEntry();\n+                        for (int c = 0; c < count; c++) {\n+                            builder.appendOrd(Math.toIntExact(ordinals.nextOrd()));\n+                        }\n+                        builder.endPositionEntry();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BytesRefBuilder) builder);\n+        }\n+\n+        private BlockLoader.Block readSingleDoc(BlockFactory factory, int docId) throws IOException {\n+            if (ordinals.advanceExact(docId) == false) {\n+                return factory.constantNulls(1);\n+            }\n+            int count = ordinals.docValueCount();\n+            if (count == 1) {\n+                BytesRef v = ordinals.lookupOrd(ordinals.nextOrd());\n+                return factory.constantBytes(BytesRef.deepCopyOf(v), 1);\n+            }\n+            try (var builder = factory.bytesRefsFromDocValues(count)) {\n+                builder.beginPositionEntry();\n+                for (int c = 0; c < count; c++) {\n+                    BytesRef v = ordinals.lookupOrd(ordinals.nextOrd());\n+                    builder.appendBytesRef(v);\n+                }\n+                builder.endPositionEntry();\n+                return builder.build();\n+            }\n+        }\n+\n+        private void read(int docId, BytesRefBuilder builder) throws IOException {\n+            if (false == ordinals.advanceExact(docId)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = ordinals.docValueCount();\n+            if (count == 1) {\n+                builder.appendBytesRef(ordinals.lookupOrd(ordinals.nextOrd()));\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendBytesRef(ordinals.lookupOrd(ordinals.nextOrd()));\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return ordinals.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Ordinals\";\n+        }\n+    }\n+}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DenseVectorBlockLoader.java b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DenseVectorBlockLoader.java\nnew file mode 100644\nindex 0000000000000..2fe188a2c38ac\n--- /dev/null\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DenseVectorBlockLoader.java\n@@ -0,0 +1,211 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.ByteVectorValues;\n+import org.apache.lucene.index.FloatVectorValues;\n+import org.apache.lucene.index.KnnVectorValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper;\n+\n+import java.io.IOException;\n+\n+import static org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper.COSINE_MAGNITUDE_FIELD_SUFFIX;\n+\n+public class DenseVectorBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+    private final int dimensions;\n+    private final DenseVectorFieldMapper.DenseVectorFieldType fieldType;\n+\n+    public DenseVectorBlockLoader(String fieldName, int dimensions, DenseVectorFieldMapper.DenseVectorFieldType fieldType) {\n+        this.fieldName = fieldName;\n+        this.dimensions = dimensions;\n+        this.fieldType = fieldType;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.denseVectors(expectedCount, dimensions);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        switch (fieldType.getElementType()) {\n+            case FLOAT -> {\n+                FloatVectorValues floatVectorValues = context.reader().getFloatVectorValues(fieldName);\n+                if (floatVectorValues != null) {\n+                    if (fieldType.isNormalized()) {\n+                        NumericDocValues magnitudeDocValues = context.reader()\n+                            .getNumericDocValues(fieldType.name() + COSINE_MAGNITUDE_FIELD_SUFFIX);\n+                        return new FloatDenseVectorNormalizedValuesBlockReader(floatVectorValues, dimensions, magnitudeDocValues);\n+                    }\n+                    return new FloatDenseVectorValuesBlockReader(floatVectorValues, dimensions);\n+                }\n+            }\n+            case BYTE -> {\n+                ByteVectorValues byteVectorValues = context.reader().getByteVectorValues(fieldName);\n+                if (byteVectorValues != null) {\n+                    return new ByteDenseVectorValuesBlockReader(byteVectorValues, dimensions);\n+                }\n+            }\n+            case BIT -> {\n+                ByteVectorValues byteVectorValues = context.reader().getByteVectorValues(fieldName);\n+                if (byteVectorValues != null) {\n+                    return new BitDenseVectorValuesBlockReader(byteVectorValues, dimensions);\n+                }\n+            }\n+        }\n+\n+        return new ConstantNullsReader();\n+    }\n+\n+    private abstract static class DenseVectorValuesBlockReader<T extends KnnVectorValues> extends BlockDocValuesReader {\n+        protected final T vectorValues;\n+        protected final KnnVectorValues.DocIndexIterator iterator;\n+        protected final int dimensions;\n+\n+        DenseVectorValuesBlockReader(T vectorValues, int dimensions) {\n+            this.vectorValues = vectorValues;\n+            iterator = vectorValues.iterator();\n+            this.dimensions = dimensions;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            // Doubles from doc values ensures that the values are in order\n+            try (BlockLoader.FloatBuilder builder = factory.denseVectors(docs.count() - offset, dimensions)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    read(docs.get(i), builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BlockLoader.FloatBuilder) builder);\n+        }\n+\n+        private void read(int doc, BlockLoader.FloatBuilder builder) throws IOException {\n+            assertDimensions();\n+\n+            if (iterator.docID() > doc) {\n+                builder.appendNull();\n+            } else if (iterator.docID() == doc || iterator.advance(doc) == doc) {\n+                builder.beginPositionEntry();\n+                appendDoc(builder);\n+                builder.endPositionEntry();\n+            } else {\n+                builder.appendNull();\n+            }\n+        }\n+\n+        protected abstract void appendDoc(BlockLoader.FloatBuilder builder) throws IOException;\n+\n+        @Override\n+        public int docId() {\n+            return iterator.docID();\n+        }\n+\n+        protected void assertDimensions() {\n+            assert vectorValues.dimension() == dimensions\n+                : \"unexpected dimensions for vector value; expected \" + dimensions + \" but got \" + vectorValues.dimension();\n+        }\n+    }\n+\n+    private static class FloatDenseVectorValuesBlockReader extends DenseVectorValuesBlockReader<FloatVectorValues> {\n+\n+        FloatDenseVectorValuesBlockReader(FloatVectorValues floatVectorValues, int dimensions) {\n+            super(floatVectorValues, dimensions);\n+        }\n+\n+        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n+            float[] floats = vectorValues.vectorValue(iterator.index());\n+            for (float aFloat : floats) {\n+                builder.appendFloat(aFloat);\n+            }\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.FloatDenseVectorValuesBlockReader\";\n+        }\n+    }\n+\n+    private static class FloatDenseVectorNormalizedValuesBlockReader extends DenseVectorValuesBlockReader<FloatVectorValues> {\n+        private final NumericDocValues magnitudeDocValues;\n+\n+        FloatDenseVectorNormalizedValuesBlockReader(\n+            FloatVectorValues floatVectorValues,\n+            int dimensions,\n+            NumericDocValues magnitudeDocValues\n+        ) {\n+            super(floatVectorValues, dimensions);\n+            this.magnitudeDocValues = magnitudeDocValues;\n+        }\n+\n+        @Override\n+        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n+            float magnitude = 1.0f;\n+            // If all vectors are normalized, no doc values will be present. The vector may be normalized already, so we may not have a\n+            // stored magnitude for all docs\n+            if ((magnitudeDocValues != null) && magnitudeDocValues.advanceExact(iterator.docID())) {\n+                magnitude = Float.intBitsToFloat((int) magnitudeDocValues.longValue());\n+            }\n+            float[] floats = vectorValues.vectorValue(iterator.index());\n+            for (float aFloat : floats) {\n+                builder.appendFloat(aFloat * magnitude);\n+            }\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.FloatDenseVectorNormalizedValuesBlockReader\";\n+        }\n+    }\n+\n+    private static class ByteDenseVectorValuesBlockReader extends DenseVectorValuesBlockReader<ByteVectorValues> {\n+        ByteDenseVectorValuesBlockReader(ByteVectorValues floatVectorValues, int dimensions) {\n+            super(floatVectorValues, dimensions);\n+        }\n+\n+        protected void appendDoc(BlockLoader.FloatBuilder builder) throws IOException {\n+            byte[] bytes = vectorValues.vectorValue(iterator.index());\n+            for (byte aFloat : bytes) {\n+                builder.appendFloat(aFloat);\n+            }\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.ByteDenseVectorValuesBlockReader\";\n+        }\n+    }\n+\n+    private static class BitDenseVectorValuesBlockReader extends ByteDenseVectorValuesBlockReader {\n+\n+        BitDenseVectorValuesBlockReader(ByteVectorValues floatVectorValues, int dimensions) {\n+            super(floatVectorValues, dimensions);\n+        }\n+\n+        @Override\n+        protected void assertDimensions() {\n+            assert vectorValues.dimension() * Byte.SIZE == dimensions\n+                : \"unexpected dimensions for vector value; expected \" + dimensions + \" but got \" + vectorValues.dimension() * Byte.SIZE;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.BitDenseVectorValuesBlockReader\";\n+        }\n+    }\n+}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DenseVectorFromBinaryBlockLoader.java b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DenseVectorFromBinaryBlockLoader.java\nnew file mode 100644\nindex 0000000000000..f5f9e8dc88295\n--- /dev/null\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DenseVectorFromBinaryBlockLoader.java\n@@ -0,0 +1,170 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.BinaryDocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.index.IndexVersion;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.index.mapper.vectors.DenseVectorFieldMapper;\n+import org.elasticsearch.index.mapper.vectors.VectorEncoderDecoder;\n+\n+import java.io.IOException;\n+\n+public class DenseVectorFromBinaryBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+    private final int dims;\n+    private final IndexVersion indexVersion;\n+    private final DenseVectorFieldMapper.ElementType elementType;\n+\n+    public DenseVectorFromBinaryBlockLoader(\n+        String fieldName,\n+        int dims,\n+        IndexVersion indexVersion,\n+        DenseVectorFieldMapper.ElementType elementType\n+    ) {\n+        this.fieldName = fieldName;\n+        this.dims = dims;\n+        this.indexVersion = indexVersion;\n+        this.elementType = elementType;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.denseVectors(expectedCount, dims);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        BinaryDocValues docValues = context.reader().getBinaryDocValues(fieldName);\n+        if (docValues == null) {\n+            return new ConstantNullsReader();\n+        }\n+        return switch (elementType) {\n+            case FLOAT -> new FloatDenseVectorFromBinary(docValues, dims, indexVersion);\n+            case BYTE -> new ByteDenseVectorFromBinary(docValues, dims, indexVersion);\n+            case BIT -> new BitDenseVectorFromBinary(docValues, dims, indexVersion);\n+        };\n+    }\n+\n+    // Abstract base for dense vector readers\n+    private abstract static class AbstractDenseVectorFromBinary<T> extends BlockDocValuesReader {\n+        protected final BinaryDocValues docValues;\n+        protected final IndexVersion indexVersion;\n+        protected final int dimensions;\n+        protected final T scratch;\n+\n+        AbstractDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion, T scratch) {\n+            this.docValues = docValues;\n+            this.indexVersion = indexVersion;\n+            this.dimensions = dims;\n+            this.scratch = scratch;\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return docValues.docID();\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (BlockLoader.FloatBuilder) builder);\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.FloatBuilder builder = factory.denseVectors(docs.count() - offset, dimensions)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        private void read(int doc, BlockLoader.FloatBuilder builder) throws IOException {\n+            if (docValues.advanceExact(doc) == false) {\n+                builder.appendNull();\n+                return;\n+            }\n+            BytesRef bytesRef = docValues.binaryValue();\n+            assert bytesRef.length > 0;\n+            decodeDenseVector(bytesRef, scratch);\n+\n+            builder.beginPositionEntry();\n+            writeScratchToBuilder(scratch, builder);\n+            builder.endPositionEntry();\n+        }\n+\n+        protected abstract void decodeDenseVector(BytesRef bytesRef, T scratch);\n+\n+        protected abstract void writeScratchToBuilder(T scratch, BlockLoader.FloatBuilder builder);\n+    }\n+\n+    private static class FloatDenseVectorFromBinary extends AbstractDenseVectorFromBinary<float[]> {\n+        FloatDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n+            super(docValues, dims, indexVersion, new float[dims]);\n+        }\n+\n+        @Override\n+        protected void writeScratchToBuilder(float[] scratch, BlockLoader.FloatBuilder builder) {\n+            for (float value : scratch) {\n+                builder.appendFloat(value);\n+            }\n+        }\n+\n+        @Override\n+        protected void decodeDenseVector(BytesRef bytesRef, float[] scratch) {\n+            VectorEncoderDecoder.decodeDenseVector(indexVersion, bytesRef, scratch);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"FloatDenseVectorFromBinary.Bytes\";\n+        }\n+    }\n+\n+    private static class ByteDenseVectorFromBinary extends AbstractDenseVectorFromBinary<byte[]> {\n+        ByteDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n+            this(docValues, dims, indexVersion, dims);\n+        }\n+\n+        protected ByteDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion, int readScratchSize) {\n+            super(docValues, dims, indexVersion, new byte[readScratchSize]);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"ByteDenseVectorFromBinary.Bytes\";\n+        }\n+\n+        protected void writeScratchToBuilder(byte[] scratch, BlockLoader.FloatBuilder builder) {\n+            for (byte value : scratch) {\n+                builder.appendFloat(value);\n+            }\n+        }\n+\n+        protected void decodeDenseVector(BytesRef bytesRef, byte[] scratch) {\n+            VectorEncoderDecoder.decodeDenseVector(indexVersion, bytesRef, scratch);\n+        }\n+    }\n+\n+    private static class BitDenseVectorFromBinary extends ByteDenseVectorFromBinary {\n+        BitDenseVectorFromBinary(BinaryDocValues docValues, int dims, IndexVersion indexVersion) {\n+            super(docValues, dims, indexVersion, dims / Byte.SIZE);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BitDenseVectorFromBinary.Bytes\";\n+        }\n+    }\n+}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DoublesBlockLoader.java b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DoublesBlockLoader.java\nnew file mode 100644\nindex 0000000000000..7e6a700f156ba\n--- /dev/null\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/DoublesBlockLoader.java\n@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedNumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class DoublesBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+    private final BlockDocValuesReader.ToDouble toDouble;\n+\n+    public DoublesBlockLoader(String fieldName, BlockDocValuesReader.ToDouble toDouble) {\n+        this.fieldName = fieldName;\n+        this.toDouble = toDouble;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.doubles(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n+        if (docValues != null) {\n+            NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonDoubles(singleton, toDouble);\n+            }\n+            return new Doubles(docValues, toDouble);\n+        }\n+        NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonDoubles(singleton, toDouble);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    public static class SingletonDoubles extends BlockDocValuesReader implements BlockDocValuesReader.NumericDocValuesAccessor {\n+        private final NumericDocValues docValues;\n+        private final ToDouble toDouble;\n+\n+        SingletonDoubles(NumericDocValues docValues, ToDouble toDouble) {\n+            this.docValues = docValues;\n+            this.toDouble = toDouble;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (docValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n+                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, toDouble, false);\n+                if (result != null) {\n+                    return result;\n+                }\n+            }\n+            try (BlockLoader.DoubleBuilder builder = factory.doublesFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (docValues.advanceExact(doc)) {\n+                        builder.appendDouble(toDouble.convert(docValues.longValue()));\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            DoubleBuilder blockBuilder = (DoubleBuilder) builder;\n+            if (docValues.advanceExact(docId)) {\n+                blockBuilder.appendDouble(toDouble.convert(docValues.longValue()));\n+            } else {\n+                blockBuilder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return docValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonDoubles\";\n+        }\n+\n+        @Override\n+        public NumericDocValues numericDocValues() {\n+            return docValues;\n+        }\n+    }\n+\n+    public static class Doubles extends BlockDocValuesReader {\n+        private final SortedNumericDocValues docValues;\n+        private final ToDouble toDouble;\n+\n+        Doubles(SortedNumericDocValues docValues, ToDouble toDouble) {\n+            this.docValues = docValues;\n+            this.toDouble = toDouble;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.DoubleBuilder builder = factory.doublesFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (DoubleBuilder) builder);\n+        }\n+\n+        private void read(int doc, DoubleBuilder builder) throws IOException {\n+            if (false == docValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = docValues.docValueCount();\n+            if (count == 1) {\n+                builder.appendDouble(toDouble.convert(docValues.nextValue()));\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendDouble(toDouble.convert(docValues.nextValue()));\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return docValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Doubles\";\n+        }\n+    }\n+}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/IntsBlockLoader.java b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/IntsBlockLoader.java\nnew file mode 100644\nindex 0000000000000..9f0bc40f02845\n--- /dev/null\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/IntsBlockLoader.java\n@@ -0,0 +1,153 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedNumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class IntsBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public IntsBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.ints(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n+        if (docValues != null) {\n+            NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonInts(singleton);\n+            }\n+            return new Ints(docValues);\n+        }\n+        NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonInts(singleton);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    public static class SingletonInts extends BlockDocValuesReader implements BlockDocValuesReader.NumericDocValuesAccessor {\n+        private final NumericDocValues numericDocValues;\n+\n+        SingletonInts(NumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (numericDocValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n+                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, null, true);\n+                if (result != null) {\n+                    return result;\n+                }\n+            }\n+            try (BlockLoader.IntBuilder builder = factory.intsFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (numericDocValues.advanceExact(doc)) {\n+                        builder.appendInt(Math.toIntExact(numericDocValues.longValue()));\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            IntBuilder blockBuilder = (IntBuilder) builder;\n+            if (numericDocValues.advanceExact(docId)) {\n+                blockBuilder.appendInt(Math.toIntExact(numericDocValues.longValue()));\n+            } else {\n+                blockBuilder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonInts\";\n+        }\n+\n+        @Override\n+        public NumericDocValues numericDocValues() {\n+            return numericDocValues;\n+        }\n+    }\n+\n+    public static class Ints extends BlockDocValuesReader {\n+        private final SortedNumericDocValues numericDocValues;\n+\n+        Ints(SortedNumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.IntBuilder builder = factory.intsFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (IntBuilder) builder);\n+        }\n+\n+        private void read(int doc, IntBuilder builder) throws IOException {\n+            if (false == numericDocValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = numericDocValues.docValueCount();\n+            if (count == 1) {\n+                builder.appendInt(Math.toIntExact(numericDocValues.nextValue()));\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendInt(Math.toIntExact(numericDocValues.nextValue()));\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Ints\";\n+        }\n+    }\n+}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/LongsBlockLoader.java b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/LongsBlockLoader.java\nnew file mode 100644\nindex 0000000000000..16425fb8a7ead\n--- /dev/null\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/blockloader/docvalues/LongsBlockLoader.java\n@@ -0,0 +1,153 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the \"Elastic License\n+ * 2.0\", the \"GNU Affero General Public License v3.0 only\", and the \"Server Side\n+ * Public License v 1\"; you may not use this file except in compliance with, at\n+ * your election, the \"Elastic License 2.0\", the \"GNU Affero General Public\n+ * License v3.0 only\", or the \"Server Side Public License, v 1\".\n+ */\n+\n+package org.elasticsearch.index.mapper.blockloader.docvalues;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.index.SortedNumericDocValues;\n+import org.elasticsearch.index.mapper.BlockLoader;\n+\n+import java.io.IOException;\n+\n+public class LongsBlockLoader extends BlockDocValuesReader.DocValuesBlockLoader {\n+    private final String fieldName;\n+\n+    public LongsBlockLoader(String fieldName) {\n+        this.fieldName = fieldName;\n+    }\n+\n+    @Override\n+    public Builder builder(BlockFactory factory, int expectedCount) {\n+        return factory.longs(expectedCount);\n+    }\n+\n+    @Override\n+    public AllReader reader(LeafReaderContext context) throws IOException {\n+        SortedNumericDocValues docValues = context.reader().getSortedNumericDocValues(fieldName);\n+        if (docValues != null) {\n+            NumericDocValues singleton = DocValues.unwrapSingleton(docValues);\n+            if (singleton != null) {\n+                return new SingletonLongs(singleton);\n+            }\n+            return new Longs(docValues);\n+        }\n+        NumericDocValues singleton = context.reader().getNumericDocValues(fieldName);\n+        if (singleton != null) {\n+            return new SingletonLongs(singleton);\n+        }\n+        return new ConstantNullsReader();\n+    }\n+\n+    public static class SingletonLongs extends BlockDocValuesReader implements BlockDocValuesReader.NumericDocValuesAccessor {\n+        final NumericDocValues numericDocValues;\n+\n+        SingletonLongs(NumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            if (numericDocValues instanceof BlockLoader.OptionalColumnAtATimeReader direct) {\n+                BlockLoader.Block result = direct.tryRead(factory, docs, offset, nullsFiltered, null, false);\n+                if (result != null) {\n+                    return result;\n+                }\n+            }\n+            try (BlockLoader.LongBuilder builder = factory.longsFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    if (numericDocValues.advanceExact(doc)) {\n+                        builder.appendLong(numericDocValues.longValue());\n+                    } else {\n+                        builder.appendNull();\n+                    }\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            BlockLoader.LongBuilder blockBuilder = (BlockLoader.LongBuilder) builder;\n+            if (numericDocValues.advanceExact(docId)) {\n+                blockBuilder.appendLong(numericDocValues.longValue());\n+            } else {\n+                blockBuilder.appendNull();\n+            }\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.SingletonLongs\";\n+        }\n+\n+        @Override\n+        public NumericDocValues numericDocValues() {\n+            return numericDocValues;\n+        }\n+    }\n+\n+    public static class Longs extends BlockDocValuesReader {\n+        private final SortedNumericDocValues numericDocValues;\n+\n+        Longs(SortedNumericDocValues numericDocValues) {\n+            this.numericDocValues = numericDocValues;\n+        }\n+\n+        @Override\n+        public BlockLoader.Block read(BlockFactory factory, Docs docs, int offset, boolean nullsFiltered) throws IOException {\n+            try (BlockLoader.LongBuilder builder = factory.longsFromDocValues(docs.count() - offset)) {\n+                for (int i = offset; i < docs.count(); i++) {\n+                    int doc = docs.get(i);\n+                    read(doc, builder);\n+                }\n+                return builder.build();\n+            }\n+        }\n+\n+        @Override\n+        public void read(int docId, BlockLoader.StoredFields storedFields, Builder builder) throws IOException {\n+            read(docId, (LongBuilder) builder);\n+        }\n+\n+        private void read(int doc, LongBuilder builder) throws IOException {\n+            if (false == numericDocValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            int count = numericDocValues.docValueCount();\n+            if (count == 1) {\n+                builder.appendLong(numericDocValues.nextValue());\n+                return;\n+            }\n+            builder.beginPositionEntry();\n+            for (int v = 0; v < count; v++) {\n+                builder.appendLong(numericDocValues.nextValue());\n+            }\n+            builder.endPositionEntry();\n+        }\n+\n+        @Override\n+        public int docId() {\n+            return numericDocValues.docID();\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Longs\";\n+        }\n+    }\n+}\ndiff --git a/server/src/main/java/org/elasticsearch/index/mapper/vectors/DenseVectorFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/vectors/DenseVectorFieldMapper.java\nindex 0fcb5a60c95bd..74af0eb222775 100644\n--- a/server/src/main/java/org/elasticsearch/index/mapper/vectors/DenseVectorFieldMapper.java\n+++ b/server/src/main/java/org/elasticsearch/index/mapper/vectors/DenseVectorFieldMapper.java\n@@ -58,7 +58,6 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.mapper.ArraySourceValueFetcher;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.BlockSourceReader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n@@ -74,6 +73,8 @@\n import org.elasticsearch.index.mapper.SourceLoader;\n import org.elasticsearch.index.mapper.SourceValueFetcher;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DenseVectorBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DenseVectorFromBinaryBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.search.DocValueFormat;\n import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n@@ -2689,11 +2690,11 @@ public BlockLoader blockLoader(MappedFieldType.BlockLoaderContext blContext) {\n             }\n \n             if (indexed) {\n-                return new BlockDocValuesReader.DenseVectorBlockLoader(name(), dims, this);\n+                return new DenseVectorBlockLoader(name(), dims, this);\n             }\n \n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSource)) {\n-                return new BlockDocValuesReader.DenseVectorFromBinaryBlockLoader(name(), dims, indexVersionCreated, element.elementType());\n+                return new DenseVectorFromBinaryBlockLoader(name(), dims, indexVersionCreated, element.elementType());\n             }\n             BlockSourceReader.LeafIteratorLookup lookup = BlockSourceReader.lookupMatchingAll();\n             return new BlockSourceReader.DenseVectorBlockLoader(\ndiff --git a/server/src/test/java/org/elasticsearch/index/mapper/DateFieldMapperTests.java b/server/src/test/java/org/elasticsearch/index/mapper/DateFieldMapperTests.java\nindex 6ded77738ec9b..4d6368b712f98 100644\n--- a/server/src/test/java/org/elasticsearch/index/mapper/DateFieldMapperTests.java\n+++ b/server/src/test/java/org/elasticsearch/index/mapper/DateFieldMapperTests.java\n@@ -33,6 +33,7 @@\n import org.elasticsearch.index.IndexVersions;\n import org.elasticsearch.index.codec.tsdb.es819.ES819TSDBDocValuesFormat;\n import org.elasticsearch.index.mapper.DateFieldMapper.DateFieldType;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.script.DateFieldScript;\n import org.elasticsearch.script.ScriptService;\n import org.elasticsearch.search.DocValueFormat;\n@@ -854,8 +855,8 @@ public void testSingletonLongBulkBlockReadingManyValues() throws Exception {\n                 LeafReaderContext context = reader.leaves().get(0);\n                 {\n                     // One big doc block\n-                    var columnReader = (BlockDocValuesReader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n-                    assertThat(columnReader.numericDocValues, instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n+                    var columnReader = (LongsBlockLoader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n+                    assertThat(columnReader.numericDocValues(), instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n                     var docBlock = TestBlock.docs(IntStream.range(from, to).toArray());\n                     var block = (TestBlock) columnReader.read(TestBlock.factory(), docBlock, 0, false);\n                     assertThat(block.size(), equalTo(to - from));\n@@ -866,8 +867,8 @@ public void testSingletonLongBulkBlockReadingManyValues() throws Exception {\n                 {\n                     // Smaller doc blocks\n                     int docBlockSize = 1000;\n-                    var columnReader = (BlockDocValuesReader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n-                    assertThat(columnReader.numericDocValues, instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n+                    var columnReader = (LongsBlockLoader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n+                    assertThat(columnReader.numericDocValues(), instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n                     for (int i = from; i < to; i += docBlockSize) {\n                         var docBlock = TestBlock.docs(IntStream.range(i, i + docBlockSize).toArray());\n                         var block = (TestBlock) columnReader.read(TestBlock.factory(), docBlock, 0, false);\n@@ -880,8 +881,8 @@ public void testSingletonLongBulkBlockReadingManyValues() throws Exception {\n                 }\n                 {\n                     // One smaller doc block:\n-                    var columnReader = (BlockDocValuesReader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n-                    assertThat(columnReader.numericDocValues, instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n+                    var columnReader = (LongsBlockLoader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n+                    assertThat(columnReader.numericDocValues(), instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n                     var docBlock = TestBlock.docs(IntStream.range(1010, 2020).toArray());\n                     var block = (TestBlock) columnReader.read(TestBlock.factory(), docBlock, 0, false);\n                     assertThat(block.size(), equalTo(1010));\n@@ -892,8 +893,8 @@ public void testSingletonLongBulkBlockReadingManyValues() throws Exception {\n                 }\n                 {\n                     // Read two tiny blocks:\n-                    var columnReader = (BlockDocValuesReader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n-                    assertThat(columnReader.numericDocValues, instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n+                    var columnReader = (LongsBlockLoader.SingletonLongs) blockLoader.columnAtATimeReader(context);\n+                    assertThat(columnReader.numericDocValues(), instanceOf(BlockLoader.OptionalColumnAtATimeReader.class));\n                     var docBlock = TestBlock.docs(IntStream.range(32, 64).toArray());\n                     var block = (TestBlock) columnReader.read(TestBlock.factory(), docBlock, 0, false);\n                     assertThat(block.size(), equalTo(32));\ndiff --git a/server/src/test/java/org/elasticsearch/index/mapper/GeoPointFieldTypeTests.java b/server/src/test/java/org/elasticsearch/index/mapper/GeoPointFieldTypeTests.java\nindex f3cd0cdaa33e2..833cddd6622c5 100644\n--- a/server/src/test/java/org/elasticsearch/index/mapper/GeoPointFieldTypeTests.java\n+++ b/server/src/test/java/org/elasticsearch/index/mapper/GeoPointFieldTypeTests.java\n@@ -19,6 +19,7 @@\n import org.elasticsearch.index.IndexMode;\n import org.elasticsearch.index.IndexSettings;\n import org.elasticsearch.index.IndexVersion;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.script.ScriptCompiler;\n \n import java.io.IOException;\n@@ -166,7 +167,7 @@ public void testBlockLoaderWhenDocValuesAreEnabledAndThePreferenceIsToUseDocValu\n \n         // then\n         // verify that we use the correct block value reader\n-        assertThat(loader, instanceOf(BlockDocValuesReader.LongsBlockLoader.class));\n+        assertThat(loader, instanceOf(LongsBlockLoader.class));\n     }\n \n     public void testBlockLoaderWhenDocValuesAreEnabledAndThereIsNoPreference() {\ndiff --git a/test/framework/src/main/java/org/elasticsearch/index/mapper/MapperTestCase.java b/test/framework/src/main/java/org/elasticsearch/index/mapper/MapperTestCase.java\nindex a2967973fb102..3ef66cebc1f14 100644\n--- a/test/framework/src/main/java/org/elasticsearch/index/mapper/MapperTestCase.java\n+++ b/test/framework/src/main/java/org/elasticsearch/index/mapper/MapperTestCase.java\n@@ -51,6 +51,10 @@\n import org.elasticsearch.index.fielddata.LeafFieldData;\n import org.elasticsearch.index.fieldvisitor.LeafStoredFieldLoader;\n import org.elasticsearch.index.fieldvisitor.StoredFieldLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.DoublesBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.IntsBlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.index.termvectors.TermVectorsService;\n import org.elasticsearch.index.translog.Translog;\n@@ -1523,17 +1527,17 @@ protected Object[] getThreeEncodedSampleValues() {\n \n     public void testSingletonIntBulkBlockReading() throws IOException {\n         assumeTrue(\"field type supports bulk singleton int reading\", supportsBulkIntBlockReading());\n-        testSingletonBulkBlockReading(columnAtATimeReader -> (BlockDocValuesReader.SingletonInts) columnAtATimeReader);\n+        testSingletonBulkBlockReading(columnAtATimeReader -> (IntsBlockLoader.SingletonInts) columnAtATimeReader);\n     }\n \n     public void testSingletonLongBulkBlockReading() throws IOException {\n         assumeTrue(\"field type supports bulk singleton long reading\", supportsBulkLongBlockReading());\n-        testSingletonBulkBlockReading(columnAtATimeReader -> (BlockDocValuesReader.SingletonLongs) columnAtATimeReader);\n+        testSingletonBulkBlockReading(columnAtATimeReader -> (LongsBlockLoader.SingletonLongs) columnAtATimeReader);\n     }\n \n     public void testSingletonDoubleBulkBlockReading() throws IOException {\n         assumeTrue(\"field type supports bulk singleton double reading\", supportsBulkDoubleBlockReading());\n-        testSingletonBulkBlockReading(columnAtATimeReader -> (BlockDocValuesReader.SingletonDoubles) columnAtATimeReader);\n+        testSingletonBulkBlockReading(columnAtATimeReader -> (DoublesBlockLoader.SingletonDoubles) columnAtATimeReader);\n     }\n \n     private void testSingletonBulkBlockReading(Function<BlockLoader.ColumnAtATimeReader, BlockDocValuesReader> readerCast)\n@@ -1637,9 +1641,9 @@ private void testSingletonBulkBlockReading(Function<BlockLoader.ColumnAtATimeRea\n                 assertThat(\n                     columnReader,\n                     anyOf(\n-                        instanceOf(BlockDocValuesReader.Longs.class),\n-                        instanceOf(BlockDocValuesReader.Doubles.class),\n-                        instanceOf(BlockDocValuesReader.Ints.class)\n+                        instanceOf(LongsBlockLoader.Longs.class),\n+                        instanceOf(DoublesBlockLoader.Doubles.class),\n+                        instanceOf(IntsBlockLoader.Ints.class)\n                     )\n                 );\n                 var docBlock = TestBlock.docs(IntStream.range(0, 3).toArray());\ndiff --git a/test/framework/src/main/java/org/elasticsearch/index/mapper/TestBlock.java b/test/framework/src/main/java/org/elasticsearch/index/mapper/TestBlock.java\nindex 278da8c1ce5c9..1e82ffb31be32 100644\n--- a/test/framework/src/main/java/org/elasticsearch/index/mapper/TestBlock.java\n+++ b/test/framework/src/main/java/org/elasticsearch/index/mapper/TestBlock.java\n@@ -13,6 +13,7 @@\n import org.apache.lucene.index.SortedDocValues;\n import org.apache.lucene.index.SortedSetDocValues;\n import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.hamcrest.Matcher;\n \n import java.io.IOException;\ndiff --git a/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/lucene/read/SingletonDoubleBuilder.java b/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/lucene/read/SingletonDoubleBuilder.java\nindex d1166c2008916..280306e8c2bbc 100644\n--- a/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/lucene/read/SingletonDoubleBuilder.java\n+++ b/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/lucene/read/SingletonDoubleBuilder.java\n@@ -10,8 +10,8 @@\n import org.elasticsearch.compute.data.Block;\n import org.elasticsearch.compute.data.BlockFactory;\n import org.elasticsearch.core.Releasable;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n \n /**\n  * Like {@link org.elasticsearch.compute.data.DoubleBlockBuilder} but optimized for collecting dense single valued values.\ndiff --git a/x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/OperatorTests.java b/x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/OperatorTests.java\nindex 84db6369ce011..fd738a4b39c04 100644\n--- a/x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/OperatorTests.java\n+++ b/x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/OperatorTests.java\n@@ -66,12 +66,12 @@\n import org.elasticsearch.core.CheckedConsumer;\n import org.elasticsearch.core.Releasables;\n import org.elasticsearch.index.IndexSettings;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.FieldNamesFieldMapper;\n import org.elasticsearch.index.mapper.KeywordFieldMapper;\n import org.elasticsearch.index.mapper.MappedFieldType;\n import org.elasticsearch.index.mapper.MapperServiceTestCase;\n import org.elasticsearch.index.mapper.Uid;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;\n import org.elasticsearch.search.lookup.SearchLookup;\n \n@@ -183,14 +183,7 @@ public void testPushRoundToToQuery() throws IOException {\n             );\n             ValuesSourceReaderOperator.Factory load = new ValuesSourceReaderOperator.Factory(\n                 ByteSizeValue.ofGb(1),\n-                List.of(\n-                    new ValuesSourceReaderOperator.FieldInfo(\n-                        \"v\",\n-                        ElementType.LONG,\n-                        false,\n-                        f -> new BlockDocValuesReader.LongsBlockLoader(\"v\")\n-                    )\n-                ),\n+                List.of(new ValuesSourceReaderOperator.FieldInfo(\"v\", ElementType.LONG, false, f -> new LongsBlockLoader(\"v\"))),\n                 new IndexedByShardIdFromSingleton<>(new ValuesSourceReaderOperator.ShardContext(reader, (sourcePaths) -> {\n                     throw new UnsupportedOperationException();\n                 }, 0.8)),\ndiff --git a/x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/lucene/LuceneQueryEvaluatorTests.java b/x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/lucene/LuceneQueryEvaluatorTests.java\nindex 5c2cd244f36c5..2a905253cc0f0 100644\n--- a/x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/lucene/LuceneQueryEvaluatorTests.java\n+++ b/x-pack/plugin/esql/compute/src/test/java/org/elasticsearch/compute/lucene/LuceneQueryEvaluatorTests.java\n@@ -42,7 +42,7 @@\n import org.elasticsearch.compute.test.TestDriverFactory;\n import org.elasticsearch.compute.test.TestResultPageSinkOperator;\n import org.elasticsearch.core.CheckedFunction;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n \n import java.io.IOException;\n import java.util.ArrayList;\n@@ -207,7 +207,7 @@ private List<Page> runQuery(Set<String> values, Query query, boolean shuffleDocs\n                             FIELD,\n                             ElementType.BYTES_REF,\n                             false,\n-                            unused -> new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(FIELD)\n+                            unused -> new BytesRefsFromOrdsBlockLoader(FIELD)\n                         )\n                     ),\n                     new IndexedByShardIdFromSingleton<>(new ValuesSourceReaderOperator.ShardContext(reader, (sourcePaths) -> {\ndiff --git a/x-pack/plugin/logsdb/src/main/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextBlockLoader.java b/x-pack/plugin/logsdb/src/main/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextBlockLoader.java\nindex b6dc2e7b20aa9..ae7c07b2fb948 100644\n--- a/x-pack/plugin/logsdb/src/main/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextBlockLoader.java\n+++ b/x-pack/plugin/logsdb/src/main/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextBlockLoader.java\n@@ -7,8 +7,11 @@\n \n package org.elasticsearch.xpack.logsdb.patterntext;\n \n+import org.apache.lucene.index.BinaryDocValues;\n import org.apache.lucene.index.LeafReaderContext;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromCustomBinaryBlockLoader;\n \n import java.io.IOException;\n \n@@ -31,6 +34,31 @@ public AllReader reader(LeafReaderContext context) throws IOException {\n         if (docValues == null) {\n             return new ConstantNullsReader();\n         }\n-        return new BlockDocValuesReader.BytesRefsFromBinary(docValues);\n+        return new BytesRefsFromBinary(docValues);\n+    }\n+\n+    /**\n+     * Read BinaryDocValues with no additional structure in the BytesRefs.\n+     * Each BytesRef from the doc values maps directly to a value in the block loader.\n+     */\n+    public static class BytesRefsFromBinary extends BytesRefsFromCustomBinaryBlockLoader.AbstractBytesRefsFromBinary {\n+        public BytesRefsFromBinary(BinaryDocValues docValues) {\n+            super(docValues);\n+        }\n+\n+        @Override\n+        public void read(int doc, BytesRefBuilder builder) throws IOException {\n+            if (false == docValues.advanceExact(doc)) {\n+                builder.appendNull();\n+                return;\n+            }\n+            BytesRef bytes = docValues.binaryValue();\n+            builder.appendBytesRef(bytes);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"BlockDocValuesReader.Bytes\";\n+        }\n     }\n }\ndiff --git a/x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateMetricDoubleFieldMapper.java b/x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateMetricDoubleFieldMapper.java\nindex 09f91209f922f..6cbe65f7c31f8 100644\n--- a/x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateMetricDoubleFieldMapper.java\n+++ b/x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateMetricDoubleFieldMapper.java\n@@ -28,7 +28,6 @@\n import org.elasticsearch.index.fielddata.ScriptDocValues.DoublesSupplier;\n import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n@@ -46,6 +45,7 @@\n import org.elasticsearch.index.mapper.TimeSeriesParams;\n import org.elasticsearch.index.mapper.TimeSeriesParams.MetricType;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BlockDocValuesReader;\n import org.elasticsearch.index.query.QueryRewriteContext;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.script.ScriptCompiler;\ndiff --git a/x-pack/plugin/mapper-unsigned-long/src/main/java/org/elasticsearch/xpack/unsignedlong/UnsignedLongFieldMapper.java b/x-pack/plugin/mapper-unsigned-long/src/main/java/org/elasticsearch/xpack/unsignedlong/UnsignedLongFieldMapper.java\nindex 5184aa10c5591..bfa3f7575e980 100644\n--- a/x-pack/plugin/mapper-unsigned-long/src/main/java/org/elasticsearch/xpack/unsignedlong/UnsignedLongFieldMapper.java\n+++ b/x-pack/plugin/mapper-unsigned-long/src/main/java/org/elasticsearch/xpack/unsignedlong/UnsignedLongFieldMapper.java\n@@ -27,7 +27,6 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.IndexNumericFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedNumericIndexFieldData;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.BlockSourceReader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n@@ -50,6 +49,7 @@\n import org.elasticsearch.index.mapper.TimeSeriesParams;\n import org.elasticsearch.index.mapper.TimeSeriesParams.MetricType;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.search.DocValueFormat;\n import org.elasticsearch.search.aggregations.support.TimeSeriesValuesSourceType;\n@@ -383,7 +383,7 @@ public BlockLoader blockLoader(BlockLoaderContext blContext) {\n                 return BlockLoader.CONSTANT_NULLS;\n             }\n             if (hasDocValues() && (blContext.fieldExtractPreference() != FieldExtractPreference.STORED || isSyntheticSource)) {\n-                return new BlockDocValuesReader.LongsBlockLoader(name());\n+                return new LongsBlockLoader(name());\n             }\n             // Multi fields don't have fallback synthetic source.\n             if (isSyntheticSource && blContext.parentField(name()) == null) {\ndiff --git a/x-pack/plugin/mapper-version/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java b/x-pack/plugin/mapper-version/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java\nindex f4031601022da..155cbd88cfcdd 100644\n--- a/x-pack/plugin/mapper-version/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java\n+++ b/x-pack/plugin/mapper-version/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java\n@@ -39,7 +39,6 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n@@ -53,6 +52,7 @@\n import org.elasticsearch.index.mapper.TermBasedFieldType;\n import org.elasticsearch.index.mapper.TextSearchInfo;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromOrdsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.search.DocValueFormat;\n import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n@@ -305,7 +305,7 @@ protected BytesRef indexedValueForSearch(Object value) {\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             failIfNoDocValues();\n-            return new BlockDocValuesReader.BytesRefsFromOrdsBlockLoader(name());\n+            return new BytesRefsFromOrdsBlockLoader(name());\n         }\n \n         @Override\ndiff --git a/x-pack/plugin/spatial/src/main/java/org/elasticsearch/xpack/spatial/index/mapper/PointFieldMapper.java b/x-pack/plugin/spatial/src/main/java/org/elasticsearch/xpack/spatial/index/mapper/PointFieldMapper.java\nindex 021b89c2c2ab9..774860aedcd69 100644\n--- a/x-pack/plugin/spatial/src/main/java/org/elasticsearch/xpack/spatial/index/mapper/PointFieldMapper.java\n+++ b/x-pack/plugin/spatial/src/main/java/org/elasticsearch/xpack/spatial/index/mapper/PointFieldMapper.java\n@@ -26,13 +26,13 @@\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.mapper.AbstractPointGeometryFieldMapper;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n import org.elasticsearch.index.mapper.FieldMapper;\n import org.elasticsearch.index.mapper.IndexType;\n import org.elasticsearch.index.mapper.MappedFieldType;\n import org.elasticsearch.index.mapper.MapperBuilderContext;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.LongsBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.lucene.spatial.XYQueriesUtils;\n import org.elasticsearch.xcontent.XContentBuilder;\n@@ -243,7 +243,7 @@ protected Function<List<CartesianPoint>, List<Object>> getFormatter(String forma\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (blContext.fieldExtractPreference() == DOC_VALUES && hasDocValues()) {\n-                return new BlockDocValuesReader.LongsBlockLoader(name());\n+                return new LongsBlockLoader(name());\n             }\n \n             // Multi fields don't have fallback synthetic source.s\ndiff --git a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\nindex a537e71d27d77..fdb6148018465 100644\n--- a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n+++ b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n@@ -59,7 +59,6 @@\n import org.elasticsearch.index.fielddata.IndexFieldData;\n import org.elasticsearch.index.fielddata.plain.StringBinaryIndexFieldData;\n import org.elasticsearch.index.mapper.BinaryFieldMapper.CustomBinaryDocValuesField;\n-import org.elasticsearch.index.mapper.BlockDocValuesReader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.CompositeSyntheticFieldLoader;\n import org.elasticsearch.index.mapper.DocumentParserContext;\n@@ -73,6 +72,7 @@\n import org.elasticsearch.index.mapper.SourceValueFetcher;\n import org.elasticsearch.index.mapper.TextSearchInfo;\n import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.mapper.blockloader.docvalues.BytesRefsFromCustomBinaryBlockLoader;\n import org.elasticsearch.index.query.SearchExecutionContext;\n import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n import org.elasticsearch.xcontent.XContentBuilder;\n@@ -958,7 +958,7 @@ public Query prefixQuery(\n         @Override\n         public BlockLoader blockLoader(BlockLoaderContext blContext) {\n             if (hasDocValues()) {\n-                return new BlockDocValuesReader.BytesRefsFromCustomBinaryBlockLoader(name());\n+                return new BytesRefsFromCustomBinaryBlockLoader(name());\n             }\n             return null;\n         }\n",
  "additions": 1524,
  "deletions": 1361,
  "changed_files": 45,
  "url": "https://github.com/elastic/elasticsearch/pull/137063",
  "mined_at": "2025-10-25T13:35:30.765285"
}