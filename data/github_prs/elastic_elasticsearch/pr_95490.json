{
  "id": 95490,
  "repository": "elastic/elasticsearch",
  "title": "[ML] Use low priority deployments in trained models tests",
  "body": "The multiple deployment tests are failing for a single processor as the deployment manager complains there is not enough resource to create the test. The answer is to use low priority deployments.\r\n\r\nCloses #95486",
  "state": "closed",
  "merged": true,
  "merged_at": "2023-04-24T09:39:04+00:00",
  "created_at": "2023-04-24T08:52:24+00:00",
  "updated_at": "2025-10-24T22:55:12+00:00",
  "author": "davidkyle",
  "reviewers": [
    "droberts195",
    "tanaraj901025-del"
  ],
  "base_sha": "67b6438e1ba292a199d0d70534e46bff6d5fa326",
  "head_sha": "a9acb01788ebd74bf5ef7deef4c739ad97e575fe",
  "review_comments": [
    {
      "user": "droberts195",
      "state": "APPROVED",
      "body": "LGTM",
      "submitted_at": "2023-04-24T09:02:27+00:00"
    },
    {
      "user": "tanaraj901025-del",
      "state": "COMMENTED",
      "body": "Approved ",
      "submitted_at": "2025-10-24T22:55:12+00:00"
    }
  ],
  "pr_comments": [
    {
      "user": "elasticsearchmachine",
      "body": "Pinging @elastic/ml-core (Team:ML)",
      "created_at": "2023-04-24T08:52:49+00:00"
    }
  ],
  "files_changed": [
    {
      "filename": "x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/MultipleDeploymentsIT.java",
      "status": "modified",
      "additions": 8,
      "deletions": 5,
      "changes": 13,
      "patch": "@@ -10,6 +10,8 @@\n import org.elasticsearch.client.Response;\n import org.elasticsearch.common.xcontent.support.XContentMapValues;\n import org.elasticsearch.core.Tuple;\n+import org.elasticsearch.xpack.core.ml.inference.assignment.AllocationStatus;\n+import org.elasticsearch.xpack.core.ml.inference.assignment.Priority;\n import org.elasticsearch.xpack.core.ml.utils.MapHelper;\n \n import java.io.IOException;\n@@ -28,13 +30,13 @@ public void testDeployModelMultipleTimes() throws IOException {\n         putAllModelParts(baseModelId);\n \n         String forSearch = \"for-search\";\n-        startWithDeploymentId(baseModelId, forSearch);\n+        startDeployment(baseModelId, forSearch, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n \n         Response inference = infer(\"my words\", forSearch);\n         assertOK(inference);\n \n         String forIngest = \"for-ingest\";\n-        startWithDeploymentId(baseModelId, forIngest);\n+        startDeployment(baseModelId, forIngest, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n \n         inference = infer(\"my words\", forIngest);\n         assertOK(inference);\n@@ -71,12 +73,13 @@ public void testGetStats() throws IOException {\n         String modelWith2Deployments = \"model-with-2-deployments\";\n         putAllModelParts(modelWith2Deployments);\n         String forSearchDeployment = \"for-search\";\n-        startWithDeploymentId(modelWith2Deployments, forSearchDeployment);\n+        startDeployment(modelWith2Deployments, forSearchDeployment, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n+\n         String forIngestDeployment = \"for-ingest\";\n-        startWithDeploymentId(modelWith2Deployments, forIngestDeployment);\n+        startDeployment(modelWith2Deployments, forIngestDeployment, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n \n         // deployment Id is the same as model\n-        startDeployment(modelWith1Deployment);\n+        startDeployment(modelWith1Deployment, modelWith1Deployment, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n \n         {\n             Map<String, Object> stats = entityAsMap(getTrainedModelStats(\"_all\"));"
    },
    {
      "filename": "x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelIT.java",
      "status": "modified",
      "additions": 15,
      "deletions": 15,
      "changes": 30,
      "patch": "@@ -190,7 +190,7 @@ public void testDeploymentStats() throws IOException {\n         putModelDefinition(modelStarted);\n \n         CheckedBiConsumer<String, AllocationStatus.State, IOException> assertAtLeast = (modelId, state) -> {\n-            startDeployment(modelId, state.toString());\n+            startDeployment(modelId, state);\n             Response response = getTrainedModelStats(modelId);\n             var responseMap = entityAsMap(response);\n             List<Map<String, Object>> stats = (List<Map<String, Object>>) responseMap.get(\"trained_model_stats\");\n@@ -246,7 +246,7 @@ public void testLiveDeploymentStats() throws IOException {\n         createPassThroughModel(modelId);\n         putVocabulary(List.of(\"once\", \"twice\"), modelId);\n         putModelDefinition(modelId);\n-        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED);\n         {\n             Response noInferenceCallsStatsResponse = getTrainedModelStats(modelId);\n             List<Map<String, Object>> stats = (List<Map<String, Object>>) entityAsMap(noInferenceCallsStatsResponse).get(\n@@ -315,7 +315,7 @@ public void testFailedDeploymentStats() throws Exception {\n         request.setJsonEntity(Strings.format(\"\"\"\n             {\"total_definition_length\":%s,\"definition\": \"%s\",\"total_parts\": 1}\"\"\", length, poorlyFormattedModelBase64));\n         client().performRequest(request);\n-        startDeployment(badModel, AllocationStatus.State.STARTING.toString());\n+        startDeployment(badModel, AllocationStatus.State.STARTING);\n         assertBusy(() -> {\n             Response noInferenceCallsStatsResponse = getTrainedModelStats(badModel);\n             List<Map<String, Object>> stats = (List<Map<String, Object>>) entityAsMap(noInferenceCallsStatsResponse).get(\n@@ -340,8 +340,8 @@ public void testGetDeploymentStats_WithWildcard() throws IOException {\n         putVocabulary(List.of(\"once\", \"twice\"), modelBar);\n         putModelDefinition(modelBar);\n \n-        startDeployment(modelFoo, AllocationStatus.State.FULLY_ALLOCATED.toString());\n-        startDeployment(modelBar, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelFoo, AllocationStatus.State.FULLY_ALLOCATED);\n+        startDeployment(modelBar, AllocationStatus.State.FULLY_ALLOCATED);\n         infer(\"once\", modelFoo);\n         infer(\"once\", modelBar);\n         {\n@@ -372,8 +372,8 @@ public void testGetDeploymentStats_WithStartedStoppedDeployments() throws IOExce\n         putVocabulary(List.of(\"once\", \"twice\"), modelBar);\n         putModelDefinition(modelBar);\n \n-        startDeployment(modelFoo, AllocationStatus.State.FULLY_ALLOCATED.toString());\n-        startDeployment(modelBar, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelFoo, AllocationStatus.State.FULLY_ALLOCATED);\n+        startDeployment(modelBar, AllocationStatus.State.FULLY_ALLOCATED);\n         infer(\"once\", modelFoo);\n         infer(\"once\", modelBar);\n \n@@ -447,7 +447,7 @@ public void testInferWithMultipleDocs() throws IOException {\n             client().performRequest(clusterSettings);\n         }\n \n-        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED);\n \n         List<String> inputs = List.of(\n             \"my words\",\n@@ -614,7 +614,7 @@ public void testTruncation() throws IOException {\n \n         putVocabulary(List.of(\"once\", \"twice\", \"thrice\"), modelId);\n         putModelDefinition(modelId);\n-        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED);\n \n         String input = \"once twice thrice\";\n         var e = expectThrows(ResponseException.class, () -> EntityUtils.toString(infer(\"once twice thrice\", modelId).getEntity()));\n@@ -846,8 +846,8 @@ public void testStoppingDeploymentShouldTriggerRebalance() throws Exception {\n         putModelDefinition(modelId2);\n         putVocabulary(List.of(\"these\", \"are\", \"my\", \"words\"), modelId2);\n \n-        startDeployment(modelId1, modelId1, AllocationStatus.State.STARTED.toString(), 100, 1, Priority.NORMAL);\n-        startDeployment(modelId2, modelId2, AllocationStatus.State.STARTING.toString(), 1, 1, Priority.NORMAL);\n+        startDeployment(modelId1, modelId1, AllocationStatus.State.STARTED, 100, 1, Priority.NORMAL);\n+        startDeployment(modelId2, modelId2, AllocationStatus.State.STARTING, 1, 1, Priority.NORMAL);\n \n         // Check second model did not get any allocations\n         assertAllocationCount(modelId2, 0);\n@@ -888,7 +888,7 @@ public void testStartDeployment_TooManyAllocations() throws IOException {\n \n         ResponseException ex = expectThrows(\n             ResponseException.class,\n-            () -> startDeployment(modelId, modelId, AllocationStatus.State.STARTED.toString(), 100, 1, Priority.NORMAL)\n+            () -> startDeployment(modelId, modelId, AllocationStatus.State.STARTED, 100, 1, Priority.NORMAL)\n         );\n         assertThat(ex.getResponse().getStatusLine().getStatusCode(), equalTo(429));\n         assertThat(\n@@ -924,7 +924,7 @@ public void testStartDeployment_GivenNoProcessorsLeft_AndLazyStartEnabled() thro\n         putModelDefinition(modelId2);\n         putVocabulary(List.of(\"these\", \"are\", \"my\", \"words\"), modelId2);\n \n-        startDeployment(modelId1, modelId1, AllocationStatus.State.STARTED.toString(), 100, 1, Priority.NORMAL);\n+        startDeployment(modelId1, modelId1, AllocationStatus.State.STARTED, 100, 1, Priority.NORMAL);\n \n         {\n             Request request = new Request(\n@@ -1033,7 +1033,7 @@ public void testUpdateDeployment_GivenAllocationsAreDecreased() throws Exception\n         createPassThroughModel(modelId);\n         putModelDefinition(modelId);\n         putVocabulary(List.of(\"these\", \"are\", \"my\", \"words\"), modelId);\n-        startDeployment(modelId, modelId, \"started\", 2, 1, Priority.NORMAL);\n+        startDeployment(modelId, modelId, AllocationStatus.State.STARTED, 2, 1, Priority.NORMAL);\n \n         assertBusy(() -> assertAllocationCount(modelId, 2));\n \n@@ -1051,7 +1051,7 @@ public void testStartMultipleLowPriorityDeployments() throws Exception {\n             createPassThroughModel(modelId);\n             putModelDefinition(modelId);\n             putVocabulary(List.of(\"these\", \"are\", \"my\", \"words\"), modelId);\n-            startDeployment(modelId, modelId, \"started\", 1, 1, Priority.LOW);\n+            startDeployment(modelId, modelId, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n             assertAllocationCount(modelId, 1);\n         }\n     }"
    },
    {
      "filename": "x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelRestTestCase.java",
      "status": "modified",
      "additions": 4,
      "deletions": 4,
      "changes": 8,
      "patch": "@@ -212,21 +212,21 @@ protected void createTextEmbeddingModel(String modelId) throws IOException {\n     }\n \n     protected Response startDeployment(String modelId) throws IOException {\n-        return startDeployment(modelId, AllocationStatus.State.STARTED.toString());\n+        return startDeployment(modelId, AllocationStatus.State.STARTED);\n     }\n \n     protected Response startWithDeploymentId(String modelId, String deploymentId) throws IOException {\n-        return startDeployment(modelId, deploymentId, AllocationStatus.State.STARTED.toString(), 1, 1, Priority.NORMAL);\n+        return startDeployment(modelId, deploymentId, AllocationStatus.State.STARTED, 1, 1, Priority.NORMAL);\n     }\n \n-    protected Response startDeployment(String modelId, String waitForState) throws IOException {\n+    protected Response startDeployment(String modelId, AllocationStatus.State waitForState) throws IOException {\n         return startDeployment(modelId, null, waitForState, 1, 1, Priority.NORMAL);\n     }\n \n     protected Response startDeployment(\n         String modelId,\n         String deploymentId,\n-        String waitForState,\n+        AllocationStatus.State waitForState,\n         int numberOfAllocations,\n         int threadsPerAllocation,\n         Priority priority"
    }
  ],
  "diff": "diff --git a/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/MultipleDeploymentsIT.java b/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/MultipleDeploymentsIT.java\nindex e78f761756e6a..80f78ac0cf3b5 100644\n--- a/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/MultipleDeploymentsIT.java\n+++ b/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/MultipleDeploymentsIT.java\n@@ -10,6 +10,8 @@\n import org.elasticsearch.client.Response;\n import org.elasticsearch.common.xcontent.support.XContentMapValues;\n import org.elasticsearch.core.Tuple;\n+import org.elasticsearch.xpack.core.ml.inference.assignment.AllocationStatus;\n+import org.elasticsearch.xpack.core.ml.inference.assignment.Priority;\n import org.elasticsearch.xpack.core.ml.utils.MapHelper;\n \n import java.io.IOException;\n@@ -28,13 +30,13 @@ public void testDeployModelMultipleTimes() throws IOException {\n         putAllModelParts(baseModelId);\n \n         String forSearch = \"for-search\";\n-        startWithDeploymentId(baseModelId, forSearch);\n+        startDeployment(baseModelId, forSearch, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n \n         Response inference = infer(\"my words\", forSearch);\n         assertOK(inference);\n \n         String forIngest = \"for-ingest\";\n-        startWithDeploymentId(baseModelId, forIngest);\n+        startDeployment(baseModelId, forIngest, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n \n         inference = infer(\"my words\", forIngest);\n         assertOK(inference);\n@@ -71,12 +73,13 @@ public void testGetStats() throws IOException {\n         String modelWith2Deployments = \"model-with-2-deployments\";\n         putAllModelParts(modelWith2Deployments);\n         String forSearchDeployment = \"for-search\";\n-        startWithDeploymentId(modelWith2Deployments, forSearchDeployment);\n+        startDeployment(modelWith2Deployments, forSearchDeployment, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n+\n         String forIngestDeployment = \"for-ingest\";\n-        startWithDeploymentId(modelWith2Deployments, forIngestDeployment);\n+        startDeployment(modelWith2Deployments, forIngestDeployment, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n \n         // deployment Id is the same as model\n-        startDeployment(modelWith1Deployment);\n+        startDeployment(modelWith1Deployment, modelWith1Deployment, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n \n         {\n             Map<String, Object> stats = entityAsMap(getTrainedModelStats(\"_all\"));\ndiff --git a/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelIT.java b/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelIT.java\nindex a94cf89fbbace..f303e4b708d1d 100644\n--- a/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelIT.java\n+++ b/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelIT.java\n@@ -190,7 +190,7 @@ public void testDeploymentStats() throws IOException {\n         putModelDefinition(modelStarted);\n \n         CheckedBiConsumer<String, AllocationStatus.State, IOException> assertAtLeast = (modelId, state) -> {\n-            startDeployment(modelId, state.toString());\n+            startDeployment(modelId, state);\n             Response response = getTrainedModelStats(modelId);\n             var responseMap = entityAsMap(response);\n             List<Map<String, Object>> stats = (List<Map<String, Object>>) responseMap.get(\"trained_model_stats\");\n@@ -246,7 +246,7 @@ public void testLiveDeploymentStats() throws IOException {\n         createPassThroughModel(modelId);\n         putVocabulary(List.of(\"once\", \"twice\"), modelId);\n         putModelDefinition(modelId);\n-        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED);\n         {\n             Response noInferenceCallsStatsResponse = getTrainedModelStats(modelId);\n             List<Map<String, Object>> stats = (List<Map<String, Object>>) entityAsMap(noInferenceCallsStatsResponse).get(\n@@ -315,7 +315,7 @@ public void testFailedDeploymentStats() throws Exception {\n         request.setJsonEntity(Strings.format(\"\"\"\n             {\"total_definition_length\":%s,\"definition\": \"%s\",\"total_parts\": 1}\"\"\", length, poorlyFormattedModelBase64));\n         client().performRequest(request);\n-        startDeployment(badModel, AllocationStatus.State.STARTING.toString());\n+        startDeployment(badModel, AllocationStatus.State.STARTING);\n         assertBusy(() -> {\n             Response noInferenceCallsStatsResponse = getTrainedModelStats(badModel);\n             List<Map<String, Object>> stats = (List<Map<String, Object>>) entityAsMap(noInferenceCallsStatsResponse).get(\n@@ -340,8 +340,8 @@ public void testGetDeploymentStats_WithWildcard() throws IOException {\n         putVocabulary(List.of(\"once\", \"twice\"), modelBar);\n         putModelDefinition(modelBar);\n \n-        startDeployment(modelFoo, AllocationStatus.State.FULLY_ALLOCATED.toString());\n-        startDeployment(modelBar, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelFoo, AllocationStatus.State.FULLY_ALLOCATED);\n+        startDeployment(modelBar, AllocationStatus.State.FULLY_ALLOCATED);\n         infer(\"once\", modelFoo);\n         infer(\"once\", modelBar);\n         {\n@@ -372,8 +372,8 @@ public void testGetDeploymentStats_WithStartedStoppedDeployments() throws IOExce\n         putVocabulary(List.of(\"once\", \"twice\"), modelBar);\n         putModelDefinition(modelBar);\n \n-        startDeployment(modelFoo, AllocationStatus.State.FULLY_ALLOCATED.toString());\n-        startDeployment(modelBar, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelFoo, AllocationStatus.State.FULLY_ALLOCATED);\n+        startDeployment(modelBar, AllocationStatus.State.FULLY_ALLOCATED);\n         infer(\"once\", modelFoo);\n         infer(\"once\", modelBar);\n \n@@ -447,7 +447,7 @@ public void testInferWithMultipleDocs() throws IOException {\n             client().performRequest(clusterSettings);\n         }\n \n-        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED);\n \n         List<String> inputs = List.of(\n             \"my words\",\n@@ -614,7 +614,7 @@ public void testTruncation() throws IOException {\n \n         putVocabulary(List.of(\"once\", \"twice\", \"thrice\"), modelId);\n         putModelDefinition(modelId);\n-        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED.toString());\n+        startDeployment(modelId, AllocationStatus.State.FULLY_ALLOCATED);\n \n         String input = \"once twice thrice\";\n         var e = expectThrows(ResponseException.class, () -> EntityUtils.toString(infer(\"once twice thrice\", modelId).getEntity()));\n@@ -846,8 +846,8 @@ public void testStoppingDeploymentShouldTriggerRebalance() throws Exception {\n         putModelDefinition(modelId2);\n         putVocabulary(List.of(\"these\", \"are\", \"my\", \"words\"), modelId2);\n \n-        startDeployment(modelId1, modelId1, AllocationStatus.State.STARTED.toString(), 100, 1, Priority.NORMAL);\n-        startDeployment(modelId2, modelId2, AllocationStatus.State.STARTING.toString(), 1, 1, Priority.NORMAL);\n+        startDeployment(modelId1, modelId1, AllocationStatus.State.STARTED, 100, 1, Priority.NORMAL);\n+        startDeployment(modelId2, modelId2, AllocationStatus.State.STARTING, 1, 1, Priority.NORMAL);\n \n         // Check second model did not get any allocations\n         assertAllocationCount(modelId2, 0);\n@@ -888,7 +888,7 @@ public void testStartDeployment_TooManyAllocations() throws IOException {\n \n         ResponseException ex = expectThrows(\n             ResponseException.class,\n-            () -> startDeployment(modelId, modelId, AllocationStatus.State.STARTED.toString(), 100, 1, Priority.NORMAL)\n+            () -> startDeployment(modelId, modelId, AllocationStatus.State.STARTED, 100, 1, Priority.NORMAL)\n         );\n         assertThat(ex.getResponse().getStatusLine().getStatusCode(), equalTo(429));\n         assertThat(\n@@ -924,7 +924,7 @@ public void testStartDeployment_GivenNoProcessorsLeft_AndLazyStartEnabled() thro\n         putModelDefinition(modelId2);\n         putVocabulary(List.of(\"these\", \"are\", \"my\", \"words\"), modelId2);\n \n-        startDeployment(modelId1, modelId1, AllocationStatus.State.STARTED.toString(), 100, 1, Priority.NORMAL);\n+        startDeployment(modelId1, modelId1, AllocationStatus.State.STARTED, 100, 1, Priority.NORMAL);\n \n         {\n             Request request = new Request(\n@@ -1033,7 +1033,7 @@ public void testUpdateDeployment_GivenAllocationsAreDecreased() throws Exception\n         createPassThroughModel(modelId);\n         putModelDefinition(modelId);\n         putVocabulary(List.of(\"these\", \"are\", \"my\", \"words\"), modelId);\n-        startDeployment(modelId, modelId, \"started\", 2, 1, Priority.NORMAL);\n+        startDeployment(modelId, modelId, AllocationStatus.State.STARTED, 2, 1, Priority.NORMAL);\n \n         assertBusy(() -> assertAllocationCount(modelId, 2));\n \n@@ -1051,7 +1051,7 @@ public void testStartMultipleLowPriorityDeployments() throws Exception {\n             createPassThroughModel(modelId);\n             putModelDefinition(modelId);\n             putVocabulary(List.of(\"these\", \"are\", \"my\", \"words\"), modelId);\n-            startDeployment(modelId, modelId, \"started\", 1, 1, Priority.LOW);\n+            startDeployment(modelId, modelId, AllocationStatus.State.STARTED, 1, 1, Priority.LOW);\n             assertAllocationCount(modelId, 1);\n         }\n     }\ndiff --git a/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelRestTestCase.java b/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelRestTestCase.java\nindex 94773c0b78b2a..5b79e647a2e4f 100644\n--- a/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelRestTestCase.java\n+++ b/x-pack/plugin/ml/qa/native-multi-node-tests/src/javaRestTest/java/org/elasticsearch/xpack/ml/integration/PyTorchModelRestTestCase.java\n@@ -212,21 +212,21 @@ protected void createTextEmbeddingModel(String modelId) throws IOException {\n     }\n \n     protected Response startDeployment(String modelId) throws IOException {\n-        return startDeployment(modelId, AllocationStatus.State.STARTED.toString());\n+        return startDeployment(modelId, AllocationStatus.State.STARTED);\n     }\n \n     protected Response startWithDeploymentId(String modelId, String deploymentId) throws IOException {\n-        return startDeployment(modelId, deploymentId, AllocationStatus.State.STARTED.toString(), 1, 1, Priority.NORMAL);\n+        return startDeployment(modelId, deploymentId, AllocationStatus.State.STARTED, 1, 1, Priority.NORMAL);\n     }\n \n-    protected Response startDeployment(String modelId, String waitForState) throws IOException {\n+    protected Response startDeployment(String modelId, AllocationStatus.State waitForState) throws IOException {\n         return startDeployment(modelId, null, waitForState, 1, 1, Priority.NORMAL);\n     }\n \n     protected Response startDeployment(\n         String modelId,\n         String deploymentId,\n-        String waitForState,\n+        AllocationStatus.State waitForState,\n         int numberOfAllocations,\n         int threadsPerAllocation,\n         Priority priority\n",
  "additions": 27,
  "deletions": 24,
  "changed_files": 3,
  "url": "https://github.com/elastic/elasticsearch/pull/95490",
  "mined_at": "2025-10-25T13:11:26.593453"
}