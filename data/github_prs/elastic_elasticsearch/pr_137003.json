{
  "id": 137003,
  "repository": "elastic/elasticsearch",
  "title": "Avoid double allocation when compressing histograms",
  "body": "Follow up for https://github.com/elastic/elasticsearch/pull/136936#discussion_r2454290057 (I pressed merge to early...).\r\nFortunately for us, the JVM devs in the early days made the \"mistake\" of exposing the `ByteArrayOutputStream`-internals, so we can avoid the double-allocation.\r\n",
  "state": "closed",
  "merged": true,
  "merged_at": "2025-10-24T08:37:43+00:00",
  "created_at": "2025-10-23T08:47:00+00:00",
  "updated_at": "2025-10-24T08:50:35+00:00",
  "author": "JonasKunz",
  "reviewers": [
    "martijnvg",
    "felixbarny"
  ],
  "base_sha": "88d4704a9a48e0c58dcb16d7f6efac2612b12901",
  "head_sha": "53ee107ae8bfaa8cf81f2b976b0ccdd5b4a82087",
  "review_comments": [
    {
      "user": "felixbarny",
      "state": "APPROVED",
      "body": "",
      "submitted_at": "2025-10-23T09:39:20+00:00"
    },
    {
      "user": "martijnvg",
      "state": "APPROVED",
      "body": "LGTM, re-using that buffer with size should be safe.",
      "submitted_at": "2025-10-24T07:17:35+00:00"
    }
  ],
  "pr_comments": [
    {
      "user": "elasticsearchmachine",
      "body": "Pinging @elastic/es-storage-engine (Team:StorageEngine)",
      "created_at": "2025-10-23T08:47:25+00:00"
    }
  ],
  "files_changed": [
    {
      "filename": "libs/exponential-histogram/src/main/java/org/elasticsearch/exponentialhistogram/CompressedHistogramData.java",
      "status": "modified",
      "additions": 11,
      "deletions": 4,
      "changes": 15,
      "patch": "@@ -117,11 +117,10 @@ static void write(OutputStream output, int scale, BucketIterator negativeBuckets\n         }\n         output.write((byte) scaleWithFlags);\n         if (hasNegativeBuckets) {\n-            ByteArrayOutputStream temp = new ByteArrayOutputStream();\n+            AccessibleByteArrayOutputStream temp = new AccessibleByteArrayOutputStream();\n             BucketsDecoder.serializeBuckets(temp, negativeBuckets);\n-            byte[] data = temp.toByteArray();\n-            writeVLong(data.length, output);\n-            output.write(data);\n+            writeVLong(temp.size(), output);\n+            output.write(temp.getBufferDirect(), 0, temp.size());\n         }\n         BucketsDecoder.serializeBuckets(output, positiveBuckets);\n     }\n@@ -252,6 +251,14 @@ private static void serializeBuckets(OutputStream out, BucketIterator buckets) t\n         }\n     }\n \n+    private static class AccessibleByteArrayOutputStream extends ByteArrayOutputStream {\n+\n+        byte[] getBufferDirect() {\n+            return buf;\n+        }\n+\n+    }\n+\n     private static class AccessibleByteArrayStreamInput extends ByteArrayInputStream {\n \n         AccessibleByteArrayStreamInput(byte[] buf, int offset, int length) {"
    }
  ],
  "diff": "diff --git a/libs/exponential-histogram/src/main/java/org/elasticsearch/exponentialhistogram/CompressedHistogramData.java b/libs/exponential-histogram/src/main/java/org/elasticsearch/exponentialhistogram/CompressedHistogramData.java\nindex 8c80a6578f736..1bc48fad5e720 100644\n--- a/libs/exponential-histogram/src/main/java/org/elasticsearch/exponentialhistogram/CompressedHistogramData.java\n+++ b/libs/exponential-histogram/src/main/java/org/elasticsearch/exponentialhistogram/CompressedHistogramData.java\n@@ -117,11 +117,10 @@ static void write(OutputStream output, int scale, BucketIterator negativeBuckets\n         }\n         output.write((byte) scaleWithFlags);\n         if (hasNegativeBuckets) {\n-            ByteArrayOutputStream temp = new ByteArrayOutputStream();\n+            AccessibleByteArrayOutputStream temp = new AccessibleByteArrayOutputStream();\n             BucketsDecoder.serializeBuckets(temp, negativeBuckets);\n-            byte[] data = temp.toByteArray();\n-            writeVLong(data.length, output);\n-            output.write(data);\n+            writeVLong(temp.size(), output);\n+            output.write(temp.getBufferDirect(), 0, temp.size());\n         }\n         BucketsDecoder.serializeBuckets(output, positiveBuckets);\n     }\n@@ -252,6 +251,14 @@ private static void serializeBuckets(OutputStream out, BucketIterator buckets) t\n         }\n     }\n \n+    private static class AccessibleByteArrayOutputStream extends ByteArrayOutputStream {\n+\n+        byte[] getBufferDirect() {\n+            return buf;\n+        }\n+\n+    }\n+\n     private static class AccessibleByteArrayStreamInput extends ByteArrayInputStream {\n \n         AccessibleByteArrayStreamInput(byte[] buf, int offset, int length) {\n",
  "additions": 11,
  "deletions": 4,
  "changed_files": 1,
  "url": "https://github.com/elastic/elasticsearch/pull/137003",
  "mined_at": "2025-10-25T13:34:21.540501"
}