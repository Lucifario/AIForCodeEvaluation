diff --git a/modules/data-streams/src/internalClusterTest/java/org/elasticsearch/datastreams/TSDBSyntheticIdsIT.java b/modules/data-streams/src/internalClusterTest/java/org/elasticsearch/datastreams/TSDBSyntheticIdsIT.java
new file mode 100644
index 0000000000000..b0d14d0d80221
--- /dev/null
+++ b/modules/data-streams/src/internalClusterTest/java/org/elasticsearch/datastreams/TSDBSyntheticIdsIT.java
@@ -0,0 +1,279 @@
+/*
+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+ * or more contributor license agreements. Licensed under the "Elastic License
+ * 2.0", the "GNU Affero General Public License v3.0 only", and the "Server Side
+ * Public License v 1"; you may not use this file except in compliance with, at
+ * your election, the "Elastic License 2.0", the "GNU Affero General Public
+ * License v3.0 only", or the "Server Side Public License, v 1".
+ */
+
+package org.elasticsearch.datastreams;
+
+import org.apache.lucene.tests.util.LuceneTestCase;
+import org.elasticsearch.action.DocWriteRequest;
+import org.elasticsearch.action.DocWriteResponse;
+import org.elasticsearch.action.admin.indices.diskusage.AnalyzeIndexDiskUsageRequest;
+import org.elasticsearch.action.admin.indices.diskusage.AnalyzeIndexDiskUsageTestUtils;
+import org.elasticsearch.action.admin.indices.diskusage.IndexDiskUsageStats;
+import org.elasticsearch.action.admin.indices.diskusage.TransportAnalyzeIndexDiskUsageAction;
+import org.elasticsearch.action.admin.indices.template.put.TransportPutComposableIndexTemplateAction;
+import org.elasticsearch.action.bulk.BulkItemResponse;
+import org.elasticsearch.cluster.metadata.ComposableIndexTemplate;
+import org.elasticsearch.cluster.metadata.Template;
+import org.elasticsearch.common.compress.CompressedXContent;
+import org.elasticsearch.common.time.DateFormatter;
+import org.elasticsearch.index.IndexMode;
+import org.elasticsearch.index.IndexSettings;
+import org.elasticsearch.index.mapper.IdFieldMapper;
+import org.elasticsearch.plugins.Plugin;
+import org.elasticsearch.test.ESIntegTestCase;
+import org.elasticsearch.test.InternalSettingsPlugin;
+import org.elasticsearch.test.junit.annotations.TestLogging;
+import org.elasticsearch.xcontent.XContentBuilder;
+import org.elasticsearch.xcontent.XContentFactory;
+
+import java.io.IOException;
+import java.time.Instant;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Random;
+
+import static org.elasticsearch.common.time.FormatNames.STRICT_DATE_OPTIONAL_TIME;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.notNullValue;
+
+/**
+ * Test suite for time series indices that use synthetic ids for documents.
+ * <p>
+ * Synthetic _id fields are not indexed in Lucene, instead they are generated on demand by concatenating the values of two other fields of
+ * the document (typically the {@code @timestamp} and {@code _tsid} fields).
+ * </p>
+ */
+@LuceneTestCase.SuppressCodecs("*") // requires codecs used in production only
+public class TSDBSyntheticIdsIT extends ESIntegTestCase {
+
+    private static final DateFormatter DATE_FORMATTER = DateFormatter.forPattern(STRICT_DATE_OPTIONAL_TIME.getName());
+
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        var plugins = new ArrayList<>(super.nodePlugins());
+        plugins.add(InternalSettingsPlugin.class);
+        plugins.add(DataStreamsPlugin.class);
+        return plugins;
+    }
+
+    public void testInvalidIndexMode() {
+        assumeTrue("Test should only run with feature flag", IndexSettings.TSDB_SYNTHETIC_ID_FEATURE_FLAG);
+        final var indexName = randomIdentifier();
+        var randomNonTsdbIndexMode = randomValueOtherThan(IndexMode.TIME_SERIES, () -> randomFrom(IndexMode.values()));
+
+        var exception = expectThrows(
+            IllegalArgumentException.class,
+            () -> createIndex(
+                indexName,
+                indexSettings(1, 0).put(IndexSettings.MODE.getKey(), randomNonTsdbIndexMode)
+                    .put(IndexSettings.USE_SYNTHETIC_ID.getKey(), true)
+                    .build()
+            )
+        );
+        assertThat(
+            exception.getMessage(),
+            containsString(
+                "The setting ["
+                    + IndexSettings.USE_SYNTHETIC_ID.getKey()
+                    + "] is only permitted when [index.mode] is set to [TIME_SERIES]. Current mode: ["
+                    + randomNonTsdbIndexMode.getName().toUpperCase(Locale.ROOT)
+                    + "]."
+            )
+        );
+    }
+
+    @TestLogging(reason = "debug", value = "org.elasticsearch.index.engine.Engine:TRACE")
+    public void testSyntheticId() throws Exception {
+        assumeTrue("Test should only run with feature flag", IndexSettings.TSDB_SYNTHETIC_ID_FEATURE_FLAG);
+        final var indexName = randomIdentifier();
+        putDataStreamTemplate(random(), indexName);
+
+        final var timestamp = Instant.now();
+
+        // Index 5 docs in datastream
+        var results = createDocuments(
+            indexName,
+            document(timestamp, "vm-dev01", "cpu-load", 0),                                // will be updated
+            document(timestamp.plusSeconds(2), "vm-dev01", "cpu-load", 1),    // will be deleted
+            document(timestamp, "vm-dev02", "cpu-load", 2),
+            document(timestamp.plusSeconds(2), "vm-dev03", "cpu-load", 3),
+            document(timestamp.plusSeconds(3), "vm-dev03", "cpu-load", 4)
+        );
+
+        // Verify documents
+        assertThat(results[0].getResponse().getResult(), equalTo(DocWriteResponse.Result.CREATED));
+        assertThat(results[0].getVersion(), equalTo(1L));
+
+        assertThat(results[1].getResponse().getResult(), equalTo(DocWriteResponse.Result.CREATED));
+        assertThat(results[1].getVersion(), equalTo(1L));
+
+        assertThat(results[2].getResponse().getResult(), equalTo(DocWriteResponse.Result.CREATED));
+        assertThat(results[2].getVersion(), equalTo(1L));
+
+        assertThat(results[3].getResponse().getResult(), equalTo(DocWriteResponse.Result.CREATED));
+        assertThat(results[3].getVersion(), equalTo(1L));
+
+        assertThat(results[4].getResponse().getResult(), equalTo(DocWriteResponse.Result.CREATED));
+        assertThat(results[4].getVersion(), equalTo(1L));
+
+        final var docIndex = results[1].getIndex();
+        final var docId = results[1].getId();
+
+        enum Operation {
+            FLUSH,
+            REFRESH,
+            NONE
+        }
+        switch (randomFrom(Operation.values())) {
+            case FLUSH:
+                flush(indexName);
+                break;
+            case REFRESH:
+                refresh(indexName);
+                break;
+            case NONE:
+            default:
+                break;
+        }
+
+        // Get by synthetic _id
+        // Note: before synthetic _id this would have required postings on disks
+        var getResponse = client().prepareGet(docIndex, docId).setFetchSource(true).execute().actionGet();
+        assertThat(getResponse.isExists(), equalTo(true));
+        assertThat(getResponse.getVersion(), equalTo(1L));
+        var source = asInstanceOf(Map.class, getResponse.getSourceAsMap().get("metric"));
+        assertThat(asInstanceOf(Integer.class, source.get("value")), equalTo(1));
+
+        // Update by synthetic _id
+        // Note: it doesn't work, is that expected? Is is blocked by IndexRouting.ExtractFromSource.updateShard
+        var exception = expectThrows(IllegalArgumentException.class, () -> {
+            var doc = document(timestamp, "vm-dev01", "cpu-load", 10); // update
+            client().prepareUpdate(docIndex, docId).setDoc(doc).get();
+        });
+        assertThat(
+            exception.getMessage(),
+            containsString("update is not supported because the destination index [" + docIndex + "] is in time_series mode")
+        );
+
+        // Delete by synthetic _id
+        var deleteResponse = client().prepareDelete(docIndex, docId).get();
+        assertThat(deleteResponse.getId(), equalTo(docId));
+        assertThat(deleteResponse.getResult(), equalTo(DocWriteResponse.Result.DELETED));
+        assertThat(deleteResponse.getVersion(), equalTo(2L));
+
+        // Index more docs
+        // TODO Randomize this to have segments only composed of deleted docs
+        createDocuments(
+            indexName,
+            document(timestamp.plusSeconds(4), "vm-dev03", "cpu-load", 5),
+            document(timestamp.plusSeconds(5), "vm-dev03", "cpu-load", 6)
+        );
+
+        flushAndRefresh(indexName);
+
+        // Check that synthetic _id field has no postings on disk
+        var diskUsage = diskUsage(docIndex);
+        var diskUsageIdField = AnalyzeIndexDiskUsageTestUtils.getPerFieldDiskUsage(diskUsage, IdFieldMapper.NAME);
+        assertThat("_id field should not have postings on disk", diskUsageIdField.getInvertedIndexBytes(), equalTo(0L));
+
+        // TODO Search datastream and count hits
+    }
+
+    private static XContentBuilder document(Instant timestamp, String hostName, String metricField, Integer metricValue)
+        throws IOException {
+        var source = XContentFactory.jsonBuilder();
+        source.startObject();
+        {
+            source.field("@timestamp", DATE_FORMATTER.format(timestamp));
+            source.field("hostname", hostName);
+            source.startObject("metric");
+            {
+                source.field("field", metricField);
+                source.field("value", metricValue);
+
+            }
+            source.endObject();
+        }
+        source.endObject();
+        return source;
+    }
+
+    private static BulkItemResponse[] createDocuments(String indexName, XContentBuilder... docs) throws IOException {
+        assertThat(docs, notNullValue());
+        final var client = client();
+        var bulkRequest = client.prepareBulk();
+        for (var doc : docs) {
+            bulkRequest.add(client.prepareIndex(indexName).setOpType(DocWriteRequest.OpType.CREATE).setSource(doc));
+        }
+        var bulkResponse = bulkRequest.get();
+        assertNoFailures(bulkResponse);
+        return bulkResponse.getItems();
+    }
+
+    private static void putDataStreamTemplate(Random random, String indexPattern) throws IOException {
+        final var settings = indexSettings(1, 0).put(IndexSettings.MODE.getKey(), IndexMode.TIME_SERIES.getName())
+            .put(IndexSettings.BLOOM_FILTER_ID_FIELD_ENABLED_SETTING.getKey(), false)
+            .put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), -1)
+            .put(IndexSettings.USE_SYNTHETIC_ID.getKey(), true);
+
+        final var mappings = """
+            {
+                "_doc": {
+                    "properties": {
+                        "@timestamp": {
+                            "type": "date"
+                        },
+                        "hostname": {
+                            "type": "keyword",
+                            "time_series_dimension": true
+                        },
+                        "metric": {
+                            "properties": {
+                                "field": {
+                                    "type": "keyword",
+                                    "time_series_dimension": true
+                                },
+                                "value": {
+                                    "type": "integer",
+                                    "time_series_metric": "counter"
+                                }
+                            }
+                        }
+                    }
+                }
+            }""";
+
+        var putTemplateRequest = new TransportPutComposableIndexTemplateAction.Request(getTestClass().getName().toLowerCase(Locale.ROOT))
+            .indexTemplate(
+                ComposableIndexTemplate.builder()
+                    .indexPatterns(List.of(indexPattern))
+                    .template(new Template(settings.build(), new CompressedXContent(mappings), null))
+                    .dataStreamTemplate(new ComposableIndexTemplate.DataStreamTemplate(false, false))
+                    .build()
+            );
+        assertAcked(client().execute(TransportPutComposableIndexTemplateAction.TYPE, putTemplateRequest).actionGet());
+    }
+
+    private static IndexDiskUsageStats diskUsage(String indexName) {
+        var diskUsageResponse = client().execute(
+            TransportAnalyzeIndexDiskUsageAction.TYPE,
+            new AnalyzeIndexDiskUsageRequest(new String[] { indexName }, AnalyzeIndexDiskUsageRequest.DEFAULT_INDICES_OPTIONS, false)
+        ).actionGet();
+
+        var indexDiskUsageStats = AnalyzeIndexDiskUsageTestUtils.getIndexStats(diskUsageResponse, indexName);
+        assertNotNull(indexDiskUsageStats);
+        return indexDiskUsageStats;
+    }
+}
diff --git a/server/src/main/java/org/elasticsearch/common/settings/IndexScopedSettings.java b/server/src/main/java/org/elasticsearch/common/settings/IndexScopedSettings.java
index 56357357af13a..d18fdc2702d56 100644
--- a/server/src/main/java/org/elasticsearch/common/settings/IndexScopedSettings.java
+++ b/server/src/main/java/org/elasticsearch/common/settings/IndexScopedSettings.java
@@ -246,6 +246,9 @@ public final class IndexScopedSettings extends AbstractScopedSettings {
         if (IndexSettings.DOC_VALUES_SKIPPER) {
             settings.add(IndexSettings.USE_DOC_VALUES_SKIPPER);
         }
+        if (IndexSettings.TSDB_SYNTHETIC_ID_FEATURE_FLAG) {
+            settings.add(IndexSettings.USE_SYNTHETIC_ID);
+        }
         settings.add(IndexSettings.INDEX_MAPPING_EXCLUDE_SOURCE_VECTORS_SETTING);
         BUILT_IN_INDEX_SETTINGS = Collections.unmodifiableSet(settings);
     };
diff --git a/server/src/main/java/org/elasticsearch/index/IndexSettings.java b/server/src/main/java/org/elasticsearch/index/IndexSettings.java
index 2abfc8348b9ce..a5fd8144c5492 100644
--- a/server/src/main/java/org/elasticsearch/index/IndexSettings.java
+++ b/server/src/main/java/org/elasticsearch/index/IndexSettings.java
@@ -676,6 +676,44 @@ public boolean isES87TSDBCodecEnabled() {
         Property.Final
     );
 
+    public static final boolean TSDB_SYNTHETIC_ID_FEATURE_FLAG = new FeatureFlag("tsdb_synthetic_id").isEnabled();
+    public static final Setting<Boolean> USE_SYNTHETIC_ID = Setting.boolSetting(
+        "index.mapping.use_synthetic_id",
+        false,
+        new Setting.Validator<>() {
+            @Override
+            public void validate(Boolean value) {}
+
+            @Override
+            public void validate(Boolean enabled, Map<Setting<?>, Object> settings) {
+                if (enabled) {
+                    // Verify if index mode is TIME_SERIES
+                    var indexMode = (IndexMode) settings.get(MODE);
+                    if (indexMode != IndexMode.TIME_SERIES) {
+                        throw new IllegalArgumentException(
+                            String.format(
+                                Locale.ROOT,
+                                "The setting [%s] is only permitted when [%s] is set to [%s]. Current mode: [%s].",
+                                USE_SYNTHETIC_ID.getKey(),
+                                MODE.getKey(),
+                                IndexMode.TIME_SERIES.name(),
+                                indexMode.name()
+                            )
+                        );
+                    }
+                }
+            }
+
+            @Override
+            public Iterator<Setting<?>> settings() {
+                List<Setting<?>> list = List.of(MODE);
+                return list.iterator();
+            }
+        },
+        Property.IndexScope,
+        Property.Final
+    );
+
     /**
      * The {@link IndexMode "mode"} of the index.
      */
@@ -937,6 +975,7 @@ private void setRetentionLeaseMillis(final TimeValue retentionLease) {
     private final boolean recoverySourceEnabled;
     private final boolean recoverySourceSyntheticEnabled;
     private final boolean useDocValuesSkipper;
+    private final boolean tsdbSyntheticId;
 
     /**
      * The maximum number of refresh listeners allows on this shard.
@@ -1123,6 +1162,8 @@ public IndexSettings(final IndexMetadata indexMetadata, final Settings nodeSetti
             && scopedSettings.get(RECOVERY_USE_SYNTHETIC_SOURCE_SETTING);
         useDocValuesSkipper = DOC_VALUES_SKIPPER && scopedSettings.get(USE_DOC_VALUES_SKIPPER);
         seqNoIndexOptions = scopedSettings.get(SEQ_NO_INDEX_OPTIONS_SETTING);
+        tsdbSyntheticId = TSDB_SYNTHETIC_ID_FEATURE_FLAG && scopedSettings.get(USE_SYNTHETIC_ID);
+        assert tsdbSyntheticId == false || mode == IndexMode.TIME_SERIES : mode;
         if (recoverySourceSyntheticEnabled) {
             if (DiscoveryNode.isStateless(settings)) {
                 throw new IllegalArgumentException("synthetic recovery source is only allowed in stateful");
@@ -1855,6 +1896,13 @@ public boolean useDocValuesSkipper() {
         return useDocValuesSkipper;
     }
 
+    /**
+     * @return Whether the index is a time-series index that use synthetic ids.
+     */
+    public boolean useTsdbSyntheticId() {
+        return tsdbSyntheticId;
+    }
+
     /**
      * The bounds for {@code @timestamp} on this index or
      * {@code null} if there are no bounds.
diff --git a/server/src/main/java/org/elasticsearch/index/codec/CodecService.java b/server/src/main/java/org/elasticsearch/index/codec/CodecService.java
index 17028137b78d8..1e2fed61578a5 100644
--- a/server/src/main/java/org/elasticsearch/index/codec/CodecService.java
+++ b/server/src/main/java/org/elasticsearch/index/codec/CodecService.java
@@ -16,6 +16,8 @@
 import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.common.util.FeatureFlag;
 import org.elasticsearch.core.Nullable;
+import org.elasticsearch.index.IndexMode;
+import org.elasticsearch.index.codec.tsdb.TSDBSyntheticIdCodec;
 import org.elasticsearch.index.codec.zstd.Zstd814StoredFieldsFormat;
 import org.elasticsearch.index.mapper.MapperService;
 
@@ -65,12 +67,20 @@ public CodecService(@Nullable MapperService mapperService, BigArrays bigArrays)
         for (String codec : Codec.availableCodecs()) {
             codecs.put(codec, Codec.forName(codec));
         }
+        final boolean useTsdbSyntheticId = mapperService != null && mapperService.getIndexSettings().useTsdbSyntheticId();
+        assert useTsdbSyntheticId == false || mapperService.getIndexSettings().getMode() == IndexMode.TIME_SERIES;
+
         this.codecs = codecs.entrySet().stream().collect(Collectors.toUnmodifiableMap(Map.Entry::getKey, e -> {
-            var codec = e.getValue();
-            if (codec instanceof DeduplicateFieldInfosCodec) {
-                return codec;
+            Codec codec;
+            if (e.getValue() instanceof DeduplicateFieldInfosCodec dedupCodec) {
+                codec = dedupCodec;
+            } else {
+                codec = new DeduplicateFieldInfosCodec(e.getValue().getName(), e.getValue());
+            }
+            if (useTsdbSyntheticId && codec instanceof TSDBSyntheticIdCodec == false) {
+                codec = new TSDBSyntheticIdCodec(codec.getName(), codec);
             }
-            return new DeduplicateFieldInfosCodec(codec.getName(), codec);
+            return codec;
         }));
     }
 
diff --git a/server/src/main/java/org/elasticsearch/index/codec/tsdb/TSDBSyntheticIdCodec.java b/server/src/main/java/org/elasticsearch/index/codec/tsdb/TSDBSyntheticIdCodec.java
new file mode 100644
index 0000000000000..970664844631a
--- /dev/null
+++ b/server/src/main/java/org/elasticsearch/index/codec/tsdb/TSDBSyntheticIdCodec.java
@@ -0,0 +1,158 @@
+/*
+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+ * or more contributor license agreements. Licensed under the "Elastic License
+ * 2.0", the "GNU Affero General Public License v3.0 only", and the "Server Side
+ * Public License v 1"; you may not use this file except in compliance with, at
+ * your election, the "Elastic License 2.0", the "GNU Affero General Public
+ * License v3.0 only", or the "Server Side Public License, v 1".
+ */
+
+package org.elasticsearch.index.codec.tsdb;
+
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.codecs.FieldInfosFormat;
+import org.apache.lucene.codecs.FilterCodec;
+import org.apache.lucene.codecs.perfield.PerFieldPostingsFormat;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexOptions;
+import org.apache.lucene.index.SegmentInfo;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IOContext;
+import org.elasticsearch.index.mapper.SyntheticIdField;
+
+import java.io.IOException;
+import java.util.HashMap;
+
+import static org.elasticsearch.index.codec.tsdb.TSDBSyntheticIdPostingsFormat.SYNTHETIC_ID;
+import static org.elasticsearch.index.codec.tsdb.TSDBSyntheticIdPostingsFormat.TIMESTAMP;
+import static org.elasticsearch.index.codec.tsdb.TSDBSyntheticIdPostingsFormat.TS_ID;
+
+/**
+ * Special codec for time-series datastreams that use synthetic ids.
+ * <p>
+ *     The role of this codec is to ensure that no inverted index is created when indexing a document id in Lucene, while allowing the usage
+ *     of terms and postings on the field (now called a "synthetic _id" field) as if it was backed by an in inverted index.
+ * </p>
+ * <p>
+ *     In order to do this, it enforces synthetic _id fields to be indexed with the {@link IndexOptions#NONE} option, hence preventing the
+ *     building of a term dictionary with postings lists. The codec also changes this {@link IndexOptions#NONE} option back to
+ *     {@link IndexOptions#DOCS} when reading the {@link FieldInfos} during the opening of a new segment core reader. This allows to use a
+ *     Lucene term dictionary on top of a synthetic _id field that does not have corresponding postings files on disk. Finally, the codec
+ *     injects additional {@link FieldInfos} attributes so that Lucene's {@link PerFieldPostingsFormat} correctly instantiates a
+ *     {@link TSDBSyntheticIdPostingsFormat} to access the term and postings of the synthetic _id field.
+ * </p>
+ */
+public class TSDBSyntheticIdCodec extends FilterCodec {
+
+    private final TSDBSyntheticIdFieldInfosFormat fieldInfosFormat;
+
+    public TSDBSyntheticIdCodec(String name, Codec delegate) {
+        super(name, delegate);
+        this.fieldInfosFormat = new TSDBSyntheticIdFieldInfosFormat(delegate.fieldInfosFormat());
+    }
+
+    @Override
+    public final FieldInfosFormat fieldInfosFormat() {
+        return fieldInfosFormat;
+    }
+
+    /**
+     * {@link FieldInfosFormat} that ensures the _id field is synthetic
+     */
+    private static class TSDBSyntheticIdFieldInfosFormat extends FieldInfosFormat {
+
+        private final FieldInfosFormat delegate;
+
+        private TSDBSyntheticIdFieldInfosFormat(FieldInfosFormat delegate) {
+            this.delegate = delegate;
+        }
+
+        private void ensureSyntheticIdFields(FieldInfos fieldInfos) {
+            // Ensure _tsid exists
+            var fi = fieldInfos.fieldInfo(TS_ID);
+            if (fi == null) {
+                var message = "Field [" + TS_ID + "] does not exist";
+                assert false : message;
+                throw new IllegalArgumentException(message);
+            }
+            // Ensure @timestamp exists
+            fi = fieldInfos.fieldInfo(TIMESTAMP);
+            if (fi == null) {
+                var message = "Field [" + TIMESTAMP + "] does not exist";
+                assert false : message;
+                throw new IllegalArgumentException(message);
+            }
+            // Ensure _id exists and not indexed
+            fi = fieldInfos.fieldInfo(SYNTHETIC_ID);
+            if (fi == null) {
+                var message = "Field [" + SYNTHETIC_ID + "] does not exist";
+                assert false : message;
+                throw new IllegalArgumentException(message);
+            }
+            if (fi.getIndexOptions() != IndexOptions.NONE) {
+                assert false;
+                throw new IllegalArgumentException("Field [" + SYNTHETIC_ID + "] has incorrect index options");
+            }
+            if (SyntheticIdField.hasSyntheticIdAttributes(fi.attributes()) == false) {
+                throw new IllegalArgumentException("Field [" + SYNTHETIC_ID + "] is not synthetic");
+            }
+        }
+
+        @Override
+        public void write(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, FieldInfos fieldInfos, IOContext context)
+            throws IOException {
+            ensureSyntheticIdFields(fieldInfos);
+            delegate.write(directory, segmentInfo, segmentSuffix, fieldInfos, context);
+        }
+
+        @Override
+        public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {
+            final var fieldInfos = delegate.read(directory, segmentInfo, segmentSuffix, iocontext);
+            ensureSyntheticIdFields(fieldInfos);
+
+            // Change the _id field index options from IndexOptions.NONE to IndexOptions.DOCS, so that terms and postings work when
+            // applying doc values updates in Lucene.
+            final var infos = new FieldInfo[fieldInfos.size()];
+            int i = 0;
+            for (FieldInfo fi : fieldInfos) {
+                if (SYNTHETIC_ID.equals(fi.getName())) {
+                    final var attributes = new HashMap<>(fi.attributes());
+
+                    // Assert that PerFieldPostingsFormat are not written to field infos on disk
+                    assert attributes.containsKey(PerFieldPostingsFormat.PER_FIELD_FORMAT_KEY) == false;
+                    assert attributes.containsKey(PerFieldPostingsFormat.PER_FIELD_SUFFIX_KEY) == false;
+
+                    // Inject attributes so that PerFieldPostingsFormat maps the synthetic _id field to the TSDBSyntheticIdPostingsFormat
+                    // This would normally be handled transparently by PerFieldPostingsFormat, but such attributes are only added if terms
+                    // are produced during indexing, which is not the case for the synthetic _id field.
+                    attributes.put(PerFieldPostingsFormat.PER_FIELD_FORMAT_KEY, TSDBSyntheticIdPostingsFormat.FORMAT_NAME);
+                    attributes.put(PerFieldPostingsFormat.PER_FIELD_SUFFIX_KEY, TSDBSyntheticIdPostingsFormat.SUFFIX);
+
+                    fi = new FieldInfo(
+                        fi.getName(),
+                        fi.getFieldNumber(),
+                        fi.hasTermVectors(),
+                        true,
+                        fi.hasPayloads(),
+                        IndexOptions.DOCS,
+                        fi.getDocValuesType(),
+                        fi.docValuesSkipIndexType(),
+                        fi.getDocValuesGen(),
+                        attributes,
+                        fi.getPointDimensionCount(),
+                        fi.getPointIndexDimensionCount(),
+                        fi.getPointNumBytes(),
+                        fi.getVectorDimension(),
+                        fi.getVectorEncoding(),
+                        fi.getVectorSimilarityFunction(),
+                        fi.isSoftDeletesField(),
+                        fi.isParentField()
+                    );
+                }
+                infos[i++] = fi;
+            }
+            return new FieldInfos(infos);
+        }
+    }
+}
diff --git a/server/src/main/java/org/elasticsearch/index/codec/tsdb/TSDBSyntheticIdFieldsProducer.java b/server/src/main/java/org/elasticsearch/index/codec/tsdb/TSDBSyntheticIdFieldsProducer.java
new file mode 100644
index 0000000000000..2f624fd2d9cd0
--- /dev/null
+++ b/server/src/main/java/org/elasticsearch/index/codec/tsdb/TSDBSyntheticIdFieldsProducer.java
@@ -0,0 +1,390 @@
+/*
+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+ * or more contributor license agreements. Licensed under the "Elastic License
+ * 2.0", the "GNU Affero General Public License v3.0 only", and the "Server Side
+ * Public License v 1"; you may not use this file except in compliance with, at
+ * your election, the "Elastic License 2.0", the "GNU Affero General Public
+ * License v3.0 only", or the "Server Side Public License, v 1".
+ */
+
+package org.elasticsearch.index.codec.tsdb;
+
+import org.apache.lucene.codecs.DocValuesProducer;
+import org.apache.lucene.codecs.FieldsProducer;
+import org.apache.lucene.index.BaseTermsEnum;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.ImpactsEnum;
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SortedDocValues;
+import org.apache.lucene.index.SortedNumericDocValues;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.util.BytesRef;
+import org.elasticsearch.core.IOUtils;
+import org.elasticsearch.index.mapper.TimeSeriesRoutingHashFieldMapper;
+import org.elasticsearch.index.mapper.TsidExtractingIdFieldMapper;
+import org.elasticsearch.index.mapper.Uid;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.util.Iterator;
+import java.util.Objects;
+import java.util.Set;
+
+import static org.elasticsearch.index.codec.tsdb.TSDBSyntheticIdPostingsFormat.SYNTHETIC_ID;
+import static org.elasticsearch.index.codec.tsdb.TSDBSyntheticIdPostingsFormat.TIMESTAMP;
+import static org.elasticsearch.index.codec.tsdb.TSDBSyntheticIdPostingsFormat.TS_ID;
+
+public class TSDBSyntheticIdFieldsProducer extends FieldsProducer {
+
+    private static final Set<String> FIELDS_NAMES = Set.of(SYNTHETIC_ID);
+
+    private final DocValuesProducer docValuesProducer;
+    private final FieldInfos fieldInfos;
+    private final int maxDocs;
+
+    public TSDBSyntheticIdFieldsProducer(SegmentReadState state, DocValuesProducer docValuesProducer) {
+        this(state.fieldInfos, docValuesProducer, state.segmentInfo.maxDoc());
+    }
+
+    private TSDBSyntheticIdFieldsProducer(FieldInfos fieldInfos, DocValuesProducer docValuesProducer, int maxDocs) {
+        assert assertFieldInfosExist(fieldInfos, SYNTHETIC_ID, TIMESTAMP, TS_ID);
+        this.docValuesProducer = Objects.requireNonNull(docValuesProducer);
+        this.fieldInfos = fieldInfos;
+        this.maxDocs = maxDocs;
+    }
+
+    @Override
+    public int size() {
+        return FIELDS_NAMES.size();
+    }
+
+    @Override
+    public Iterator<String> iterator() {
+        return FIELDS_NAMES.iterator();
+    }
+
+    @Override
+    public void close() throws IOException {
+        IOUtils.close(docValuesProducer);
+    }
+
+    @Override
+    public void checkIntegrity() throws IOException {}
+
+    @Override
+    public FieldsProducer getMergeInstance() {
+        return new TSDBSyntheticIdFieldsProducer(fieldInfos, docValuesProducer, maxDocs);
+    }
+
+    @Override
+    public Terms terms(String field) throws IOException {
+        assert FIELDS_NAMES.contains(field) : field;
+        return new Terms() {
+            @Override
+            public TermsEnum iterator() {
+                return new FakeTermsEnum();
+            }
+
+            @Override
+            public int getDocCount() {
+                return maxDocs - 1; // All docs have a synthetic id
+            }
+
+            @Override
+            public long size() {
+                return -1; // Number of terms is unknown
+            }
+
+            @Override
+            public long getSumTotalTermFreq() {
+                return 0;
+            }
+
+            @Override
+            public long getSumDocFreq() {
+                return 0;
+            }
+
+            @Override
+            public boolean hasFreqs() {
+                return false;
+            }
+
+            @Override
+            public boolean hasOffsets() {
+                return false;
+            }
+
+            @Override
+            public boolean hasPositions() {
+                return false;
+            }
+
+            @Override
+            public boolean hasPayloads() {
+                return false;
+            }
+        };
+    }
+
+    /**
+     * This is a fake TermsEnum that scans all documents for find docs matching a specific _id. This implementation is only here to show
+     * that the synthetic _id terms is used when applying doc values updates during soft-updates. It is buggy and should not be used besides
+     * some carefully crafted integration tests, because it relies on the current _id format for TSDB indices that has limitations:
+     * - it is composed of a routing hash, a @timestamp and a tsid that cannot be un-hashed so all docs must be scanned to find matchings
+     * - it is not sorted on _id in the Lucene segments so doc values updates stop too early when applying DV updates
+     *
+     * This fake terms enumeration will be changed to support a different _id format in a short future.
+     */
+    private class FakeTermsEnum extends BaseTermsEnum {
+
+        private BytesRef term = null;
+        private int docID = -1;
+
+        private BytesRef latestTsId = null;
+        private long latestTimestamp = -1L;
+
+        private FakeTermsEnum() {}
+
+        @Override
+        public BytesRef next() throws IOException {
+            if (docID == DocIdSetIterator.NO_MORE_DOCS) {
+                assert term == null;
+                return null;
+            }
+            docID += 1;
+            if (maxDocs <= docID) {
+                docID = DocIdSetIterator.NO_MORE_DOCS;
+                latestTimestamp = -1L;
+                latestTsId = null;
+                term = null;
+                return null;
+            }
+
+            // Retrieve _tsid
+            SortedDocValues tsIdDocValues = docValuesProducer.getSorted(fieldInfos.fieldInfo(TS_ID));
+            boolean found = tsIdDocValues.advanceExact(docID);
+            assert found;
+            int tsIdOrd = tsIdDocValues.ordValue();
+            BytesRef tsId = tsIdDocValues.lookupOrd(tsIdOrd);
+            assert tsId != null;
+
+            // Retrieve timestamp
+            SortedNumericDocValues timestampDocValues = docValuesProducer.getSortedNumeric(fieldInfos.fieldInfo(TIMESTAMP));
+            found = timestampDocValues.advanceExact(docID);
+            assert found;
+            assert timestampDocValues.docValueCount() == 1;
+            long timestamp = timestampDocValues.nextValue();
+
+            // Retrieve routing hash
+            var tsRoutingHash = fieldInfos.fieldInfo(TimeSeriesRoutingHashFieldMapper.NAME);
+            assert tsRoutingHash != null;
+            SortedDocValues routingHashDocValues = docValuesProducer.getSorted(tsRoutingHash);
+            found = routingHashDocValues.advanceExact(docID);
+            assert found;
+            BytesRef routingHashBytes = routingHashDocValues.lookupOrd(routingHashDocValues.ordValue());
+
+            int routingHash = TimeSeriesRoutingHashFieldMapper.decode(
+                Uid.decodeId(routingHashBytes.bytes, routingHashBytes.offset, routingHashBytes.length)
+            );
+            term = Uid.encodeId(TsidExtractingIdFieldMapper.createId(routingHash, tsId, timestamp));
+            latestTimestamp = timestamp;
+            latestTsId = tsId;
+            return term;
+        }
+
+        @Override
+        public SeekStatus seekCeil(BytesRef id) {
+            assert id != null;
+            if (term != null && term.equals(id)) {
+                return SeekStatus.FOUND;
+            }
+            try {
+                while (next() != null) {
+                    if (term.equals(id)) {
+                        return SeekStatus.FOUND;
+                    }
+                }
+            } catch (IOException e) {
+                throw new UncheckedIOException(e);
+            }
+            return SeekStatus.END;
+        }
+
+        @Override
+        public BytesRef term() {
+            return term;
+        }
+
+        @Override
+        public PostingsEnum postings(PostingsEnum reuse, int flags) {
+            return new FakePostingsEnum(docID, latestTsId, latestTimestamp, maxDocs);
+        }
+
+        /**
+         * This is an optional method as per the {@link TermsEnum#ord()} documentation that is not supported by the current implementation.
+         * This method always throws an {@link UnsupportedOperationException}.
+         */
+        @Override
+        public long ord() {
+            throw unsupportedException();
+        }
+
+        /**
+         * This is an optional method as per the {@link TermsEnum#ord()} documentation that is not supported by the current implementation.
+         * This method always throws an {@link UnsupportedOperationException}.
+         */
+        @Override
+        public void seekExact(long ord) {
+            throw unsupportedException();
+        }
+
+        @Override
+        public int docFreq() throws IOException {
+            return 0;
+        }
+
+        @Override
+        public long totalTermFreq() throws IOException {
+            return 0;
+        }
+
+        @Override
+        public ImpactsEnum impacts(int flags) throws IOException {
+            return null;
+        }
+    }
+
+    /**
+     * Do not use in production. See {@link FakeTermsEnum}.
+     */
+    private class FakePostingsEnum extends PostingsEnum {
+
+        private final int startDocID;
+        private final BytesRef latestTsId;
+        private final long latestTimestamp;
+        private final int maxDocs;
+        private int docID;
+
+        private FakePostingsEnum(int docID, BytesRef latestTsId, long latestTimestamp, int maxDocs) {
+            this.startDocID = docID;
+            this.latestTsId = latestTsId;
+            this.latestTimestamp = latestTimestamp;
+            this.maxDocs = maxDocs;
+            this.docID = -1;
+        }
+
+        @Override
+        public int docID() {
+            return docID;
+        }
+
+        @Override
+        public int nextDoc() throws IOException {
+            if (docID == DocIdSetIterator.NO_MORE_DOCS) {
+                return docID;
+            } else if (docID == -1) {
+                docID = startDocID;
+            } else {
+                docID = docID + 1;
+                if (maxDocs <= docID) {
+                    docID = DocIdSetIterator.NO_MORE_DOCS;
+                    return docID;
+                }
+            }
+
+            // Retrieve _tsid
+            SortedDocValues tsIdDocValues = docValuesProducer.getSorted(fieldInfos.fieldInfo(TS_ID));
+            boolean found = tsIdDocValues.advanceExact(docID);
+            assert found;
+            int tsIdOrd = tsIdDocValues.ordValue();
+            BytesRef tsId = tsIdDocValues.lookupOrd(tsIdOrd);
+            assert tsId != null;
+
+            if (latestTsId != null && latestTsId.equals(tsId) == false) {
+                // Different _tsid, stop here
+                docID = DocIdSetIterator.NO_MORE_DOCS;
+                return docID;
+            }
+
+            // Retrieve timestamp
+            SortedNumericDocValues timestampDocValues = docValuesProducer.getSortedNumeric(fieldInfos.fieldInfo(TIMESTAMP));
+            found = timestampDocValues.advanceExact(docID);
+            assert found;
+            assert timestampDocValues.docValueCount() == 1;
+            long timestamp = timestampDocValues.nextValue();
+
+            if (latestTimestamp != -1L && latestTimestamp != timestamp) {
+                // Different @timestamp, stop here
+                docID = DocIdSetIterator.NO_MORE_DOCS;
+                return docID;
+            }
+
+            // Retrieve routing hash
+            var tsRoutingHash = fieldInfos.fieldInfo(TimeSeriesRoutingHashFieldMapper.NAME);
+            assert tsRoutingHash != null;
+            SortedDocValues routingHashDocValues = docValuesProducer.getSorted(tsRoutingHash);
+            found = routingHashDocValues.advanceExact(docID);
+            assert found;
+            BytesRef routingHashBytes = routingHashDocValues.lookupOrd(routingHashDocValues.ordValue());
+            assert routingHashBytes != null;
+            return docID;
+        }
+
+        @Override
+        public int advance(int target) throws IOException {
+            int doc;
+            while ((doc = nextDoc()) < target) {
+                // Continue
+            }
+            return doc;
+        }
+
+        @Override
+        public long cost() {
+            return 0L;
+        }
+
+        @Override
+        public int freq() throws IOException {
+            return 0; // not supported
+        }
+
+        @Override
+        public int nextPosition() throws IOException {
+            return -1; // not supported
+        }
+
+        @Override
+        public int startOffset() throws IOException {
+            return -1; // not supported
+        }
+
+        @Override
+        public int endOffset() throws IOException {
+            return -1; // not supported
+        }
+
+        @Override
+        public BytesRef getPayload() throws IOException {
+            return null; // not supported
+        }
+    }
+
+    private static boolean assertFieldInfosExist(FieldInfos fieldInfos, String... fieldNames) {
+        assert fieldNames != null && fieldNames.length > 0 : "fieldNames should be > 0";
+        for (var fieldName : fieldNames) {
+            assert fieldInfos.fieldInfo(fieldName) != null : "field [" + fieldName + "] not found";
+        }
+        return true;
+    }
+
+    private static UnsupportedOperationException unsupportedException() {
+        var error = "This method should not be called on this enum";
+        assert false : error;
+        return new UnsupportedOperationException(error);
+    }
+}
diff --git a/server/src/main/java/org/elasticsearch/index/codec/tsdb/TSDBSyntheticIdPostingsFormat.java b/server/src/main/java/org/elasticsearch/index/codec/tsdb/TSDBSyntheticIdPostingsFormat.java
new file mode 100644
index 0000000000000..cfe9975f33a1b
--- /dev/null
+++ b/server/src/main/java/org/elasticsearch/index/codec/tsdb/TSDBSyntheticIdPostingsFormat.java
@@ -0,0 +1,61 @@
+/*
+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+ * or more contributor license agreements. Licensed under the "Elastic License
+ * 2.0", the "GNU Affero General Public License v3.0 only", and the "Server Side
+ * Public License v 1"; you may not use this file except in compliance with, at
+ * your election, the "Elastic License 2.0", the "GNU Affero General Public
+ * License v3.0 only", or the "Server Side Public License, v 1".
+ */
+
+package org.elasticsearch.index.codec.tsdb;
+
+import org.apache.lucene.codecs.DocValuesProducer;
+import org.apache.lucene.codecs.FieldsConsumer;
+import org.apache.lucene.codecs.FieldsProducer;
+import org.apache.lucene.codecs.PostingsFormat;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.index.SegmentWriteState;
+import org.elasticsearch.core.IOUtils;
+import org.elasticsearch.index.mapper.DataStreamTimestampFieldMapper;
+import org.elasticsearch.index.mapper.SyntheticIdField;
+import org.elasticsearch.index.mapper.TimeSeriesIdFieldMapper;
+
+import java.io.IOException;
+
+public class TSDBSyntheticIdPostingsFormat extends PostingsFormat {
+
+    public static final String SYNTHETIC_ID = SyntheticIdField.NAME;
+    public static final String TIMESTAMP = DataStreamTimestampFieldMapper.DEFAULT_PATH;
+    public static final String TS_ID = TimeSeriesIdFieldMapper.NAME;
+
+    static final String FORMAT_NAME = "TSDBSyntheticId";
+    static final String SUFFIX = "0";
+
+    public TSDBSyntheticIdPostingsFormat() {
+        super(FORMAT_NAME);
+    }
+
+    @Override
+    public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {
+        DocValuesProducer docValuesProducer = null;
+        boolean success = false;
+        try {
+            var codec = state.segmentInfo.getCodec();
+            // Erase the segment suffix (used only for reading postings)
+            docValuesProducer = codec.docValuesFormat().fieldsProducer(new SegmentReadState(state, ""));
+            var fieldsProducer = new TSDBSyntheticIdFieldsProducer(state, docValuesProducer);
+            success = true;
+            return fieldsProducer;
+        } finally {
+            if (success == false) {
+                IOUtils.close(docValuesProducer);
+            }
+        }
+    }
+
+    @Override
+    public FieldsConsumer fieldsConsumer(SegmentWriteState state) throws IOException {
+        assert false : "this should never be called";
+        throw new UnsupportedOperationException();
+    }
+}
diff --git a/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
index 415670d811b82..47e9ab7803a84 100644
--- a/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
+++ b/server/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
@@ -231,6 +231,8 @@ public class InternalEngine extends Engine {
 
     private final ByteSizeValue totalDiskSpace;
 
+    private final boolean useTsdbSyntheticId;
+
     protected static final String REAL_TIME_GET_REFRESH_SOURCE = "realtime_get";
     protected static final String UNSAFE_VERSION_MAP_REFRESH_SOURCE = "unsafe_version_map";
 
@@ -243,6 +245,12 @@ public InternalEngine(EngineConfig engineConfig) {
     InternalEngine(EngineConfig engineConfig, int maxDocs, BiFunction<Long, Long, LocalCheckpointTracker> localCheckpointTrackerSupplier) {
         super(engineConfig);
         this.maxDocs = maxDocs;
+        if (engineConfig.getIndexSettings().useTsdbSyntheticId()) {
+            logger.info("using TSDB with synthetic id");
+            useTsdbSyntheticId = true;
+        } else {
+            useTsdbSyntheticId = false;
+        }
         this.relativeTimeInNanosSupplier = config().getRelativeTimeInNanosSupplier();
         this.lastFlushTimestamp = relativeTimeInNanosSupplier.getAsLong(); // default to creation timestamp
         this.liveVersionMapArchive = createLiveVersionMapArchive();
@@ -1434,6 +1442,7 @@ private IndexResult indexIntoLucene(Index index, IndexingStrategy plan) throws I
         index.parsedDoc().updateSeqID(index.seqNo(), index.primaryTerm());
         index.parsedDoc().version().setLongValue(plan.versionForIndexing);
         try {
+            logDocumentsDetails(index.docs());
             if (plan.addStaleOpToLucene) {
                 addStaleDocs(index.docs(), indexWriter);
             } else if (plan.useLuceneUpdateDocument) {
@@ -1469,6 +1478,14 @@ && treatDocumentFailureAsTragicError(index) == false) {
         }
     }
 
+    private void logDocumentsDetails(List<LuceneDocument> docs) {
+        if (useTsdbSyntheticId && logger.isTraceEnabled()) {
+            for (var doc : docs) {
+                logger.trace("indexing document fields [{}]", doc.getFields());
+            }
+        }
+    }
+
     /**
      * Whether we should treat any document failure as tragic error.
      * If we hit any failure while processing an indexing on a replica, we should treat that error as tragic and fail the engine.
@@ -1842,6 +1859,7 @@ private DeleteResult deleteInLucene(Delete delete, DeletionStrategy plan) throws
         try {
             final ParsedDocument tombstone = ParsedDocument.deleteTombstone(
                 engineConfig.getIndexSettings().seqNoIndexOptions(),
+                useTsdbSyntheticId,
                 delete.id()
             );
             assert tombstone.docs().size() == 1 : "Tombstone doc should have single doc [" + tombstone + "]";
diff --git a/server/src/main/java/org/elasticsearch/index/mapper/IdFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/IdFieldMapper.java
index 8e418f45ddb3a..61f5fa9abcf0a 100644
--- a/server/src/main/java/org/elasticsearch/index/mapper/IdFieldMapper.java
+++ b/server/src/main/java/org/elasticsearch/index/mapper/IdFieldMapper.java
@@ -78,6 +78,13 @@ public static Field standardIdField(String id) {
         return new StringField(NAME, Uid.encodeId(id), Field.Store.YES);
     }
 
+    /**
+     * Create a {@link Field} corresponding to a synthetic {@code _id} field, which is not indexed but instead resolved at runtime.
+     */
+    public static Field syntheticIdField(String id) {
+        return new SyntheticIdField(Uid.encodeId(id));
+    }
+
     protected abstract static class AbstractIdFieldType extends TermBasedFieldType {
 
         public AbstractIdFieldType() {
diff --git a/server/src/main/java/org/elasticsearch/index/mapper/ParsedDocument.java b/server/src/main/java/org/elasticsearch/index/mapper/ParsedDocument.java
index 72fd812d982d8..61b26ca33b1ef 100644
--- a/server/src/main/java/org/elasticsearch/index/mapper/ParsedDocument.java
+++ b/server/src/main/java/org/elasticsearch/index/mapper/ParsedDocument.java
@@ -70,15 +70,32 @@ public static ParsedDocument noopTombstone(SeqNoFieldMapper.SeqNoIndexOptions se
     /**
      * Create a delete tombstone document, which will be used in soft-update methods.
      * The returned document consists only _uid, _seqno, _term and _version fields; other metadata fields are excluded.
-     * @param id    the id of the deleted document
+     * @param id                the id of the deleted document
      */
     public static ParsedDocument deleteTombstone(SeqNoFieldMapper.SeqNoIndexOptions seqNoIndexOptions, String id) {
+        return deleteTombstone(seqNoIndexOptions, false, id);
+    }
+
+    /**
+     * Create a delete tombstone document, which will be used in soft-update methods.
+     * The returned document consists only _uid, _seqno, _term and _version fields; other metadata fields are excluded.
+     * @param useSyntheticId    whether the id is synthetic or not
+     * @param id                the id of the deleted document
+     */
+    public static ParsedDocument deleteTombstone(SeqNoFieldMapper.SeqNoIndexOptions seqNoIndexOptions, boolean useSyntheticId, String id) {
         LuceneDocument document = new LuceneDocument();
         SeqNoFieldMapper.SequenceIDFields seqIdFields = SeqNoFieldMapper.SequenceIDFields.tombstone(seqNoIndexOptions);
         seqIdFields.addFields(document);
         Field versionField = VersionFieldMapper.versionField();
         document.add(versionField);
-        document.add(IdFieldMapper.standardIdField(id));
+        if (useSyntheticId) {
+            // Use a synthetic _id field which is not indexed nor stored
+            document.add(IdFieldMapper.syntheticIdField(id));
+            // TODO I think we also need to add the fields that compose the synthetic _id.
+        } else {
+            // Use standard _id field (indexed and stored, some indices also trim the stored field at some point)
+            document.add(IdFieldMapper.standardIdField(id));
+        }
         return new ParsedDocument(
             versionField,
             seqIdFields,
diff --git a/server/src/main/java/org/elasticsearch/index/mapper/SyntheticIdField.java b/server/src/main/java/org/elasticsearch/index/mapper/SyntheticIdField.java
new file mode 100644
index 0000000000000..0a37fc564a0a4
--- /dev/null
+++ b/server/src/main/java/org/elasticsearch/index/mapper/SyntheticIdField.java
@@ -0,0 +1,67 @@
+/*
+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+ * or more contributor license agreements. Licensed under the "Elastic License
+ * 2.0", the "GNU Affero General Public License v3.0 only", and the "Server Side
+ * Public License v 1"; you may not use this file except in compliance with, at
+ * your election, the "Elastic License 2.0", the "GNU Affero General Public
+ * License v3.0 only", or the "Server Side Public License, v 1".
+ */
+
+package org.elasticsearch.index.mapper;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.index.IndexOptions;
+import org.apache.lucene.util.BytesRef;
+
+import java.util.Map;
+
+public final class SyntheticIdField extends Field {
+
+    public static final String NAME = IdFieldMapper.NAME;
+
+    private static final String ENABLED_ATTRIBUTE_KEY = SyntheticIdField.class.getSimpleName() + ".enabled";
+    private static final String ENABLED_ATTRIBUTE_VALUE = Boolean.TRUE.toString();
+
+    private static final FieldType TYPE;
+    static {
+        TYPE = new FieldType();
+        TYPE.putAttribute(ENABLED_ATTRIBUTE_KEY, ENABLED_ATTRIBUTE_VALUE);
+        // Make sure the field is not indexed, but this option is changed at runtime
+        // in FieldInfos so that the field can use terms and postings.
+        TYPE.setIndexOptions(IndexOptions.NONE);
+        TYPE.setTokenized(false);
+        TYPE.setOmitNorms(true);
+        // The field is marked as stored, but storage on disk might be skipped
+        TYPE.setStored(true);
+        TYPE.freeze();
+    }
+
+    public SyntheticIdField(BytesRef bytes) {
+        super(NAME, bytes, TYPE);
+    }
+
+    @Override
+    public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) {
+        assert false : "this should never be called";
+        throw new UnsupportedOperationException();
+    }
+
+    @Override
+    public void setTokenStream(TokenStream tokenStream) {
+        assert false : "this should never be called";
+        throw new UnsupportedOperationException();
+    }
+
+    public static boolean hasSyntheticIdAttributes(Map<String, String> attributes) {
+        if (attributes != null) {
+            var attributeValue = attributes.get(SyntheticIdField.ENABLED_ATTRIBUTE_KEY);
+            if (attributeValue != null) {
+                return SyntheticIdField.ENABLED_ATTRIBUTE_VALUE.equals(attributeValue);
+            }
+        }
+        return false;
+    }
+}
diff --git a/server/src/main/java/org/elasticsearch/index/mapper/TsidExtractingIdFieldMapper.java b/server/src/main/java/org/elasticsearch/index/mapper/TsidExtractingIdFieldMapper.java
index bb8b0d9ec775c..1bb7001b29890 100644
--- a/server/src/main/java/org/elasticsearch/index/mapper/TsidExtractingIdFieldMapper.java
+++ b/server/src/main/java/org/elasticsearch/index/mapper/TsidExtractingIdFieldMapper.java
@@ -10,7 +10,6 @@
 package org.elasticsearch.index.mapper;
 
 import org.apache.lucene.document.Field;
-import org.apache.lucene.document.StringField;
 import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.cluster.routing.IndexRouting;
@@ -91,11 +90,20 @@ public static BytesRef createField(DocumentParserContext context, RoutingHashBui
                 )
             );
         }
+        assert id != null;
         context.id(id);
 
-        BytesRef uidEncoded = Uid.encodeId(context.id());
-        context.doc().add(new StringField(NAME, uidEncoded, Field.Store.YES));
-        return uidEncoded;
+        final Field idField;
+        if (context.indexSettings().useTsdbSyntheticId()) {
+            idField = syntheticIdField(context.id());
+        } else {
+            idField = standardIdField(context.id());
+        }
+        assert NAME.equals(idField.name()) : idField.name();
+        assert idField.binaryValue() != null;
+
+        context.doc().add(idField);
+        return idField.binaryValue();
     }
 
     public static String createId(int routingHash, BytesRef tsid, long timestamp) {
diff --git a/server/src/main/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat b/server/src/main/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat
index bdb1b75be4843..ce7ea69c10d9e 100644
--- a/server/src/main/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat
+++ b/server/src/main/resources/META-INF/services/org.apache.lucene.codecs.PostingsFormat
@@ -1,3 +1,4 @@
 org.elasticsearch.index.codec.bloomfilter.ES85BloomFilterPostingsFormat
 org.elasticsearch.index.codec.bloomfilter.ES87BloomFilterPostingsFormat
 org.elasticsearch.index.codec.postings.ES812PostingsFormat
+org.elasticsearch.index.codec.tsdb.TSDBSyntheticIdPostingsFormat
diff --git a/server/src/test/java/org/elasticsearch/common/lucene/uid/VersionLookupTests.java b/server/src/test/java/org/elasticsearch/common/lucene/uid/VersionLookupTests.java
index e6c0742cb9979..2e69987f29180 100644
--- a/server/src/test/java/org/elasticsearch/common/lucene/uid/VersionLookupTests.java
+++ b/server/src/test/java/org/elasticsearch/common/lucene/uid/VersionLookupTests.java
@@ -158,7 +158,8 @@ public void testLoadTimestampRange() throws Exception {
     public void testLoadTimestampRangeWithDeleteTombstone() throws Exception {
         Directory dir = newDirectory();
         IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(Lucene.STANDARD_ANALYZER).setMergePolicy(NoMergePolicy.INSTANCE));
-        writer.addDocument(ParsedDocument.deleteTombstone(randomFrom(SeqNoFieldMapper.SeqNoIndexOptions.values()), "_id").docs().get(0));
+        var randomSeqNoIndexOptions = randomFrom(SeqNoFieldMapper.SeqNoIndexOptions.values());
+        writer.addDocument(ParsedDocument.deleteTombstone(randomSeqNoIndexOptions, false, "_id").docs().get(0));
         DirectoryReader reader = DirectoryReader.open(writer);
         LeafReaderContext segment = reader.leaves().get(0);
         PerThreadIDVersionAndSeqNoLookup lookup = new PerThreadIDVersionAndSeqNoLookup(segment.reader(), true);
diff --git a/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
index 79f6710bbe7a7..a553dc6578807 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
@@ -4558,7 +4558,7 @@ public void testOnCloseStats() throws IOException {
     public void testSupplyTombstoneDoc() throws Exception {
         IndexShard shard = newStartedShard();
         String id = randomRealisticUnicodeOfLengthBetween(1, 10);
-        ParsedDocument deleteTombstone = ParsedDocument.deleteTombstone(shard.indexSettings.seqNoIndexOptions(), id);
+        ParsedDocument deleteTombstone = ParsedDocument.deleteTombstone(shard.indexSettings.seqNoIndexOptions(), randomBoolean(), id);
         assertThat(deleteTombstone.docs(), hasSize(1));
         LuceneDocument deleteDoc = deleteTombstone.docs().get(0);
         assertThat(
diff --git a/test/framework/src/main/java/org/elasticsearch/action/admin/indices/diskusage/AnalyzeIndexDiskUsageTestUtils.java b/test/framework/src/main/java/org/elasticsearch/action/admin/indices/diskusage/AnalyzeIndexDiskUsageTestUtils.java
new file mode 100644
index 0000000000000..5c433aeacc5ec
--- /dev/null
+++ b/test/framework/src/main/java/org/elasticsearch/action/admin/indices/diskusage/AnalyzeIndexDiskUsageTestUtils.java
@@ -0,0 +1,40 @@
+/*
+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+ * or more contributor license agreements. Licensed under the "Elastic License
+ * 2.0", the "GNU Affero General Public License v3.0 only", and the "Server Side
+ * Public License v 1"; you may not use this file except in compliance with, at
+ * your election, the "Elastic License 2.0", the "GNU Affero General Public
+ * License v3.0 only", or the "Server Side Public License, v 1".
+ */
+
+package org.elasticsearch.action.admin.indices.diskusage;
+
+import org.elasticsearch.core.Nullable;
+
+public class AnalyzeIndexDiskUsageTestUtils {
+
+    private AnalyzeIndexDiskUsageTestUtils() {}
+
+    @Nullable
+    public static IndexDiskUsageStats getIndexStats(final AnalyzeIndexDiskUsageResponse diskUsageResponse, final String indexName) {
+        var stats = diskUsageResponse.getStats();
+        if (stats != null) {
+            return stats.get(indexName);
+        }
+        return null;
+    }
+
+    @Nullable
+    public static IndexDiskUsageStats.PerFieldDiskUsage getPerFieldDiskUsage(
+        final IndexDiskUsageStats indexDiskUsageStats,
+        final String fieldName
+    ) {
+        if (indexDiskUsageStats != null) {
+            var fields = indexDiskUsageStats.getFields();
+            if (fields != null) {
+                return fields.get(fieldName);
+            }
+        }
+        return null;
+    }
+}
