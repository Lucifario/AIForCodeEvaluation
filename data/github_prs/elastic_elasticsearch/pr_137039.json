{
  "id": 137039,
  "repository": "elastic/elasticsearch",
  "title": "[DiskBBQ] add method for calculate centroids during merge",
  "body": "We currently se the same API method to compute centroids during flush and during merge. In order to explore improvements on how we compute centroids during merge (e.g reusing some of the existing centroids), this commit adds a new API method for calculating centroids during merging. They implementation currently fowards the request to the calcualtion of centroids during flush.\r\n\r\nI moved the computation of the global centroid to CentroidAssignments as it feels it belongs there.\r\n",
  "state": "closed",
  "merged": true,
  "merged_at": "2025-10-23T15:53:42+00:00",
  "created_at": "2025-10-23T14:45:22+00:00",
  "updated_at": "2025-10-23T15:54:05+00:00",
  "author": "iverase",
  "reviewers": [
    "benwtrent"
  ],
  "base_sha": "93d08aaf3dc6c1924e32e5500abcf14cf0c53815",
  "head_sha": "cbe73b68ee5f4431fe2cb7b01eafd927ae851f77",
  "review_comments": [
    {
      "user": "benwtrent",
      "state": "APPROVED",
      "body": "yessir, I agree with the split, we should have a \"merge time\" calculator.",
      "submitted_at": "2025-10-23T14:56:06+00:00"
    }
  ],
  "pr_comments": [
    {
      "user": "elasticsearchmachine",
      "body": "Pinging @elastic/es-search-relevance (Team:Search Relevance)",
      "created_at": "2025-10-23T14:45:56+00:00"
    }
  ],
  "files_changed": [
    {
      "filename": "server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/CentroidAssignments.java",
      "status": "modified",
      "additions": 25,
      "deletions": 3,
      "changes": 28,
      "patch": "@@ -9,11 +9,33 @@\n \n package org.elasticsearch.index.codec.vectors.diskbbq;\n \n-public record CentroidAssignments(int numCentroids, float[][] centroids, int[] assignments, int[] overspillAssignments) {\n+public record CentroidAssignments(\n+    int numCentroids,\n+    float[][] centroids,\n+    int[] assignments,\n+    int[] overspillAssignments,\n+    float[] globalCentroid\n+) {\n \n-    public CentroidAssignments(float[][] centroids, int[] assignments, int[] overspillAssignments) {\n-        this(centroids.length, centroids, assignments, overspillAssignments);\n+    public CentroidAssignments(int dims, float[][] centroids, int[] assignments, int[] overspillAssignments) {\n+        this(centroids.length, centroids, assignments, overspillAssignments, computeGlobalCentroid(dims, centroids));\n         assert assignments.length == overspillAssignments.length || overspillAssignments.length == 0\n             : \"assignments and overspillAssignments must have the same length\";\n+\n+    }\n+\n+    private static float[] computeGlobalCentroid(int dims, float[][] centroids) {\n+        final float[] globalCentroid = new float[dims];\n+        // TODO: push this logic into vector util?\n+        for (float[] centroid : centroids) {\n+            assert centroid.length == dims;\n+            for (int j = 0; j < centroid.length; j++) {\n+                globalCentroid[j] += centroid[j];\n+            }\n+        }\n+        for (int j = 0; j < globalCentroid.length; j++) {\n+            globalCentroid[j] /= centroids.length;\n+        }\n+        return globalCentroid;\n     }\n }"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/ES920DiskBBQVectorsWriter.java",
      "status": "modified",
      "additions": 10,
      "deletions": 23,
      "changes": 33,
      "patch": "@@ -523,47 +523,34 @@ public int size() {\n         return new CentroidGroups(kMeansResult.centroids(), vectorsPerCentroid, maxVectorsPerCentroidLength);\n     }\n \n+    @Override\n+    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, MergeState mergeState)\n+        throws IOException {\n+        return calculateCentroids(fieldInfo, floatVectorValues);\n+    }\n+\n     /**\n      * Calculate the centroids for the given field.\n      * We use the {@link HierarchicalKMeans} algorithm to partition the space of all vectors across merging segments\n      *\n      * @param fieldInfo merging field info\n      * @param floatVectorValues the float vector values to merge\n-     * @param globalCentroid the global centroid, calculated by this method and used to quantize the centroids\n      * @return the vector assignments, soar assignments, and if asked the centroids themselves that were computed\n      * @throws IOException if an I/O error occurs\n      */\n     @Override\n-    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, float[] globalCentroid)\n-        throws IOException {\n-\n+    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues) throws IOException {\n         // TODO: consider hinting / bootstrapping hierarchical kmeans with the prior segments centroids\n-        CentroidAssignments centroidAssignments = buildCentroidAssignments(floatVectorValues, vectorPerCluster);\n-        float[][] centroids = centroidAssignments.centroids();\n         // TODO: for flush we are doing this over the vectors and here centroids which seems duplicative\n         // preliminary tests suggest recall is good using only centroids but need to do further evaluation\n-        // TODO: push this logic into vector util?\n-        for (float[] centroid : centroids) {\n-            for (int j = 0; j < centroid.length; j++) {\n-                globalCentroid[j] += centroid[j];\n-            }\n-        }\n-        for (int j = 0; j < globalCentroid.length; j++) {\n-            globalCentroid[j] /= centroids.length;\n-        }\n-\n+        KMeansResult kMeansResult = new HierarchicalKMeans(floatVectorValues.dimension()).cluster(floatVectorValues, vectorPerCluster);\n+        float[][] centroids = kMeansResult.centroids();\n         if (logger.isDebugEnabled()) {\n             logger.debug(\"final centroid count: {}\", centroids.length);\n         }\n-        return centroidAssignments;\n-    }\n-\n-    static CentroidAssignments buildCentroidAssignments(FloatVectorValues floatVectorValues, int vectorPerCluster) throws IOException {\n-        KMeansResult kMeansResult = new HierarchicalKMeans(floatVectorValues.dimension()).cluster(floatVectorValues, vectorPerCluster);\n-        float[][] centroids = kMeansResult.centroids();\n         int[] assignments = kMeansResult.assignments();\n         int[] soarAssignments = kMeansResult.soarAssignments();\n-        return new CentroidAssignments(centroids, assignments, soarAssignments);\n+        return new CentroidAssignments(fieldInfo.getVectorDimension(), centroids, assignments, soarAssignments);\n     }\n \n     static void writeQuantizedValue(IndexOutput indexOutput, byte[] binaryValue, OptimizedScalarQuantizer.QuantizationResult corrections)"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/IVFVectorsWriter.java",
      "status": "modified",
      "additions": 8,
      "deletions": 5,
      "changes": 13,
      "patch": "@@ -141,7 +141,9 @@ public final KnnFieldVectorsWriter<?> addField(FieldInfo fieldInfo) throws IOExc\n         return rawVectorDelegate;\n     }\n \n-    public abstract CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, float[] globalCentroid)\n+    public abstract CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues) throws IOException;\n+\n+    public abstract CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, MergeState mergeState)\n         throws IOException;\n \n     public record CentroidOffsetAndLength(LongValues offsets, LongValues lengths) {}\n@@ -191,11 +193,10 @@ public final void flush(int maxDoc, Sorter.DocMap sortMap) throws IOException {\n                 writeMeta(fieldWriter.fieldInfo, 0, 0, 0, 0, 0, null);\n                 continue;\n             }\n-            final float[] globalCentroid = new float[fieldWriter.fieldInfo.getVectorDimension()];\n             // build a float vector values with random access\n             final FloatVectorValues floatVectorValues = getFloatVectorValues(fieldWriter.fieldInfo, fieldWriter.delegate, maxDoc);\n             // build centroids\n-            final CentroidAssignments centroidAssignments = calculateCentroids(fieldWriter.fieldInfo, floatVectorValues, globalCentroid);\n+            final CentroidAssignments centroidAssignments = calculateCentroids(fieldWriter.fieldInfo, floatVectorValues);\n             // wrap centroids with a supplier\n             final CentroidSupplier centroidSupplier = CentroidSupplier.fromArray(centroidAssignments.centroids());\n             // write posting lists\n@@ -211,6 +212,7 @@ public final void flush(int maxDoc, Sorter.DocMap sortMap) throws IOException {\n             );\n             final long postingListLength = ivfClusters.getFilePointer() - postingListOffset;\n             // write centroids\n+            final float[] globalCentroid = centroidAssignments.globalCentroid();\n             final long centroidOffset = ivfCentroids.alignFilePointer(Float.BYTES);\n             writeCentroids(fieldWriter.fieldInfo, centroidSupplier, globalCentroid, centroidOffsetAndLength, ivfCentroids);\n             final long centroidLength = ivfCentroids.getFilePointer() - centroidOffset;\n@@ -377,7 +379,7 @@ private void mergeOneFieldIVF(FieldInfo fieldInfo, MergeState mergeState) throws\n             final int numCentroids;\n             final int[] assignments;\n             final int[] overspillAssignments;\n-            final float[] calculatedGlobalCentroid = new float[fieldInfo.getVectorDimension()];\n+            final float[] calculatedGlobalCentroid;\n             String centroidTempName = null;\n             IndexOutput centroidTemp = null;\n             success = false;\n@@ -387,7 +389,7 @@ private void mergeOneFieldIVF(FieldInfo fieldInfo, MergeState mergeState) throws\n                 CentroidAssignments centroidAssignments = calculateCentroids(\n                     fieldInfo,\n                     getFloatVectorValues(fieldInfo, docs, vectors, numVectors),\n-                    calculatedGlobalCentroid\n+                    mergeState\n                 );\n                 // write the centroids to a temporary file so we are not holding them on heap\n                 final ByteBuffer buffer = ByteBuffer.allocate(fieldInfo.getVectorDimension() * Float.BYTES).order(ByteOrder.LITTLE_ENDIAN);\n@@ -397,6 +399,7 @@ private void mergeOneFieldIVF(FieldInfo fieldInfo, MergeState mergeState) throws\n                 }\n                 numCentroids = centroidAssignments.numCentroids();\n                 assignments = centroidAssignments.assignments();\n+                calculatedGlobalCentroid = centroidAssignments.globalCentroid();\n                 overspillAssignments = centroidAssignments.overspillAssignments();\n                 success = true;\n             } finally {"
    },
    {
      "filename": "server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/next/ESNextDiskBBQVectorsWriter.java",
      "status": "modified",
      "additions": 10,
      "deletions": 23,
      "changes": 33,
      "patch": "@@ -511,47 +511,34 @@ public int size() {\n         return new CentroidGroups(kMeansResult.centroids(), vectorsPerCentroid, maxVectorsPerCentroidLength);\n     }\n \n+    @Override\n+    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, MergeState mergeState)\n+        throws IOException {\n+        return calculateCentroids(fieldInfo, floatVectorValues);\n+    }\n+\n     /**\n      * Calculate the centroids for the given field.\n      * We use the {@link HierarchicalKMeans} algorithm to partition the space of all vectors across merging segments\n      *\n      * @param fieldInfo merging field info\n      * @param floatVectorValues the float vector values to merge\n-     * @param globalCentroid the global centroid, calculated by this method and used to quantize the centroids\n      * @return the vector assignments, soar assignments, and if asked the centroids themselves that were computed\n      * @throws IOException if an I/O error occurs\n      */\n     @Override\n-    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, float[] globalCentroid)\n-        throws IOException {\n-\n+    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues) throws IOException {\n         // TODO: consider hinting / bootstrapping hierarchical kmeans with the prior segments centroids\n-        CentroidAssignments centroidAssignments = buildCentroidAssignments(floatVectorValues, vectorPerCluster);\n-        float[][] centroids = centroidAssignments.centroids();\n         // TODO: for flush we are doing this over the vectors and here centroids which seems duplicative\n         // preliminary tests suggest recall is good using only centroids but need to do further evaluation\n-        // TODO: push this logic into vector util?\n-        for (float[] centroid : centroids) {\n-            for (int j = 0; j < centroid.length; j++) {\n-                globalCentroid[j] += centroid[j];\n-            }\n-        }\n-        for (int j = 0; j < globalCentroid.length; j++) {\n-            globalCentroid[j] /= centroids.length;\n-        }\n-\n+        KMeansResult kMeansResult = new HierarchicalKMeans(floatVectorValues.dimension()).cluster(floatVectorValues, vectorPerCluster);\n+        float[][] centroids = kMeansResult.centroids();\n         if (logger.isDebugEnabled()) {\n             logger.debug(\"final centroid count: {}\", centroids.length);\n         }\n-        return centroidAssignments;\n-    }\n-\n-    static CentroidAssignments buildCentroidAssignments(FloatVectorValues floatVectorValues, int vectorPerCluster) throws IOException {\n-        KMeansResult kMeansResult = new HierarchicalKMeans(floatVectorValues.dimension()).cluster(floatVectorValues, vectorPerCluster);\n-        float[][] centroids = kMeansResult.centroids();\n         int[] assignments = kMeansResult.assignments();\n         int[] soarAssignments = kMeansResult.soarAssignments();\n-        return new CentroidAssignments(centroids, assignments, soarAssignments);\n+        return new CentroidAssignments(fieldInfo.getVectorDimension(), centroids, assignments, soarAssignments);\n     }\n \n     static void writeQuantizedValue(IndexOutput indexOutput, byte[] binaryValue, OptimizedScalarQuantizer.QuantizationResult corrections)"
    }
  ],
  "diff": "diff --git a/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/CentroidAssignments.java b/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/CentroidAssignments.java\nindex 33ea8085191c3..32044e30a9aab 100644\n--- a/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/CentroidAssignments.java\n+++ b/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/CentroidAssignments.java\n@@ -9,11 +9,33 @@\n \n package org.elasticsearch.index.codec.vectors.diskbbq;\n \n-public record CentroidAssignments(int numCentroids, float[][] centroids, int[] assignments, int[] overspillAssignments) {\n+public record CentroidAssignments(\n+    int numCentroids,\n+    float[][] centroids,\n+    int[] assignments,\n+    int[] overspillAssignments,\n+    float[] globalCentroid\n+) {\n \n-    public CentroidAssignments(float[][] centroids, int[] assignments, int[] overspillAssignments) {\n-        this(centroids.length, centroids, assignments, overspillAssignments);\n+    public CentroidAssignments(int dims, float[][] centroids, int[] assignments, int[] overspillAssignments) {\n+        this(centroids.length, centroids, assignments, overspillAssignments, computeGlobalCentroid(dims, centroids));\n         assert assignments.length == overspillAssignments.length || overspillAssignments.length == 0\n             : \"assignments and overspillAssignments must have the same length\";\n+\n+    }\n+\n+    private static float[] computeGlobalCentroid(int dims, float[][] centroids) {\n+        final float[] globalCentroid = new float[dims];\n+        // TODO: push this logic into vector util?\n+        for (float[] centroid : centroids) {\n+            assert centroid.length == dims;\n+            for (int j = 0; j < centroid.length; j++) {\n+                globalCentroid[j] += centroid[j];\n+            }\n+        }\n+        for (int j = 0; j < globalCentroid.length; j++) {\n+            globalCentroid[j] /= centroids.length;\n+        }\n+        return globalCentroid;\n     }\n }\ndiff --git a/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/ES920DiskBBQVectorsWriter.java b/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/ES920DiskBBQVectorsWriter.java\nindex 68d6acc248a07..125144138f952 100644\n--- a/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/ES920DiskBBQVectorsWriter.java\n+++ b/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/ES920DiskBBQVectorsWriter.java\n@@ -523,47 +523,34 @@ public int size() {\n         return new CentroidGroups(kMeansResult.centroids(), vectorsPerCentroid, maxVectorsPerCentroidLength);\n     }\n \n+    @Override\n+    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, MergeState mergeState)\n+        throws IOException {\n+        return calculateCentroids(fieldInfo, floatVectorValues);\n+    }\n+\n     /**\n      * Calculate the centroids for the given field.\n      * We use the {@link HierarchicalKMeans} algorithm to partition the space of all vectors across merging segments\n      *\n      * @param fieldInfo merging field info\n      * @param floatVectorValues the float vector values to merge\n-     * @param globalCentroid the global centroid, calculated by this method and used to quantize the centroids\n      * @return the vector assignments, soar assignments, and if asked the centroids themselves that were computed\n      * @throws IOException if an I/O error occurs\n      */\n     @Override\n-    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, float[] globalCentroid)\n-        throws IOException {\n-\n+    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues) throws IOException {\n         // TODO: consider hinting / bootstrapping hierarchical kmeans with the prior segments centroids\n-        CentroidAssignments centroidAssignments = buildCentroidAssignments(floatVectorValues, vectorPerCluster);\n-        float[][] centroids = centroidAssignments.centroids();\n         // TODO: for flush we are doing this over the vectors and here centroids which seems duplicative\n         // preliminary tests suggest recall is good using only centroids but need to do further evaluation\n-        // TODO: push this logic into vector util?\n-        for (float[] centroid : centroids) {\n-            for (int j = 0; j < centroid.length; j++) {\n-                globalCentroid[j] += centroid[j];\n-            }\n-        }\n-        for (int j = 0; j < globalCentroid.length; j++) {\n-            globalCentroid[j] /= centroids.length;\n-        }\n-\n+        KMeansResult kMeansResult = new HierarchicalKMeans(floatVectorValues.dimension()).cluster(floatVectorValues, vectorPerCluster);\n+        float[][] centroids = kMeansResult.centroids();\n         if (logger.isDebugEnabled()) {\n             logger.debug(\"final centroid count: {}\", centroids.length);\n         }\n-        return centroidAssignments;\n-    }\n-\n-    static CentroidAssignments buildCentroidAssignments(FloatVectorValues floatVectorValues, int vectorPerCluster) throws IOException {\n-        KMeansResult kMeansResult = new HierarchicalKMeans(floatVectorValues.dimension()).cluster(floatVectorValues, vectorPerCluster);\n-        float[][] centroids = kMeansResult.centroids();\n         int[] assignments = kMeansResult.assignments();\n         int[] soarAssignments = kMeansResult.soarAssignments();\n-        return new CentroidAssignments(centroids, assignments, soarAssignments);\n+        return new CentroidAssignments(fieldInfo.getVectorDimension(), centroids, assignments, soarAssignments);\n     }\n \n     static void writeQuantizedValue(IndexOutput indexOutput, byte[] binaryValue, OptimizedScalarQuantizer.QuantizationResult corrections)\ndiff --git a/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/IVFVectorsWriter.java b/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/IVFVectorsWriter.java\nindex 87b01f3800068..ee4aaca10227b 100644\n--- a/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/IVFVectorsWriter.java\n+++ b/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/IVFVectorsWriter.java\n@@ -141,7 +141,9 @@ public final KnnFieldVectorsWriter<?> addField(FieldInfo fieldInfo) throws IOExc\n         return rawVectorDelegate;\n     }\n \n-    public abstract CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, float[] globalCentroid)\n+    public abstract CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues) throws IOException;\n+\n+    public abstract CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, MergeState mergeState)\n         throws IOException;\n \n     public record CentroidOffsetAndLength(LongValues offsets, LongValues lengths) {}\n@@ -191,11 +193,10 @@ public final void flush(int maxDoc, Sorter.DocMap sortMap) throws IOException {\n                 writeMeta(fieldWriter.fieldInfo, 0, 0, 0, 0, 0, null);\n                 continue;\n             }\n-            final float[] globalCentroid = new float[fieldWriter.fieldInfo.getVectorDimension()];\n             // build a float vector values with random access\n             final FloatVectorValues floatVectorValues = getFloatVectorValues(fieldWriter.fieldInfo, fieldWriter.delegate, maxDoc);\n             // build centroids\n-            final CentroidAssignments centroidAssignments = calculateCentroids(fieldWriter.fieldInfo, floatVectorValues, globalCentroid);\n+            final CentroidAssignments centroidAssignments = calculateCentroids(fieldWriter.fieldInfo, floatVectorValues);\n             // wrap centroids with a supplier\n             final CentroidSupplier centroidSupplier = CentroidSupplier.fromArray(centroidAssignments.centroids());\n             // write posting lists\n@@ -211,6 +212,7 @@ public final void flush(int maxDoc, Sorter.DocMap sortMap) throws IOException {\n             );\n             final long postingListLength = ivfClusters.getFilePointer() - postingListOffset;\n             // write centroids\n+            final float[] globalCentroid = centroidAssignments.globalCentroid();\n             final long centroidOffset = ivfCentroids.alignFilePointer(Float.BYTES);\n             writeCentroids(fieldWriter.fieldInfo, centroidSupplier, globalCentroid, centroidOffsetAndLength, ivfCentroids);\n             final long centroidLength = ivfCentroids.getFilePointer() - centroidOffset;\n@@ -377,7 +379,7 @@ private void mergeOneFieldIVF(FieldInfo fieldInfo, MergeState mergeState) throws\n             final int numCentroids;\n             final int[] assignments;\n             final int[] overspillAssignments;\n-            final float[] calculatedGlobalCentroid = new float[fieldInfo.getVectorDimension()];\n+            final float[] calculatedGlobalCentroid;\n             String centroidTempName = null;\n             IndexOutput centroidTemp = null;\n             success = false;\n@@ -387,7 +389,7 @@ private void mergeOneFieldIVF(FieldInfo fieldInfo, MergeState mergeState) throws\n                 CentroidAssignments centroidAssignments = calculateCentroids(\n                     fieldInfo,\n                     getFloatVectorValues(fieldInfo, docs, vectors, numVectors),\n-                    calculatedGlobalCentroid\n+                    mergeState\n                 );\n                 // write the centroids to a temporary file so we are not holding them on heap\n                 final ByteBuffer buffer = ByteBuffer.allocate(fieldInfo.getVectorDimension() * Float.BYTES).order(ByteOrder.LITTLE_ENDIAN);\n@@ -397,6 +399,7 @@ private void mergeOneFieldIVF(FieldInfo fieldInfo, MergeState mergeState) throws\n                 }\n                 numCentroids = centroidAssignments.numCentroids();\n                 assignments = centroidAssignments.assignments();\n+                calculatedGlobalCentroid = centroidAssignments.globalCentroid();\n                 overspillAssignments = centroidAssignments.overspillAssignments();\n                 success = true;\n             } finally {\ndiff --git a/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/next/ESNextDiskBBQVectorsWriter.java b/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/next/ESNextDiskBBQVectorsWriter.java\nindex 5b19f62f00167..70f140294b380 100644\n--- a/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/next/ESNextDiskBBQVectorsWriter.java\n+++ b/server/src/main/java/org/elasticsearch/index/codec/vectors/diskbbq/next/ESNextDiskBBQVectorsWriter.java\n@@ -511,47 +511,34 @@ public int size() {\n         return new CentroidGroups(kMeansResult.centroids(), vectorsPerCentroid, maxVectorsPerCentroidLength);\n     }\n \n+    @Override\n+    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, MergeState mergeState)\n+        throws IOException {\n+        return calculateCentroids(fieldInfo, floatVectorValues);\n+    }\n+\n     /**\n      * Calculate the centroids for the given field.\n      * We use the {@link HierarchicalKMeans} algorithm to partition the space of all vectors across merging segments\n      *\n      * @param fieldInfo merging field info\n      * @param floatVectorValues the float vector values to merge\n-     * @param globalCentroid the global centroid, calculated by this method and used to quantize the centroids\n      * @return the vector assignments, soar assignments, and if asked the centroids themselves that were computed\n      * @throws IOException if an I/O error occurs\n      */\n     @Override\n-    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues, float[] globalCentroid)\n-        throws IOException {\n-\n+    public CentroidAssignments calculateCentroids(FieldInfo fieldInfo, FloatVectorValues floatVectorValues) throws IOException {\n         // TODO: consider hinting / bootstrapping hierarchical kmeans with the prior segments centroids\n-        CentroidAssignments centroidAssignments = buildCentroidAssignments(floatVectorValues, vectorPerCluster);\n-        float[][] centroids = centroidAssignments.centroids();\n         // TODO: for flush we are doing this over the vectors and here centroids which seems duplicative\n         // preliminary tests suggest recall is good using only centroids but need to do further evaluation\n-        // TODO: push this logic into vector util?\n-        for (float[] centroid : centroids) {\n-            for (int j = 0; j < centroid.length; j++) {\n-                globalCentroid[j] += centroid[j];\n-            }\n-        }\n-        for (int j = 0; j < globalCentroid.length; j++) {\n-            globalCentroid[j] /= centroids.length;\n-        }\n-\n+        KMeansResult kMeansResult = new HierarchicalKMeans(floatVectorValues.dimension()).cluster(floatVectorValues, vectorPerCluster);\n+        float[][] centroids = kMeansResult.centroids();\n         if (logger.isDebugEnabled()) {\n             logger.debug(\"final centroid count: {}\", centroids.length);\n         }\n-        return centroidAssignments;\n-    }\n-\n-    static CentroidAssignments buildCentroidAssignments(FloatVectorValues floatVectorValues, int vectorPerCluster) throws IOException {\n-        KMeansResult kMeansResult = new HierarchicalKMeans(floatVectorValues.dimension()).cluster(floatVectorValues, vectorPerCluster);\n-        float[][] centroids = kMeansResult.centroids();\n         int[] assignments = kMeansResult.assignments();\n         int[] soarAssignments = kMeansResult.soarAssignments();\n-        return new CentroidAssignments(centroids, assignments, soarAssignments);\n+        return new CentroidAssignments(fieldInfo.getVectorDimension(), centroids, assignments, soarAssignments);\n     }\n \n     static void writeQuantizedValue(IndexOutput indexOutput, byte[] binaryValue, OptimizedScalarQuantizer.QuantizationResult corrections)\n",
  "additions": 53,
  "deletions": 54,
  "changed_files": 4,
  "url": "https://github.com/elastic/elasticsearch/pull/137039",
  "mined_at": "2025-10-25T13:43:12.709411"
}